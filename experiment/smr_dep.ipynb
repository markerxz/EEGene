{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75316ef5-b08d-481b-a70c-b80d3564d8e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:36:59.321840: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-05 23:36:59.321910: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import EEGene\n",
    "import misc\n",
    "import Benchmarks\n",
    "from EEGene import EEGene,Processing\n",
    "from misc import Experiment,Data_Loader,Baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa9a758-b302-425e-aeba-fbaa3dcaa0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing from all possible events\n"
     ]
    }
   ],
   "source": [
    "DL = Data_Loader()\n",
    "X_smr,y_smr = DL.load_smr(sub=-1,fmin=0.5,fmax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbee531-c678-43df-9c13-a301ea861257",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  0\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 15, 448, 8)       32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 1, 448, 16)       240       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 448, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 112, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1, 112, 16)       1056      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 112, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 14, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:38:50.230532: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-12-05 23:38:50.230619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: bob\n",
      "2022-12-05 23:38:50.230629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: bob\n",
      "2022-12-05 23:38:50.230839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2022-12-05 23:38:50.230874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.85.2\n",
      "2022-12-05 23:38:50.230882: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 510.85.2 does not match DSO version 510.108.3 -- cannot find working devices in this configuration\n",
      "2022-12-05 23:38:50.231361: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.5104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:38:52.929242: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7249 - accuracy: 0.5104 - val_loss: 0.6873 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.6316 - accuracy: 0.7083 - val_loss: 0.7113 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.5761 - accuracy: 0.7188 - val_loss: 0.7334 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.5287 - accuracy: 0.8125 - val_loss: 0.7335 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.4876 - accuracy: 0.8125 - val_loss: 0.7329 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.4560 - accuracy: 0.7917 - val_loss: 0.7809 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.4226 - accuracy: 0.8854 - val_loss: 0.7932 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.4069 - accuracy: 0.8646 - val_loss: 0.8109 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.3684 - accuracy: 0.9375 - val_loss: 0.8265 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.3650 - accuracy: 0.8958 - val_loss: 0.8115 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.3322 - accuracy: 0.9271 - val_loss: 0.8238 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.3462 - accuracy: 0.9062 - val_loss: 0.8318 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.3098 - accuracy: 0.9062 - val_loss: 0.8211 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.2853 - accuracy: 0.9479 - val_loss: 0.7879 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.2703 - accuracy: 0.9792 - val_loss: 0.8229 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.2580 - accuracy: 0.9583 - val_loss: 0.8246 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.2383 - accuracy: 0.9583 - val_loss: 0.8083 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.2236 - accuracy: 0.9688 - val_loss: 0.7938 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.1928 - accuracy: 0.9792 - val_loss: 0.7914 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.2080 - accuracy: 0.9583 - val_loss: 0.8022 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.1780 - accuracy: 0.9896 - val_loss: 0.8079 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:39:08.562837: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.62      0.67        16\n",
      "         1.0       0.67      0.75      0.71        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.69      0.69      0.69        32\n",
      "weighted avg       0.69      0.69      0.69        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 1, 444, 25)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 222, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1, 218, 50)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 109, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1, 105, 100)      4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 52, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 1, 48, 200)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 24, 200)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4800)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.0658 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 6.0658 - accuracy: 0.5521 - val_loss: 8.9401 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.9090 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.9090 - accuracy: 0.5417 - val_loss: 3.2594 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6961 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.6961 - accuracy: 0.5417 - val_loss: 1.9371 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4576 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.4576 - accuracy: 0.5312 - val_loss: 0.9790 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 133ms/step - loss: 1.5803 - accuracy: 0.6042 - val_loss: 2.2128 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 1.5744 - accuracy: 0.6250 - val_loss: 1.2345 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 1.1081 - accuracy: 0.6354 - val_loss: 1.9754 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.8879 - accuracy: 0.6146 - val_loss: 1.3258 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.8432 - accuracy: 0.6771 - val_loss: 1.4423 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6689 - accuracy: 0.6771 - val_loss: 1.3298 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6095 - accuracy: 0.7188 - val_loss: 1.2012 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4927 - accuracy: 0.7708 - val_loss: 1.0349 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4652 - accuracy: 0.7708 - val_loss: 0.9989 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4794 - accuracy: 0.7812 - val_loss: 1.0355 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3998 - accuracy: 0.8021 - val_loss: 0.9223 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4263 - accuracy: 0.8021 - val_loss: 1.0375 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.3926 - accuracy: 0.8021 - val_loss: 1.1071 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4066 - accuracy: 0.8333 - val_loss: 0.9550 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.3277 - accuracy: 0.8854 - val_loss: 1.1100 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.2932 - accuracy: 0.8854 - val_loss: 1.1472 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.3176 - accuracy: 0.8646 - val_loss: 1.0667 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2709 - accuracy: 0.9062 - val_loss: 1.0759 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.2990 - accuracy: 0.8854 - val_loss: 1.2889 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.2573 - accuracy: 0.9062 - val_loss: 1.1002 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.2832 - accuracy: 0.9062 - val_loss: 1.0688 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2796 - accuracy: 0.8958 - val_loss: 1.2193 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.2210 - accuracy: 0.9375 - val_loss: 1.2727 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.1886 - accuracy: 0.9167 - val_loss: 1.3224 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 0.1703 - accuracy: 0.9583 - val_loss: 1.4423 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1894 - accuracy: 0.8958 - val_loss: 1.5632 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1733 - accuracy: 0.9479 - val_loss: 1.6273 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.2097 - accuracy: 0.9167 - val_loss: 1.5262 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.2155 - accuracy: 0.9062 - val_loss: 1.8703 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.2775 - accuracy: 0.9062 - val_loss: 1.3203 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.2468 - accuracy: 0.9167 - val_loss: 1.4905 - val_accuracy: 0.6250 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:39:43.621467: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.56      0.64        16\n",
      "         1.0       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.70      0.69      0.68        32\n",
      "weighted avg       0.70      0.69      0.68        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 1, 448, 16)       240       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 1, 112, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 1, 112, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 1, 14, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7409 - accuracy: 0.4792 - val_loss: 0.6905 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6165 - accuracy: 0.6667 - val_loss: 0.6795 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.5259 - accuracy: 0.8125 - val_loss: 0.6993 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.4704 - accuracy: 0.8021 - val_loss: 0.7799 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.4339 - accuracy: 0.8125 - val_loss: 0.8197 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.4051 - accuracy: 0.8542 - val_loss: 0.8258 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.3664 - accuracy: 0.9167 - val_loss: 0.8607 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.3361 - accuracy: 0.9167 - val_loss: 0.9059 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.3159 - accuracy: 0.9375 - val_loss: 0.9474 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.2950 - accuracy: 0.9271 - val_loss: 0.9533 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.2865 - accuracy: 0.9271 - val_loss: 0.9417 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.2846 - accuracy: 0.9375 - val_loss: 0.9726 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.2464 - accuracy: 0.9271 - val_loss: 0.9899 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.2599 - accuracy: 0.9375 - val_loss: 1.0316 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 304ms/step - loss: 0.2268 - accuracy: 0.9688 - val_loss: 1.0592 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.2020 - accuracy: 0.9583 - val_loss: 1.1160 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.2015 - accuracy: 0.9583 - val_loss: 1.1386 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.1992 - accuracy: 0.9896 - val_loss: 1.1537 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.1733 - accuracy: 0.9688 - val_loss: 1.2039 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.1705 - accuracy: 0.9896 - val_loss: 1.2322 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.1507 - accuracy: 0.9688 - val_loss: 1.2016 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.1347 - accuracy: 0.9896 - val_loss: 1.2509 - val_accuracy: 0.4688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:43:18.131094: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.56      0.58        16\n",
      "         1.0       0.59      0.62      0.61        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.59      0.59      0.59        32\n",
      "weighted avg       0.59      0.59      0.59        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 222, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 109, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.9856 - accuracy: 0.4167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 6.9856 - accuracy: 0.4167 - val_loss: 30.4146 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.6308 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.6308 - accuracy: 0.4896 - val_loss: 7.0831 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9240 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 1.9240 - accuracy: 0.5312 - val_loss: 1.8670 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9751 - accuracy: 0.6562 - val_loss: 1.2140 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 1.0494 - accuracy: 0.5521 - val_loss: 1.3640 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.7950 - accuracy: 0.6667 - val_loss: 2.5121 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 1.1172 - accuracy: 0.6250 - val_loss: 1.4848 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.9957 - accuracy: 0.6875 - val_loss: 1.7008 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.8005 - accuracy: 0.6250 - val_loss: 1.7219 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.6818 - accuracy: 0.6875 - val_loss: 1.4232 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.7975 - accuracy: 0.6562 - val_loss: 1.8644 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.7823 - accuracy: 0.6146 - val_loss: 1.6441 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.5469 - accuracy: 0.7500 - val_loss: 1.5201 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.5232 - accuracy: 0.7708 - val_loss: 1.2840 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.4215 - accuracy: 0.8021 - val_loss: 1.2149 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.5397 - accuracy: 0.7396 - val_loss: 1.5125 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.6720 - accuracy: 0.7396 - val_loss: 1.4567 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.6822 - accuracy: 0.6979 - val_loss: 1.7471 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.6596 - accuracy: 0.7188 - val_loss: 1.5785 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.5852 - accuracy: 0.6979 - val_loss: 1.4165 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.5773 - accuracy: 0.7083 - val_loss: 1.5021 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.7500INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5188 - accuracy: 0.7500 - val_loss: 1.2020 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 1.5244 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.4561 - accuracy: 0.8125 - val_loss: 1.3523 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3257 - accuracy: 0.8438 - val_loss: 1.3458 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8333INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3130 - accuracy: 0.8333 - val_loss: 1.1077 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.3015 - accuracy: 0.8542 - val_loss: 1.1902 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.3356 - accuracy: 0.7917 - val_loss: 1.1513 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.3135 - accuracy: 0.8229 - val_loss: 1.2228 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.2976 - accuracy: 0.8542 - val_loss: 1.1481 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.8646INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2608 - accuracy: 0.8646 - val_loss: 1.0815 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.2646 - accuracy: 0.8854 - val_loss: 1.2376 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.2490 - accuracy: 0.8854 - val_loss: 1.2531 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.2551 - accuracy: 0.8750 - val_loss: 1.2917 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.2960 - accuracy: 0.8750 - val_loss: 1.1612 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.2486 - accuracy: 0.8750 - val_loss: 1.1821 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.2027 - accuracy: 0.9062 - val_loss: 1.3873 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.1699 - accuracy: 0.9271 - val_loss: 1.2663 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.2186 - accuracy: 0.9271 - val_loss: 1.4200 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.2016 - accuracy: 0.9062 - val_loss: 1.5048 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.2278 - accuracy: 0.9062 - val_loss: 1.2912 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.1453 - accuracy: 0.9896 - val_loss: 1.5098 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.1762 - accuracy: 0.9167 - val_loss: 1.5018 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.1236 - accuracy: 0.9479 - val_loss: 1.2778 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1563 - accuracy: 0.9479 - val_loss: 1.4037 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1105 - accuracy: 0.9583 - val_loss: 1.1655 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1618 - accuracy: 0.9583 - val_loss: 1.3207 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1494 - accuracy: 0.9375 - val_loss: 1.6924 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.1257 - accuracy: 0.9583 - val_loss: 1.1357 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.1314 - accuracy: 0.9583 - val_loss: 1.2844 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.1091 - accuracy: 0.9688 - val_loss: 1.4205 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:44:42.340305: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.50      0.48        16\n",
      "         1.0       0.47      0.44      0.45        16\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.47      0.47      0.47        32\n",
      "weighted avg       0.47      0.47      0.47        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 1, 448, 16)       240       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_8 (Averag  (None, 1, 112, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 1, 112, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_9 (Averag  (None, 1, 14, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7382 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7382 - accuracy: 0.5000 - val_loss: 0.6882 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6262 - accuracy: 0.6458 - val_loss: 0.6848 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.5312 - accuracy: 0.8125 - val_loss: 0.7000 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.4679 - accuracy: 0.8021 - val_loss: 0.6906 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4172 - accuracy: 0.8438 - val_loss: 0.6986 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4188 - accuracy: 0.8229 - val_loss: 0.7318 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.7524 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.3660 - accuracy: 0.8854 - val_loss: 0.7526 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.3251 - accuracy: 0.9271 - val_loss: 0.7968 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.3246 - accuracy: 0.9062 - val_loss: 0.8314 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.2993 - accuracy: 0.9479 - val_loss: 0.8460 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.2872 - accuracy: 0.9271 - val_loss: 0.8160 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.3024 - accuracy: 0.8750 - val_loss: 0.8105 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.2730 - accuracy: 0.9271 - val_loss: 0.8526 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.2600 - accuracy: 0.9375 - val_loss: 0.8571 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.2330 - accuracy: 0.9792 - val_loss: 0.8223 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.2324 - accuracy: 0.9688 - val_loss: 0.8780 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.2170 - accuracy: 0.9583 - val_loss: 0.8694 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.2056 - accuracy: 0.9792 - val_loss: 0.8152 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.1893 - accuracy: 0.9896 - val_loss: 0.8037 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.1793 - accuracy: 0.9792 - val_loss: 0.8496 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:48:29.189554: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f53aa3c5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.44      0.50        16\n",
      "         1.0       0.55      0.69      0.61        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.57      0.56      0.56        32\n",
      "weighted avg       0.57      0.56      0.56        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.0499 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 6.0499 - accuracy: 0.5104 - val_loss: 39.5606 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.7148 - accuracy: 0.5625 INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.7148 - accuracy: 0.5625 - val_loss: 7.9541 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.9023 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 3.9023 - accuracy: 0.5417 - val_loss: 2.8960 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 1.2110 - accuracy: 0.6562 - val_loss: 3.2526 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3545 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.3545 - accuracy: 0.6562 - val_loss: 2.1575 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.7292INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9502 - accuracy: 0.7292 - val_loss: 1.4738 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.7808 - accuracy: 0.7500 - val_loss: 1.8779 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.7917INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6499 - accuracy: 0.7917 - val_loss: 1.0949 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.6071 - accuracy: 0.7396 - val_loss: 0.9115 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.5546 - accuracy: 0.7812 - val_loss: 1.0041 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4571 - accuracy: 0.8125 - val_loss: 0.8607 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.4790 - accuracy: 0.7812 - val_loss: 0.8338 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.4376 - accuracy: 0.8125 - val_loss: 0.8422 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.7917INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3837 - accuracy: 0.7917 - val_loss: 0.8016 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.4220 - accuracy: 0.8125 - val_loss: 0.8367 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.6519 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.3855 - accuracy: 0.8229 - val_loss: 0.7387 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.3583 - accuracy: 0.8438 - val_loss: 0.8103 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.3515 - accuracy: 0.8125 - val_loss: 0.7251 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.3053 - accuracy: 0.8646 - val_loss: 0.7083 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.3526 - accuracy: 0.8438 - val_loss: 0.8197 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.3161 - accuracy: 0.8750 - val_loss: 0.7301 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.3036 - accuracy: 0.8750 - val_loss: 0.7609 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.2822 - accuracy: 0.8646 - val_loss: 0.7215 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.3071 - accuracy: 0.8646 - val_loss: 0.7779 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.3066 - accuracy: 0.8438 - val_loss: 0.6918 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.2477 - accuracy: 0.9062 - val_loss: 0.6953 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.2533 - accuracy: 0.9062 - val_loss: 0.7477 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.2655 - accuracy: 0.8854 - val_loss: 0.6578 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.2344 - accuracy: 0.9271 - val_loss: 0.7756 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.2796 - accuracy: 0.8750 - val_loss: 0.8144 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.2761 - accuracy: 0.8854 - val_loss: 0.8827 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.3412 - accuracy: 0.8229 - val_loss: 0.9695 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.2689 - accuracy: 0.8750 - val_loss: 0.7241 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.2223 - accuracy: 0.9271 - val_loss: 0.8883 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.2566 - accuracy: 0.9062 - val_loss: 0.8953 - val_accuracy: 0.7188 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:49:29.562480: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f53aa541160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.44      0.48        16\n",
      "         1.0       0.53      0.62      0.57        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.53        32\n",
      "weighted avg       0.53      0.53      0.53        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 1, 448, 16)       240       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 1, 112, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_13 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6982 - accuracy: 0.4792 - val_loss: 0.6907 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.5701 - accuracy: 0.7188 - val_loss: 0.6969 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8229INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 968ms/step - loss: 0.5106 - accuracy: 0.8229 - val_loss: 0.6827 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.4352 - accuracy: 0.8750 - val_loss: 0.6882 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.9062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3979 - accuracy: 0.9062 - val_loss: 0.6671 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.3602 - accuracy: 0.9271 - val_loss: 0.6815 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.3366 - accuracy: 0.8958 - val_loss: 0.6967 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.3108 - accuracy: 0.9271 - val_loss: 0.7135 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.9479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 940ms/step - loss: 0.2910 - accuracy: 0.9479 - val_loss: 0.6504 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.2808 - accuracy: 0.9583 - val_loss: 0.7060 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.2719 - accuracy: 0.9479 - val_loss: 0.7616 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.2363 - accuracy: 0.9792 - val_loss: 0.7472 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.2293 - accuracy: 0.9792 - val_loss: 0.7261 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2126 - accuracy: 0.9688 - val_loss: 0.7406 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2077 - accuracy: 0.9896 - val_loss: 0.7496 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.1811 - accuracy: 0.9792 - val_loss: 0.7722 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1766 - accuracy: 0.9792 - val_loss: 0.7622 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1733 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.1398 - accuracy: 0.9896 - val_loss: 0.7742 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.1593 - accuracy: 0.9896 - val_loss: 0.7899 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1357 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.8134 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.1172 - accuracy: 0.9896 - val_loss: 0.8720 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.1082 - accuracy: 0.9896 - val_loss: 0.8672 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:53:07.970241: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.56      0.58        16\n",
      "         1.0       0.59      0.62      0.61        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.59      0.59      0.59        32\n",
      "weighted avg       0.59      0.59      0.59        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.8941 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 4.8941 - accuracy: 0.5625 - val_loss: 47.4075 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.8204 - accuracy: 0.4583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.8204 - accuracy: 0.4583 - val_loss: 6.3047 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6895 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.6895 - accuracy: 0.6458 - val_loss: 1.4915 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8378 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8378 - accuracy: 0.6250 - val_loss: 1.0255 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7120 - accuracy: 0.6458 - val_loss: 0.9889 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.5968 - accuracy: 0.6979 - val_loss: 0.8914 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.6384 - accuracy: 0.6667 - val_loss: 1.7574 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.7806 - accuracy: 0.6771 - val_loss: 1.2635 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.8506 - accuracy: 0.7083 - val_loss: 1.8005 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.7395 - accuracy: 0.6562 - val_loss: 1.1173 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.9670 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.5610 - accuracy: 0.7188 - val_loss: 1.0946 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.5359 - accuracy: 0.6771 - val_loss: 1.1058 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.4998 - accuracy: 0.7292 - val_loss: 1.0560 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.5124 - accuracy: 0.7396 - val_loss: 1.0497 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.4568 - accuracy: 0.7917 - val_loss: 0.9854 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 1.3071 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.4261 - accuracy: 0.7500 - val_loss: 0.9068 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.5148 - accuracy: 0.7500 - val_loss: 1.0801 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4070 - accuracy: 0.7708 - val_loss: 0.9502 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.3802 - accuracy: 0.7812 - val_loss: 1.3543 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 1.0226 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.3704 - accuracy: 0.8229 - val_loss: 1.1525 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 1.2237 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.2985 - accuracy: 0.8646 - val_loss: 1.1292 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.3604 - accuracy: 0.8542 - val_loss: 1.3678 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:53:51.056290: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.38      0.43        16\n",
      "         1.0       0.50      0.62      0.56        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.49        32\n",
      "weighted avg       0.50      0.50      0.49        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthwi  (None, 1, 448, 16)       240       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_16 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 1, 112, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_17 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7614 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 959ms/step - loss: 0.7614 - accuracy: 0.4688 - val_loss: 0.6968 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6792 - accuracy: 0.5938 - val_loss: 0.6741 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.7604INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 942ms/step - loss: 0.5757 - accuracy: 0.7604 - val_loss: 0.6541 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 880ms/step - loss: 0.5132 - accuracy: 0.8021 - val_loss: 0.6533 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4503 - accuracy: 0.8646 - val_loss: 0.6769 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.4157 - accuracy: 0.8854 - val_loss: 0.7072 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.3854 - accuracy: 0.8646 - val_loss: 0.7413 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.3754 - accuracy: 0.8750 - val_loss: 0.7615 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.3466 - accuracy: 0.8958 - val_loss: 0.7740 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.3088 - accuracy: 0.9479 - val_loss: 0.7908 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.2728 - accuracy: 0.9479 - val_loss: 0.7912 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.2588 - accuracy: 0.9479 - val_loss: 0.7777 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.2651 - accuracy: 0.9375 - val_loss: 0.7846 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.2334 - accuracy: 0.9583 - val_loss: 0.7934 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.2226 - accuracy: 0.9688 - val_loss: 0.8466 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.1951 - accuracy: 0.9583 - val_loss: 0.8200 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.1920 - accuracy: 0.9688 - val_loss: 0.8113 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.1737 - accuracy: 0.9583 - val_loss: 0.8902 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.1667 - accuracy: 0.9688 - val_loss: 0.8668 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.1372 - accuracy: 0.9896 - val_loss: 0.9504 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.1137 - accuracy: 0.9896 - val_loss: 0.9343 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.1143 - accuracy: 0.9792 - val_loss: 0.9688 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:57:06.905788: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.81      0.70        16\n",
      "         1.0       0.73      0.50      0.59        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.67      0.66      0.65        32\n",
      "weighted avg       0.67      0.66      0.65        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.7659 - accuracy: 0.4479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 10.7659 - accuracy: 0.4479 - val_loss: 7.9251 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5406 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.5406 - accuracy: 0.5208 - val_loss: 1.1987 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 1.0087 - accuracy: 0.6146 - val_loss: 1.8269 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 1.1825 - accuracy: 0.5938 - val_loss: 2.9187 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 2.2419 - accuracy: 0.5104 - val_loss: 1.8355 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.9958 - accuracy: 0.5833 - val_loss: 1.7042 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9847 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.9847 - accuracy: 0.5938 - val_loss: 1.1376 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7368 - accuracy: 0.6562 - val_loss: 0.9332 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7677 - accuracy: 0.6458 - val_loss: 0.7338 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6617 - accuracy: 0.6875 - val_loss: 0.9431 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7175 - accuracy: 0.6875 - val_loss: 1.3271 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in0_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.7598 - accuracy: 0.6458 - val_loss: 0.6685 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.5277 - accuracy: 0.7396 - val_loss: 0.7942 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4610 - accuracy: 0.8229 - val_loss: 0.8532 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4774 - accuracy: 0.7812 - val_loss: 0.7239 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4904 - accuracy: 0.7604 - val_loss: 0.7819 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4524 - accuracy: 0.7917 - val_loss: 0.8322 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4456 - accuracy: 0.8125 - val_loss: 0.8894 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4066 - accuracy: 0.8750 - val_loss: 0.8434 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.8100 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.3821 - accuracy: 0.8333 - val_loss: 0.8309 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3210 - accuracy: 0.8958 - val_loss: 0.9009 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.3429 - accuracy: 0.8542 - val_loss: 0.9488 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.3107 - accuracy: 0.8750 - val_loss: 0.8519 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3048 - accuracy: 0.8854 - val_loss: 1.1361 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.2977 - accuracy: 0.8750 - val_loss: 1.2078 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.3365 - accuracy: 0.8438 - val_loss: 1.1195 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.3594 - accuracy: 0.8333 - val_loss: 1.1560 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.3452 - accuracy: 0.8438 - val_loss: 1.1664 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.2661 - accuracy: 0.8854 - val_loss: 1.0084 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.3062 - accuracy: 0.8542 - val_loss: 1.0618 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.2445 - accuracy: 0.8958 - val_loss: 1.0564 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:57:42.993021: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in0_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in0_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.81      0.67        16\n",
      "         1.0       0.67      0.38      0.48        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.62      0.59      0.57        32\n",
      "weighted avg       0.62      0.59      0.57        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  1\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_70 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_20 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_10 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_71 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_21 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6721 - accuracy: 0.6250 - val_loss: 0.7200 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.6875INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 931ms/step - loss: 0.5684 - accuracy: 0.6875 - val_loss: 0.6396 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 955ms/step - loss: 0.5177 - accuracy: 0.7083 - val_loss: 0.6326 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.7364 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3637 - accuracy: 0.8542 - val_loss: 0.6870 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.3108 - accuracy: 0.8958 - val_loss: 0.7356 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.2776 - accuracy: 0.9375 - val_loss: 0.7678 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.2422 - accuracy: 0.9375 - val_loss: 0.7830 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.2258 - accuracy: 0.9479 - val_loss: 0.8335 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.2044 - accuracy: 0.9688 - val_loss: 0.7332 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1696 - accuracy: 0.9792 - val_loss: 0.7472 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1694 - accuracy: 0.9792 - val_loss: 0.7869 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.1435 - accuracy: 0.9896 - val_loss: 0.8901 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.1396 - accuracy: 0.9688 - val_loss: 0.8225 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.1279 - accuracy: 0.9896 - val_loss: 0.8636 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1207 - accuracy: 0.9896 - val_loss: 0.8965 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.9332 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0986 - accuracy: 0.9896 - val_loss: 0.9405 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.0907 - accuracy: 0.9896 - val_loss: 0.9039 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.7500 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:00:30.406629: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.81      0.72        16\n",
      "         1.0       0.75      0.56      0.64        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.70      0.69      0.68        32\n",
      "weighted avg       0.70      0.69      0.68        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_74 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_75 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_76 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.4901 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 7.4901 - accuracy: 0.5312 - val_loss: 33.4667 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.6571 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.6571 - accuracy: 0.5521 - val_loss: 7.3148 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3914 - accuracy: 0.6146INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.3914 - accuracy: 0.6146 - val_loss: 0.5374 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.9738 - accuracy: 0.6979 - val_loss: 1.1536 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.7765 - accuracy: 0.6354 - val_loss: 0.7290 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.5471 - accuracy: 0.7604 - val_loss: 0.6311 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.5448 - accuracy: 0.7812 - val_loss: 0.6987 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4900 - accuracy: 0.7396 - val_loss: 0.6303 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.4233 - accuracy: 0.8125 - val_loss: 0.7072 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.3894 - accuracy: 0.8333 - val_loss: 0.7509 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.3667 - accuracy: 0.8438 - val_loss: 0.6294 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.3503 - accuracy: 0.8646 - val_loss: 0.9479 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4091 - accuracy: 0.8021 - val_loss: 0.4989 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4867 - accuracy: 0.7708 - val_loss: 0.9120 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.8542INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3092 - accuracy: 0.8542 - val_loss: 0.3829 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.2522 - accuracy: 0.9062 - val_loss: 0.3963 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1868 - accuracy: 0.9167 - val_loss: 0.5681 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1800 - accuracy: 0.9271 - val_loss: 0.4506 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.8854 - val_loss: 0.3224 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.1674 - accuracy: 0.9271 - val_loss: 0.4663 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1452 - accuracy: 0.9583 - val_loss: 0.5004 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1500 - accuracy: 0.9479 - val_loss: 0.5169 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1405 - accuracy: 0.9688 - val_loss: 0.5397 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1411 - accuracy: 0.9375 - val_loss: 0.7880 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0888 - accuracy: 0.9688 - val_loss: 0.4863 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0802 - accuracy: 0.9792 - val_loss: 0.4740 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0783 - accuracy: 0.9896 - val_loss: 0.5113 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0681 - accuracy: 0.9896 - val_loss: 0.5017 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0741 - accuracy: 0.9792 - val_loss: 0.5999 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1039 - accuracy: 0.9583 - val_loss: 0.5179 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1242 - accuracy: 0.9583 - val_loss: 0.4026 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1649 - accuracy: 0.9375 - val_loss: 0.5795 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1922 - accuracy: 0.9479 - val_loss: 0.8130 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1125 - accuracy: 0.9479 - val_loss: 0.5273 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.6449 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.4609 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0729 - accuracy: 0.9792 - val_loss: 0.4603 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8438 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:01:07.068787: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91        16\n",
      "         1.0       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.91      0.91      0.91        32\n",
      "weighted avg       0.91      0.91      0.91        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_12 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_24 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_12 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_86 (Bat  (None, 1, 112, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_25 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 982ms/step - loss: 0.6985 - accuracy: 0.5208 - val_loss: 0.6811 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5487 - accuracy: 0.6875 - val_loss: 0.6897 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.4031 - accuracy: 0.8958 - val_loss: 0.7476 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.3189 - accuracy: 0.9062 - val_loss: 0.7384 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.2783 - accuracy: 0.9271 - val_loss: 0.7843 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.2272 - accuracy: 0.9375 - val_loss: 1.1628 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.1928 - accuracy: 0.9375 - val_loss: 1.4096 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.1701 - accuracy: 0.9792 - val_loss: 1.5250 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.1378 - accuracy: 0.9688 - val_loss: 1.4675 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.1286 - accuracy: 0.9896 - val_loss: 1.3233 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.1074 - accuracy: 0.9896 - val_loss: 1.3078 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.1057 - accuracy: 0.9896 - val_loss: 1.4912 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.0910 - accuracy: 0.9896 - val_loss: 1.5448 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.0843 - accuracy: 0.9896 - val_loss: 1.4373 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 1.3634 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.0746 - accuracy: 0.9896 - val_loss: 1.2914 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:04:59.465398: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.69      0.58        16\n",
      "         1.0       0.50      0.31      0.38        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.48        32\n",
      "weighted avg       0.50      0.50      0.48        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 1, 444, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_88 (Activation)  (None, 1, 444, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 1, 218, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_89 (Activation)  (None, 1, 218, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 1, 105, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_90 (Activation)  (None, 1, 105, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 1, 48, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_91 (Activation)  (None, 1, 48, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_92 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.4844 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 10.4844 - accuracy: 0.5417 - val_loss: 14.3546 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.4217 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 7.4217 - accuracy: 0.5312 - val_loss: 3.5750 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8604 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.8604 - accuracy: 0.4688 - val_loss: 1.4565 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 1.3443 - accuracy: 0.6250 - val_loss: 1.8994 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8492 - accuracy: 0.7292INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8492 - accuracy: 0.7292 - val_loss: 0.9635 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6875INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6416 - accuracy: 0.6875 - val_loss: 0.8272 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.5934 - accuracy: 0.7188 - val_loss: 0.9178 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.6256 - accuracy: 0.6979 - val_loss: 0.8415 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.5824 - accuracy: 0.7292 - val_loss: 1.4847 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.6208 - accuracy: 0.7188 - val_loss: 1.5116 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.7577 - accuracy: 0.6771 - val_loss: 1.0081 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.8862 - accuracy: 0.6667 - val_loss: 1.5949 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.7223 - accuracy: 0.6875 - val_loss: 1.2025 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.6079 - accuracy: 0.7812 - val_loss: 1.4773 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 1.0631 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4755 - accuracy: 0.8021 - val_loss: 1.3686 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.3742 - accuracy: 0.8333 - val_loss: 1.0791 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4122 - accuracy: 0.8125 - val_loss: 1.1013 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.3840 - accuracy: 0.8229 - val_loss: 1.0627 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.3630 - accuracy: 0.8333 - val_loss: 1.1397 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.3298 - accuracy: 0.8750 - val_loss: 1.0118 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3384 - accuracy: 0.8542 - val_loss: 0.9902 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4090 - accuracy: 0.7812 - val_loss: 1.2025 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.3493 - accuracy: 0.8542 - val_loss: 1.0879 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.3539 - accuracy: 0.8229 - val_loss: 1.2549 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2914 - accuracy: 0.8854 - val_loss: 1.0174 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:05:29.993501: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.19      0.29        16\n",
      "         1.0       0.52      0.88      0.65        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.56      0.53      0.47        32\n",
      "weighted avg       0.56      0.53      0.47        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 15, 448, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_14 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  (None, 1, 448, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_98 (Activation)  (None, 1, 448, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_28 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_14 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_99 (Activation)  (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_29 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6623 - accuracy: 0.5625 - val_loss: 0.6798 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5819 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 966ms/step - loss: 0.5819 - accuracy: 0.6667 - val_loss: 0.6247 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4795 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 992ms/step - loss: 0.3755 - accuracy: 0.8854 - val_loss: 0.5303 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 953ms/step - loss: 0.3143 - accuracy: 0.9167 - val_loss: 0.5152 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.2795 - accuracy: 0.9167 - val_loss: 0.5271 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.2392 - accuracy: 0.9271 - val_loss: 0.6225 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.2109 - accuracy: 0.9375 - val_loss: 0.5687 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.1817 - accuracy: 0.9688 - val_loss: 0.5331 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.1501 - accuracy: 0.9688 - val_loss: 0.6233 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.1322 - accuracy: 0.9896 - val_loss: 0.5953 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.1354 - accuracy: 0.9688 - val_loss: 0.5429 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1195 - accuracy: 0.9896 - val_loss: 0.5549 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.4504 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0845 - accuracy: 0.9896 - val_loss: 0.5057 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0895 - accuracy: 0.9896 - val_loss: 0.6514 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0926 - accuracy: 0.9896 - val_loss: 0.6236 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 919ms/step - loss: 0.0792 - accuracy: 0.9896 - val_loss: 0.3639 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 926ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0632 - accuracy: 0.9896 - val_loss: 0.4191 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 867ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 856ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 901ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:10:26.529393: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.88      0.82        16\n",
      "         1.0       0.86      0.75      0.80        16\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.82      0.81      0.81        32\n",
      "weighted avg       0.82      0.81      0.81        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_104 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_102 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_105 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_103 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_104 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_105 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_106 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.3437 - accuracy: 0.4375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 8.3437 - accuracy: 0.4375 - val_loss: 34.5428 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 11.0482 - accuracy: 0.4167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 11.0482 - accuracy: 0.4167 - val_loss: 14.8226 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.9588 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.9588 - accuracy: 0.5208 - val_loss: 1.7963 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9612 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.9612 - accuracy: 0.5312 - val_loss: 1.3959 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7533 - accuracy: 0.6979 - val_loss: 0.9863 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7487 - accuracy: 0.6667 - val_loss: 1.1226 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.7247 - accuracy: 0.6979 - val_loss: 1.1568 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5526 - accuracy: 0.7396 - val_loss: 0.7138 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.5865 - accuracy: 0.6875 - val_loss: 0.8429 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4946 - accuracy: 0.7292 - val_loss: 0.8406 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4888 - accuracy: 0.8021 - val_loss: 0.8414 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4861 - accuracy: 0.7604 - val_loss: 0.7244 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.8257 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.7917INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3966 - accuracy: 0.7917 - val_loss: 0.6400 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4223 - accuracy: 0.8125 - val_loss: 0.7337 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4165 - accuracy: 0.8333 - val_loss: 0.7342 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3676 - accuracy: 0.8229 - val_loss: 0.7670 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.2881 - accuracy: 0.8750 - val_loss: 0.8195 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.3549 - accuracy: 0.8542 - val_loss: 0.6882 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3863 - accuracy: 0.8229 - val_loss: 0.8662 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3989 - accuracy: 0.8542 - val_loss: 0.7306 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3313 - accuracy: 0.8125 - val_loss: 0.6783 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.2506 - accuracy: 0.8750 - val_loss: 0.6909 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.2628 - accuracy: 0.9271 - val_loss: 0.6614 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2558 - accuracy: 0.8958 - val_loss: 0.7603 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.2140 - accuracy: 0.9062 - val_loss: 0.8007 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.2391 - accuracy: 0.8958 - val_loss: 0.8814 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1983 - accuracy: 0.9062 - val_loss: 0.9155 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.2159 - accuracy: 0.9062 - val_loss: 0.7430 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2055 - accuracy: 0.9167 - val_loss: 0.6747 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1767 - accuracy: 0.9271 - val_loss: 0.9338 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.1981 - accuracy: 0.9375 - val_loss: 0.8629 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1484 - accuracy: 0.9375 - val_loss: 0.7048 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.1448 - accuracy: 0.9688 - val_loss: 0.8133 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:11:04.867732: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.56        16\n",
      "         1.0       0.50      0.38      0.43        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.49        32\n",
      "weighted avg       0.50      0.50      0.49        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_112 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_16 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_113 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_112 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_32 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_16 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_114 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_113 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_33 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 0.6674 - accuracy: 0.5729 - val_loss: 0.6089 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5674 - accuracy: 0.7083 - val_loss: 0.4253 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.6543 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.3983 - accuracy: 0.8542 - val_loss: 0.6730 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.3337 - accuracy: 0.8750 - val_loss: 0.7468 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.2873 - accuracy: 0.9062 - val_loss: 1.0263 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.2453 - accuracy: 0.9375 - val_loss: 1.4049 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.2165 - accuracy: 0.9375 - val_loss: 1.6922 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.1905 - accuracy: 0.9375 - val_loss: 1.8954 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1606 - accuracy: 0.9896 - val_loss: 2.3561 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1419 - accuracy: 1.0000 - val_loss: 2.2741 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.1498 - accuracy: 0.9896 - val_loss: 1.7958 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1280 - accuracy: 0.9896 - val_loss: 1.5102 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1047 - accuracy: 0.9896 - val_loss: 1.3421 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1482 - accuracy: 0.9688 - val_loss: 0.8852 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0910 - accuracy: 0.9792 - val_loss: 0.8429 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.8557 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0940 - accuracy: 0.9792 - val_loss: 0.7004 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0728 - accuracy: 0.9896 - val_loss: 0.6389 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.8438 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:14:27.824812: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.69      0.67        16\n",
      "         1.0       0.67      0.62      0.65        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.66      0.66      0.66        32\n",
      "weighted avg       0.66      0.66      0.66        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_118 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_116 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_119 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_117 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_120 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_118 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_121 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_119 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_120 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.9236 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.9236 - accuracy: 0.5417 - val_loss: 4.8634 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0148 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.0148 - accuracy: 0.5208 - val_loss: 4.7464 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.1153 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.1153 - accuracy: 0.5417 - val_loss: 3.4260 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.9136 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.9136 - accuracy: 0.4688 - val_loss: 0.7026 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 1.3973 - accuracy: 0.6771 - val_loss: 1.2261 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6832 - accuracy: 0.7812 - val_loss: 0.5532 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.5157 - accuracy: 0.7500 - val_loss: 0.7073 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4316 - accuracy: 0.8125 - val_loss: 0.4894 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8229INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.4224 - accuracy: 0.8229 - val_loss: 0.4881 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3406 - accuracy: 0.8125 - val_loss: 0.4611 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3571 - accuracy: 0.8125 - val_loss: 0.5569 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.3510 - accuracy: 0.8750 - val_loss: 0.4654 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2791 - accuracy: 0.9062 - val_loss: 0.5213 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.2765 - accuracy: 0.8750 - val_loss: 0.4748 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.2448 - accuracy: 0.8854 - val_loss: 0.6227 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1875 - accuracy: 0.9479 - val_loss: 0.5470 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2283 - accuracy: 0.9271 - val_loss: 0.9131 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1964 - accuracy: 0.9375 - val_loss: 0.6223 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.2209 - accuracy: 0.8958 - val_loss: 0.6187 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1899 - accuracy: 0.9479 - val_loss: 0.7091 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1242 - accuracy: 0.9688 - val_loss: 0.5907 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0893 - accuracy: 0.9792 - val_loss: 0.5363 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1434 - accuracy: 0.9583 - val_loss: 0.9077 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1683 - accuracy: 0.9479 - val_loss: 0.5840 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1783 - accuracy: 0.9271 - val_loss: 0.8222 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.1258 - accuracy: 0.9375 - val_loss: 0.6008 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.1056 - accuracy: 0.9479 - val_loss: 0.6730 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0749 - accuracy: 0.9792 - val_loss: 0.4676 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0680 - accuracy: 0.9688 - val_loss: 0.4605 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0803 - accuracy: 0.9688 - val_loss: 0.6106 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1156 - accuracy: 0.9479 - val_loss: 0.5162 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1044 - accuracy: 0.9583 - val_loss: 0.5586 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1637 - accuracy: 0.9167 - val_loss: 0.5372 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0857 - accuracy: 0.9583 - val_loss: 0.4847 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0727 - accuracy: 0.9792 - val_loss: 0.5225 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0458 - accuracy: 0.9896 - val_loss: 0.5666 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0422 - accuracy: 0.9792 - val_loss: 0.4910 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0507 - accuracy: 0.9896 - val_loss: 0.5509 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0253 - accuracy: 0.9896 - val_loss: 0.5974 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.8684 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.8456 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0462 - accuracy: 0.9792 - val_loss: 1.1856 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1168 - accuracy: 0.9583 - val_loss: 0.4105 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1140 - accuracy: 0.9271 - val_loss: 0.7568 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0948 - accuracy: 0.9688 - val_loss: 0.5695 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0850 - accuracy: 0.9688 - val_loss: 0.2428 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0564 - accuracy: 0.9688 - val_loss: 0.3186 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0432 - accuracy: 0.9896 - val_loss: 0.4256 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0463 - accuracy: 0.9896 - val_loss: 0.3178 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0520 - accuracy: 0.9896 - val_loss: 0.3093 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 8.6280e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0136 - accuracy: 0.9896 - val_loss: 0.2149 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.0188 - accuracy: 0.9896 - val_loss: 0.4307 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0191 - accuracy: 0.9896 - val_loss: 0.6211 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.4913 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.3527 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0172 - accuracy: 0.9896 - val_loss: 0.4120 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.8750 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:15:55.433975: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.81      0.84        16\n",
      "         1.0       0.82      0.88      0.85        16\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.84      0.84        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_126 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_18 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_127 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_126 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_36 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_18 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_128 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_127 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_37 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7332 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 928ms/step - loss: 0.7332 - accuracy: 0.5000 - val_loss: 0.6598 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.6045 - accuracy: 0.6667 - val_loss: 0.6725 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.4551 - accuracy: 0.8229 - val_loss: 0.7404 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.3384 - accuracy: 0.9375 - val_loss: 0.8232 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.3056 - accuracy: 0.9271 - val_loss: 1.5362 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.2422 - accuracy: 0.9583 - val_loss: 2.5407 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.2083 - accuracy: 0.9479 - val_loss: 3.4265 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.1701 - accuracy: 0.9688 - val_loss: 3.8760 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.1645 - accuracy: 0.9896 - val_loss: 3.4180 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 3.0699 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.1226 - accuracy: 0.9688 - val_loss: 2.9783 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 2.8346 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.0846 - accuracy: 0.9792 - val_loss: 2.3240 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.0935 - accuracy: 0.9896 - val_loss: 1.6264 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.0758 - accuracy: 0.9896 - val_loss: 1.4105 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 1.4772 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.5373 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.4462 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:19:46.327804: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.81      0.68        16\n",
      "         1.0       0.70      0.44      0.54        16\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.65      0.62      0.61        32\n",
      "weighted avg       0.65      0.62      0.61        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_132 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_130 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_133 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_131 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_134 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_132 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_135 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_133 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_134 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.6863 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.6863 - accuracy: 0.5625 - val_loss: 10.0192 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 7.8755 - accuracy: 0.5417 - val_loss: 18.2417 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.3683 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.3683 - accuracy: 0.5312 - val_loss: 2.1913 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9144 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9144 - accuracy: 0.6250 - val_loss: 0.8598 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.6354INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7657 - accuracy: 0.6354 - val_loss: 0.8289 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.7188INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6605 - accuracy: 0.7188 - val_loss: 0.5925 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.6648 - accuracy: 0.6771 - val_loss: 0.5934 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.6012 - accuracy: 0.7083 - val_loss: 1.2788 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.6918 - accuracy: 0.6562 - val_loss: 0.7708 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 135ms/step - loss: 0.6955 - accuracy: 0.6354 - val_loss: 1.0713 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.5504 - accuracy: 0.7188 - val_loss: 0.6663 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4998 - accuracy: 0.7604 - val_loss: 0.6023 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.7500INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4778 - accuracy: 0.7500 - val_loss: 0.5874 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5002 - accuracy: 0.8021 - val_loss: 0.5315 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4390 - accuracy: 0.7396 - val_loss: 0.4795 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.3429 - accuracy: 0.8750 - val_loss: 0.4944 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8646INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3304 - accuracy: 0.8646 - val_loss: 0.3809 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.2998 - accuracy: 0.8542 - val_loss: 0.4787 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1962 - accuracy: 0.9375 - val_loss: 0.3415 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1801 - accuracy: 0.9479 - val_loss: 0.5837 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3030 - accuracy: 0.8750 - val_loss: 0.4415 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.2677 - accuracy: 0.8750 - val_loss: 0.8340 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.2440 - accuracy: 0.8958 - val_loss: 0.5642 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2021 - accuracy: 0.9167 - val_loss: 0.3106 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.1333 - accuracy: 0.9688 - val_loss: 0.4040 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1253 - accuracy: 0.9583 - val_loss: 0.3736 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in1_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1134 - accuracy: 0.9688 - val_loss: 0.3019 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0594 - accuracy: 0.9896 - val_loss: 0.4003 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.0606 - accuracy: 0.9896 - val_loss: 0.4307 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0422 - accuracy: 0.9896 - val_loss: 0.4461 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0854 - accuracy: 0.9792 - val_loss: 0.5153 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.5201 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0500 - accuracy: 0.9896 - val_loss: 0.4840 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.0389 - accuracy: 0.9896 - val_loss: 0.4609 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 0.5920 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0475 - accuracy: 0.9792 - val_loss: 0.4955 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0490 - accuracy: 0.9792 - val_loss: 0.5260 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0422 - accuracy: 0.9896 - val_loss: 0.5133 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0654 - accuracy: 0.9896 - val_loss: 0.4523 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.7483 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.6118 - val_accuracy: 0.7812 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:21:10.933016: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in1_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.75      0.77        16\n",
      "         1.0       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.78      0.78        32\n",
      "weighted avg       0.78      0.78      0.78        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  2\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_140 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_20 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_141 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_140 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_40 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_20 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_142 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_141 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_41 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6934 - accuracy: 0.5521 - val_loss: 0.5987 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7292INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 0.5474 - accuracy: 0.7292 - val_loss: 0.4680 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8542INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 888ms/step - loss: 0.3952 - accuracy: 0.8542 - val_loss: 0.4343 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.3324 - accuracy: 0.8438 - val_loss: 0.5207 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.2629 - accuracy: 0.8750 - val_loss: 0.5099 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.2349 - accuracy: 0.9375 - val_loss: 0.6656 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.2073 - accuracy: 0.9479 - val_loss: 0.6946 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.2124 - accuracy: 0.9167 - val_loss: 0.9671 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.1787 - accuracy: 0.9479 - val_loss: 0.7738 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1524 - accuracy: 0.9792 - val_loss: 0.8718 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1493 - accuracy: 0.9688 - val_loss: 0.8153 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.1348 - accuracy: 0.9688 - val_loss: 0.8045 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.1399 - accuracy: 0.9479 - val_loss: 0.8998 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.1130 - accuracy: 0.9896 - val_loss: 0.9524 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.8618 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.8411 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.0935 - accuracy: 0.9896 - val_loss: 0.7641 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0774 - accuracy: 0.9792 - val_loss: 0.7569 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0924 - accuracy: 0.9688 - val_loss: 0.7463 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.8438 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:25:08.969894: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.81      0.76        16\n",
      "         1.0       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.75      0.75      0.75        32\n",
      "weighted avg       0.75      0.75      0.75        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_146 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_144 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_147 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_145 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_148 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_146 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_149 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_147 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_148 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.1606 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 5.1606 - accuracy: 0.5417 - val_loss: 1.6799 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 7.2188 - accuracy: 0.4896 - val_loss: 4.4008 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 4.6595 - accuracy: 0.5104 - val_loss: 2.5271 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1881 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.1881 - accuracy: 0.6979 - val_loss: 0.2517 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.5517 - accuracy: 0.8229 - val_loss: 0.3336 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.4076 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3730 - accuracy: 0.8438 - val_loss: 0.2655 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3301 - accuracy: 0.8229 - val_loss: 0.3364 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2531 - accuracy: 0.8854 - val_loss: 0.2790 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.2097 - accuracy: 0.9271 - val_loss: 0.3063 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1507 - accuracy: 0.9479 - val_loss: 0.2681 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1303 - accuracy: 0.9583 - val_loss: 0.2195 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.0880 - accuracy: 0.9792 - val_loss: 0.2785 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.0744 - accuracy: 0.9896 - val_loss: 0.3788 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0779 - accuracy: 0.9792 - val_loss: 0.1200 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: 0.3602 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0467 - accuracy: 0.9896 - val_loss: 0.1658 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0209 - accuracy: 0.9896 - val_loss: 0.1266 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.0146 - accuracy: 0.9896 - val_loss: 0.2709 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.2988 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0218 - accuracy: 0.9896 - val_loss: 0.0805 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.1453 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0166 - accuracy: 0.9896 - val_loss: 0.0813 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0287 - accuracy: 0.9792 - val_loss: 0.1598 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.0650e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 5.6473e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 6.5380e-04 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.7511e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 5.5032e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 4.0344e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4789e-04 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.8505e-04 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.7575e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.3653e-04 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.6095e-04 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.1561e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 7.3682e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.7609e-04 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 5.5914e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.6566e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.2046e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:26:01.647436: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        16\n",
      "         1.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_154 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_22 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_155 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_154 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_44 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_22 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_156 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_155 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_45 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7158 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 914ms/step - loss: 0.7158 - accuracy: 0.5208 - val_loss: 0.6216 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5080 - accuracy: 0.8125 - val_loss: 0.4514 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 913ms/step - loss: 0.3646 - accuracy: 0.8958 - val_loss: 0.3766 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3067 - accuracy: 0.8958 - val_loss: 0.5299 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.2717 - accuracy: 0.8958 - val_loss: 0.3647 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.2421 - accuracy: 0.9271 - val_loss: 0.3771 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.2324 - accuracy: 0.9375 - val_loss: 0.3938 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1900 - accuracy: 0.9688 - val_loss: 0.5554 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.1745 - accuracy: 0.9583 - val_loss: 0.5557 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1567 - accuracy: 0.9688 - val_loss: 0.5603 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.1321 - accuracy: 0.9896 - val_loss: 0.4444 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1115 - accuracy: 0.9896 - val_loss: 0.4641 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0625 - accuracy: 0.9896 - val_loss: 0.5597 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0648 - accuracy: 0.9896 - val_loss: 0.5037 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0597 - accuracy: 0.9896 - val_loss: 0.5267 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.8125 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:29:38.490399: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.81      0.81        16\n",
      "         1.0       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.81      0.81      0.81        32\n",
      "weighted avg       0.81      0.81      0.81        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_160 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_158 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_161 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_159 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_162 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_160 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_163 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_161 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_162 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.5376 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 6.5376 - accuracy: 0.5000 - val_loss: 45.6710 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.7009 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 7.7009 - accuracy: 0.5833 - val_loss: 10.3723 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.1296 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.1296 - accuracy: 0.5833 - val_loss: 1.4212 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0069 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.0069 - accuracy: 0.5417 - val_loss: 1.3654 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9560 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9560 - accuracy: 0.6562 - val_loss: 1.2138 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.6771INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6425 - accuracy: 0.6771 - val_loss: 0.7909 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6106 - accuracy: 0.6667 - val_loss: 0.7402 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5550 - accuracy: 0.7396 - val_loss: 0.7364 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.7917INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.6601 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4165 - accuracy: 0.8229 - val_loss: 0.6683 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3387 - accuracy: 0.8438 - val_loss: 0.7395 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3163 - accuracy: 0.8646 - val_loss: 0.7694 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3048 - accuracy: 0.8646 - val_loss: 0.6961 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2325 - accuracy: 0.9062 - val_loss: 0.5955 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1662 - accuracy: 0.9792 - val_loss: 0.5823 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1527 - accuracy: 0.9583 - val_loss: 0.3055 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.1537 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0502 - accuracy: 0.9792 - val_loss: 0.0654 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.0664 - accuracy: 0.9896 - val_loss: 0.1462 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0345 - accuracy: 0.9792 - val_loss: 0.0548 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.0919 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0128 - accuracy: 0.9896 - val_loss: 0.0355 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000  INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.7014e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 6.5306e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 5.8504e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 8.5965e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.6949e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 3.5376e-04 - accuracy: 1.0000 - val_loss: 9.6044e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 7.8367e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 8.2538e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 8.9190e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 6.6541e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000  INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.8850e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 6.3094e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 9.0673e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 7.0088e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 6.1886e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 4.2549e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 6.6107e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 1.8015e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 4.0911e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 1.7183e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 2.2049e-04 - accuracy: 1.0000 - val_loss: 7.5695e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2.7103e-04 - accuracy: 1.0000 - val_loss: 7.7906e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 7.5950e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7229e-04 - accuracy: 1.0000 - val_loss: 5.8270e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 6.5329e-04 - accuracy: 1.0000 - val_loss: 6.7902e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.2889e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.7016e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.5500e-04 - accuracy: 1.0000 - val_loss: 9.2506e-04 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 3.3332e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:32:02.409787: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        16\n",
      "         1.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_168 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_24 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_169 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_168 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_48 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_24 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_170 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_169 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_49 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.7289 - accuracy: 0.5104 - val_loss: 0.6181 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.4857 - accuracy: 0.8021 - val_loss: 0.5227 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.3737 - accuracy: 0.8750 - val_loss: 0.8343 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.2956 - accuracy: 0.8958 - val_loss: 1.1740 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.2504 - accuracy: 0.9271 - val_loss: 1.1145 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.1899 - accuracy: 0.9375 - val_loss: 0.9246 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.1598 - accuracy: 0.9792 - val_loss: 0.9387 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.1445 - accuracy: 0.9792 - val_loss: 0.9286 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.1321 - accuracy: 0.9792 - val_loss: 0.9431 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.1122 - accuracy: 0.9792 - val_loss: 0.9849 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.1059 - accuracy: 0.9688 - val_loss: 0.9565 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.0890 - accuracy: 0.9896 - val_loss: 0.8070 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.0622 - accuracy: 0.9896 - val_loss: 0.9214 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.7812 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:35:49.195126: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.81      0.79        16\n",
      "         1.0       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.78      0.78        32\n",
      "weighted avg       0.78      0.78      0.78        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_174 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_172 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 1, 222, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_175 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_173 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 1, 109, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_176 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_174 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 1, 52, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_150 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_177 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_175 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 1, 24, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_176 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 12.5337 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 12.5337 - accuracy: 0.4688 - val_loss: 6.1106 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 4.9113 - accuracy: 0.4583 - val_loss: 13.7172 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.7258 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.7258 - accuracy: 0.5938 - val_loss: 2.7696 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7898 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.7898 - accuracy: 0.5833 - val_loss: 0.6825 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.8314 - accuracy: 0.6771 - val_loss: 0.8219 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4756 - accuracy: 0.7292 - val_loss: 0.9691 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.8242 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.8750INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3137 - accuracy: 0.8750 - val_loss: 0.5928 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2856 - accuracy: 0.8958 - val_loss: 0.4593 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2337 - accuracy: 0.8854 - val_loss: 0.4431 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1527 - accuracy: 0.9167 - val_loss: 0.4211 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1140 - accuracy: 0.9583 - val_loss: 0.3547 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0841 - accuracy: 0.9896 - val_loss: 0.2956 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9896 - val_loss: 0.2780 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.1544 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.0391 - accuracy: 0.9896 - val_loss: 0.1797 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.1767 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 9.1843e-04 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 9.6197e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 8.3837e-04 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 8.9944e-04 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 6.0493e-04 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 9.3396e-04 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 7.2693e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.5548e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 7.5548e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 7.4821e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 8.2057e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 7.5437e-04 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.8658e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.8658e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 6.9808e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.6554e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 7.6554e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 8.2842e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.9327e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 8.9327e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 8.1625e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 9.0207e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 6.3029e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 8.2019e-04 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 6.3570e-04 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.1616e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.1616e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.9098e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.9098e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 5.4956e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 3.1375e-04 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.2249e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 7.2249e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.5687e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 4.5687e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.0149e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 5.0149e-04 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.3098e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.2737e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.3342e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 3.7360e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 6.0565e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 8.5575e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 4.4500e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9521e-04 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 2.9254e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 7.8439e-04 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 8.5772e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.1291e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.4998e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8161e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.8161e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 4.3447e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.4701e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.2561e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.7090e-04 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.3802e-04 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.0414e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.1578e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.1578e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.6543e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.6543e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 2.1034e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 9.6189e-04 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.6840e-04 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.7189e-04 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 5.8925e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.9754e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.5466e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.6049e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.8971e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3831e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1685e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.1224e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.3088e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.1528e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 2.5080e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.4574e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 5.4574e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 8.4269e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 2.3972e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.6052e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.1909e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 5.2702e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.7600e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 1.9170e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.0450e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 3.8939e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.4401e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 6.8982e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 3.1313e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 2.7067e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 1.4320e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.4479e-04 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 5.7287e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.2379e-04 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 9.6083e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:38:48.298474: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        16\n",
      "         1.0       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_156 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_182 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_26 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_183 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_182 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_52 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_26 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_184 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_183 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_53 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7072 - accuracy: 0.5208 - val_loss: 0.7074 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 0.5280 - accuracy: 0.7396 - val_loss: 0.4342 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3933 - accuracy: 0.8542 - val_loss: 0.5816 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3518 - accuracy: 0.8646 - val_loss: 0.6222 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.3421 - accuracy: 0.9062 - val_loss: 0.5743 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.2702 - accuracy: 0.9271 - val_loss: 1.0129 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.2459 - accuracy: 0.9375 - val_loss: 0.8150 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.2270 - accuracy: 0.9479 - val_loss: 0.7535 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.2177 - accuracy: 0.9688 - val_loss: 0.8147 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1755 - accuracy: 0.9896 - val_loss: 0.8082 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.1765 - accuracy: 0.9688 - val_loss: 0.8336 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 276ms/step - loss: 0.1404 - accuracy: 0.9896 - val_loss: 0.7298 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.1283 - accuracy: 0.9896 - val_loss: 0.7629 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.1103 - accuracy: 0.9792 - val_loss: 0.8041 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.1078 - accuracy: 0.9896 - val_loss: 0.6981 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0949 - accuracy: 0.9896 - val_loss: 0.6128 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.0685 - accuracy: 0.9896 - val_loss: 0.6553 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.7812 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:42:52.421402: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.81      0.76        16\n",
      "         1.0       0.79      0.69      0.73        16\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.75      0.75      0.75        32\n",
      "weighted avg       0.75      0.75      0.75        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_188 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_186 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_104 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_160 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_189 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_187 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_190 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_188 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_162 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_191 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_189 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_190 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.7288 - accuracy: 0.4375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 7.7288 - accuracy: 0.4375 - val_loss: 49.2856 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.9526 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.9526 - accuracy: 0.5521 - val_loss: 9.0373 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8842 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.8842 - accuracy: 0.5208 - val_loss: 2.4635 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.2724 - accuracy: 0.3750INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.2724 - accuracy: 0.3750 - val_loss: 1.3936 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9251 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.9251 - accuracy: 0.5417 - val_loss: 0.9247 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.1292 - accuracy: 0.4583 - val_loss: 0.9854 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7736 - accuracy: 0.3854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7736 - accuracy: 0.3854 - val_loss: 0.7246 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.8315 - accuracy: 0.3646 - val_loss: 0.8371 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7138 - accuracy: 0.5312 - val_loss: 0.7030 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.6850 - accuracy: 0.5521 - val_loss: 0.7143 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.6784 - accuracy: 0.5833 - val_loss: 0.8174 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6703 - accuracy: 0.5417 - val_loss: 0.6731 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.6771INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6456 - accuracy: 0.6771 - val_loss: 0.6540 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.6051 - accuracy: 0.6562 - val_loss: 0.6696 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5763 - accuracy: 0.6562 - val_loss: 0.5432 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.5296 - accuracy: 0.7604 - val_loss: 0.5823 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4911 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4263 - accuracy: 0.8333 - val_loss: 0.5594 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.3685 - accuracy: 0.8646 - val_loss: 0.6049 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.3259 - accuracy: 0.8750 - val_loss: 0.6125 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.2735 - accuracy: 0.8854 - val_loss: 0.6267 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.2428 - accuracy: 0.8958 - val_loss: 0.6590 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.2260 - accuracy: 0.9062 - val_loss: 0.5260 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.1727 - accuracy: 0.9583 - val_loss: 0.5896 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.1549 - accuracy: 0.9792 - val_loss: 0.6456 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1171 - accuracy: 0.9792 - val_loss: 0.6723 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.1092 - accuracy: 0.9583 - val_loss: 0.5881 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.1356 - accuracy: 0.9479 - val_loss: 0.6666 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1714 - accuracy: 0.9271 - val_loss: 0.5243 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0852 - accuracy: 0.9792 - val_loss: 0.9104 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0816 - accuracy: 0.9896 - val_loss: 0.7315 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0960 - accuracy: 0.9583 - val_loss: 0.7645 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0885 - accuracy: 0.9792 - val_loss: 0.8316 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1000 - accuracy: 0.9583 - val_loss: 0.6809 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0904 - accuracy: 0.9583 - val_loss: 0.7775 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.1071 - accuracy: 0.9688 - val_loss: 0.5354 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8125 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:43:50.132197: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.88      0.80        16\n",
      "         1.0       0.85      0.69      0.76        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.79      0.78      0.78        32\n",
      "weighted avg       0.79      0.78      0.78        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_196 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_28 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_197 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_196 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_56 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_28 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_198 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_197 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_57 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6980 - accuracy: 0.5625 - val_loss: 0.6603 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.4342 - accuracy: 0.8229 - val_loss: 0.7739 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.3022 - accuracy: 0.9167 - val_loss: 1.1286 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.2729 - accuracy: 0.8750 - val_loss: 1.4956 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.2138 - accuracy: 0.9479 - val_loss: 1.7387 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.1802 - accuracy: 0.9479 - val_loss: 1.7349 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.1389 - accuracy: 0.9688 - val_loss: 1.7186 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.1278 - accuracy: 0.9792 - val_loss: 2.1507 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.1186 - accuracy: 0.9688 - val_loss: 1.8481 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.5740 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0898 - accuracy: 0.9896 - val_loss: 1.4646 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0810 - accuracy: 0.9896 - val_loss: 1.8879 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0789 - accuracy: 0.9896 - val_loss: 1.5170 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 1.7515 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.6569 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.0635 - accuracy: 0.9896 - val_loss: 1.6661 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.6331 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 1.6332 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 1.6038 - val_accuracy: 0.7188 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:47:00.613260: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.94      0.71        16\n",
      "         1.0       0.83      0.31      0.45        16\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.71      0.62      0.58        32\n",
      "weighted avg       0.71      0.62      0.58        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_202 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_200 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_112 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_203 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_201 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_113 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_204 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_202 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_114 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_205 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_203 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_204 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.9559 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 9.9559 - accuracy: 0.4792 - val_loss: 1.1049 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 8.0899 - accuracy: 0.4792 - val_loss: 3.4774 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8733 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.8733 - accuracy: 0.6250 - val_loss: 1.0149 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.7292INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6959 - accuracy: 0.7292 - val_loss: 0.5593 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4236 - accuracy: 0.8229 - val_loss: 0.8744 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.8377 - accuracy: 0.6354 - val_loss: 0.9850 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5861 - accuracy: 0.6875 - val_loss: 1.5607 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6326 - accuracy: 0.7917 - val_loss: 1.0293 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5219 - accuracy: 0.7917 - val_loss: 0.8099 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3268 - accuracy: 0.8229 - val_loss: 0.6118 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.3076 - accuracy: 0.8750 - val_loss: 0.6316 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2487 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.9167 - val_loss: 0.3755 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2084 - accuracy: 0.9062 - val_loss: 0.3522 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1979 - accuracy: 0.9062 - val_loss: 0.2602 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2307 - accuracy: 0.8958 - val_loss: 0.3754 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.1680 - accuracy: 0.9583 - val_loss: 0.3690 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1361 - accuracy: 0.9375 - val_loss: 0.4428 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.1318 - accuracy: 0.9375 - val_loss: 0.3217 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.1207 - accuracy: 0.9688 - val_loss: 0.3622 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.1358 - accuracy: 0.9583 - val_loss: 0.3384 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0844 - accuracy: 0.9792 - val_loss: 0.6858 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1009 - accuracy: 0.9688 - val_loss: 0.2293 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0595 - accuracy: 0.9896 - val_loss: 0.4445 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0824 - accuracy: 0.9792 - val_loss: 0.2543 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1056 - accuracy: 0.9167 - val_loss: 0.1792 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0901 - accuracy: 0.9688 - val_loss: 0.5072 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1078 - accuracy: 0.9688 - val_loss: 0.2585 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0455 - accuracy: 0.9896 - val_loss: 0.1360 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.3292 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 6.7044e-04 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 5.5737e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 5.1322e-04 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 6.5321e-04 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 1.7725e-04 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.5874e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in2_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 8.5874e-04 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 4.6521e-04 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 2.9628e-04 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 4.4106e-04 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 5.3575e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 1.9881e-04 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 2.1566e-04 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.7767e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.3930e-04 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.9302e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.1308e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1067e-04 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.1381e-04 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.8688e-04 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.0015e-04 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 8.1788e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.3315e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.3180e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.1686e-04 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 2.7007e-04 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:48:17.071535: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in2_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in2_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        16\n",
      "         1.0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  3\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_180 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_210 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_30 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_211 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_210 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_60 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_30 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_212 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_211 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_61 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 0.7170 - accuracy: 0.4792 - val_loss: 0.6940 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6477 - accuracy: 0.6771 - val_loss: 0.7258 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.5661 - accuracy: 0.7188 - val_loss: 1.0569 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.5092 - accuracy: 0.7604 - val_loss: 1.0249 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.4678 - accuracy: 0.7917 - val_loss: 1.1611 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.4404 - accuracy: 0.8229 - val_loss: 1.2427 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.3847 - accuracy: 0.8646 - val_loss: 1.5900 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.3686 - accuracy: 0.8854 - val_loss: 1.6320 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.3258 - accuracy: 0.9167 - val_loss: 1.5541 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.3349 - accuracy: 0.8958 - val_loss: 1.8085 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.2694 - accuracy: 0.9271 - val_loss: 1.4004 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.2807 - accuracy: 0.9167 - val_loss: 1.5585 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.2122 - accuracy: 0.9792 - val_loss: 1.7847 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.2078 - accuracy: 0.9688 - val_loss: 1.8636 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.1780 - accuracy: 0.9792 - val_loss: 1.8949 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.1872 - accuracy: 0.9479 - val_loss: 1.6991 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.1462 - accuracy: 0.9896 - val_loss: 1.7126 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1366 - accuracy: 0.9896 - val_loss: 1.5485 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.1015 - accuracy: 0.9896 - val_loss: 1.6093 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.4688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:52:01.947261: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.25      0.32        16\n",
      "         1.0       0.48      0.69      0.56        16\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.46      0.47      0.44        32\n",
      "weighted avg       0.46      0.47      0.44        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_216 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_214 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_120 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_217 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_215 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_121 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_218 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_216 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_122 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_219 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_217 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_123 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_218 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.3455 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.3455 - accuracy: 0.4688 - val_loss: 19.3899 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.6385 - accuracy: 0.4167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.6385 - accuracy: 0.4167 - val_loss: 7.8469 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4109 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.4109 - accuracy: 0.5729 - val_loss: 4.8880 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2632 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.2632 - accuracy: 0.5833 - val_loss: 0.6794 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.8476 - accuracy: 0.6250 - val_loss: 0.6941 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5966 - accuracy: 0.6979 - val_loss: 0.6695 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.7708INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5161 - accuracy: 0.7708 - val_loss: 0.6535 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.7604INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5102 - accuracy: 0.7604 - val_loss: 0.5744 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8333INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4304 - accuracy: 0.8333 - val_loss: 0.5610 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8646INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3485 - accuracy: 0.8646 - val_loss: 0.5158 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2865 - accuracy: 0.8958 - val_loss: 0.4795 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.2199 - accuracy: 0.8854 - val_loss: 0.5412 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.1707 - accuracy: 0.9271 - val_loss: 0.5325 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.1365 - accuracy: 0.9479 - val_loss: 0.7258 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1403 - accuracy: 0.9479 - val_loss: 0.5961 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0904 - accuracy: 0.9688 - val_loss: 0.5638 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.1027 - accuracy: 0.9688 - val_loss: 0.6771 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.7559 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0780 - accuracy: 0.9688 - val_loss: 0.5766 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0522 - accuracy: 0.9896 - val_loss: 0.7123 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0523 - accuracy: 0.9896 - val_loss: 0.6289 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0459 - accuracy: 0.9792 - val_loss: 0.6695 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0495 - accuracy: 0.9792 - val_loss: 0.6463 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0794 - accuracy: 0.9688 - val_loss: 0.6158 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.7916 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1038 - accuracy: 0.9583 - val_loss: 0.7456 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0544 - accuracy: 0.9792 - val_loss: 0.6298 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.5641 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.5644 - val_accuracy: 0.8438 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:52:50.166244: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.75      0.77        16\n",
      "         1.0       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.78      0.78        32\n",
      "weighted avg       0.78      0.78      0.78        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_224 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_32 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_225 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_224 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_64 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_32 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_226 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_225 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_65 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7039 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 965ms/step - loss: 0.7039 - accuracy: 0.5625 - val_loss: 0.6302 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.5860 - accuracy: 0.6771 - val_loss: 0.7267 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.5235 - accuracy: 0.7708 - val_loss: 0.8316 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.4706 - accuracy: 0.7604 - val_loss: 1.1193 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.4253 - accuracy: 0.8438 - val_loss: 1.3126 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.3661 - accuracy: 0.8854 - val_loss: 1.2697 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.3486 - accuracy: 0.8854 - val_loss: 1.4060 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.3057 - accuracy: 0.9062 - val_loss: 1.3982 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.3117 - accuracy: 0.8958 - val_loss: 1.3035 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.2886 - accuracy: 0.9167 - val_loss: 1.3099 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.2482 - accuracy: 0.9271 - val_loss: 1.3146 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.2640 - accuracy: 0.8750 - val_loss: 1.4294 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.2319 - accuracy: 0.9375 - val_loss: 1.3762 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.2300 - accuracy: 0.9375 - val_loss: 1.2870 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.1965 - accuracy: 0.9688 - val_loss: 1.3742 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.1809 - accuracy: 0.9688 - val_loss: 1.3141 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.1636 - accuracy: 0.9896 - val_loss: 1.2733 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.1564 - accuracy: 0.9688 - val_loss: 1.1967 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.1393 - accuracy: 0.9896 - val_loss: 1.1728 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.1534 - accuracy: 0.9583 - val_loss: 1.1946 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.1327 - accuracy: 0.9792 - val_loss: 1.3154 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:56:41.370699: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.62      0.54        16\n",
      "         1.0       0.45      0.31      0.37        16\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.47      0.47      0.46        32\n",
      "weighted avg       0.47      0.47      0.46        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_230 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_228 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_128 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_231 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_229 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_129 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_232 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_230 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_130 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_198 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_233 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_231 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_131 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_232 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.8069 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 6.8069 - accuracy: 0.4688 - val_loss: 34.7634 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.1257 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 8.1257 - accuracy: 0.5104 - val_loss: 8.3244 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4654 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.4654 - accuracy: 0.5521 - val_loss: 1.1297 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.4264 - accuracy: 0.5625 - val_loss: 1.3082 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0590 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0590 - accuracy: 0.5521 - val_loss: 0.7987 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.6042INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6787 - accuracy: 0.6042 - val_loss: 0.6824 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6365 - accuracy: 0.5938 - val_loss: 0.6759 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5940 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5940 - accuracy: 0.6458 - val_loss: 0.6636 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.5694 - accuracy: 0.7188 - val_loss: 0.6701 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5811 - accuracy: 0.6667 - val_loss: 0.7098 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5367 - accuracy: 0.7083 - val_loss: 0.7524 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5301 - accuracy: 0.7292 - val_loss: 0.8343 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4836 - accuracy: 0.7917 - val_loss: 0.8783 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4655 - accuracy: 0.7917 - val_loss: 0.8484 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4418 - accuracy: 0.8333 - val_loss: 0.9530 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.9789 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3964 - accuracy: 0.8542 - val_loss: 1.0043 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3705 - accuracy: 0.8542 - val_loss: 0.9886 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.3263 - accuracy: 0.8958 - val_loss: 1.0181 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.3336 - accuracy: 0.8646 - val_loss: 1.0688 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.3261 - accuracy: 0.8542 - val_loss: 1.2833 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3323 - accuracy: 0.8333 - val_loss: 1.1616 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3398 - accuracy: 0.8542 - val_loss: 1.1929 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.2962 - accuracy: 0.8854 - val_loss: 1.3694 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2758 - accuracy: 0.8750 - val_loss: 1.1607 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.2399 - accuracy: 0.9167 - val_loss: 1.2631 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.2183 - accuracy: 0.8958 - val_loss: 1.3144 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1425 - accuracy: 0.9792 - val_loss: 1.4171 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:57:17.399744: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.69      0.61        16\n",
      "         1.0       0.58      0.44      0.50        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.57      0.56      0.56        32\n",
      "weighted avg       0.57      0.56      0.56        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_204 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_238 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_34 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_239 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_238 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_68 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_34 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_240 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_239 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_69 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7256 - accuracy: 0.5104 - val_loss: 0.6830 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.6277 - accuracy: 0.6250 - val_loss: 0.9115 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.5658 - accuracy: 0.6667 - val_loss: 1.3674 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 1.8898 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4300 - accuracy: 0.8646 - val_loss: 2.5353 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4001 - accuracy: 0.8750 - val_loss: 2.9288 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3592 - accuracy: 0.8646 - val_loss: 3.2094 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3099 - accuracy: 0.9167 - val_loss: 5.1398 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.2826 - accuracy: 0.9479 - val_loss: 5.6100 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.2506 - accuracy: 0.9479 - val_loss: 7.6840 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2338 - accuracy: 0.9375 - val_loss: 7.8988 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.2326 - accuracy: 0.9167 - val_loss: 5.5270 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1872 - accuracy: 0.9479 - val_loss: 5.7442 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.1681 - accuracy: 0.9792 - val_loss: 5.0458 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1923 - accuracy: 0.9583 - val_loss: 5.0475 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1314 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1309 - accuracy: 0.9896 - val_loss: 3.9519 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.1206 - accuracy: 0.9896 - val_loss: 4.5134 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1042 - accuracy: 0.9896 - val_loss: 4.3957 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0883 - accuracy: 0.9896 - val_loss: 3.4015 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.0867 - accuracy: 0.9896 - val_loss: 3.1998 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:01:10.376641: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.81      0.74        16\n",
      "         1.0       0.77      0.62      0.69        16\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.73      0.72      0.72        32\n",
      "weighted avg       0.73      0.72      0.72        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_71 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_207 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_244 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_242 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_245 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_243 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_137 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_246 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_244 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_138 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_210 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_247 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_245 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_139 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_246 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.4811 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 7.4811 - accuracy: 0.5208 - val_loss: 19.7906 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.5892 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 10.5892 - accuracy: 0.4792 - val_loss: 1.5208 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.4657 - accuracy: 0.5729 - val_loss: 3.7555 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0243 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.0243 - accuracy: 0.5625 - val_loss: 1.2165 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7790 - accuracy: 0.6771 - val_loss: 1.3077 - val_accuracy: 0.2812 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.6771INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6310 - accuracy: 0.6771 - val_loss: 0.7712 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5819 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5819 - accuracy: 0.6562 - val_loss: 0.7544 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.5668 - accuracy: 0.6875 - val_loss: 0.7651 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.5244 - accuracy: 0.7604 - val_loss: 0.7815 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.5614 - accuracy: 0.7604 - val_loss: 0.8635 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5659 - accuracy: 0.6771 - val_loss: 0.8177 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5254 - accuracy: 0.7604 - val_loss: 0.8758 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5093 - accuracy: 0.7708 - val_loss: 0.8300 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5010 - accuracy: 0.7604 - val_loss: 0.8739 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4891 - accuracy: 0.7812 - val_loss: 0.9068 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4748 - accuracy: 0.7500 - val_loss: 0.9124 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4955 - accuracy: 0.7917 - val_loss: 0.9386 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.9408 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4496 - accuracy: 0.7708 - val_loss: 0.9096 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.8805 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.9328 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.4002 - accuracy: 0.8854 - val_loss: 0.8770 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4101 - accuracy: 0.7812 - val_loss: 0.9020 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.3398 - accuracy: 0.8542 - val_loss: 0.9273 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3421 - accuracy: 0.8333 - val_loss: 0.9411 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3906 - accuracy: 0.8125 - val_loss: 1.1465 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4100 - accuracy: 0.8333 - val_loss: 0.9189 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:01:38.915349: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.81      0.67        16\n",
      "         1.0       0.67      0.38      0.48        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.62      0.59      0.57        32\n",
      "weighted avg       0.62      0.59      0.57        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_73 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_216 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_252 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_36 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_253 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_252 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_72 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_36 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_254 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_253 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_73 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 0.7343 - accuracy: 0.4896 - val_loss: 0.7011 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.7090 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.5277 - accuracy: 0.7708 - val_loss: 0.9183 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.4770 - accuracy: 0.8021 - val_loss: 1.1542 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.4282 - accuracy: 0.8333 - val_loss: 0.9549 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.4158 - accuracy: 0.8438 - val_loss: 1.0616 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.3628 - accuracy: 0.8750 - val_loss: 1.0122 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.3246 - accuracy: 0.9375 - val_loss: 0.8029 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3067 - accuracy: 0.9271 - val_loss: 0.8055 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.2840 - accuracy: 0.8958 - val_loss: 0.7251 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2556 - accuracy: 0.9688 - val_loss: 0.7971 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.2554 - accuracy: 0.9375 - val_loss: 0.7693 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1994 - accuracy: 0.9792 - val_loss: 0.7628 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.2089 - accuracy: 0.9583 - val_loss: 0.7171 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1789 - accuracy: 0.9896 - val_loss: 0.8178 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1531 - accuracy: 0.9896 - val_loss: 0.7965 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 0.1433 - accuracy: 0.9896 - val_loss: 0.6911 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1389 - accuracy: 0.9896 - val_loss: 0.7298 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.1110 - accuracy: 0.9896 - val_loss: 0.7804 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.0748 - accuracy: 0.9896 - val_loss: 0.7636 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.8602 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0643 - accuracy: 0.9896 - val_loss: 0.9010 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0517 - accuracy: 0.9896 - val_loss: 0.9022 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0567 - accuracy: 0.9896 - val_loss: 0.7929 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.8702 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:05:35.375468: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.50      0.59        16\n",
      "         1.0       0.62      0.81      0.70        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.67      0.66      0.65        32\n",
      "weighted avg       0.67      0.66      0.65        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_258 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_256 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_144 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_259 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_257 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_145 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_260 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_258 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_146 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_222 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_261 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_259 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_147 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_260 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.1560 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 10.1560 - accuracy: 0.4896 - val_loss: 13.4855 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.1773 - accuracy: 0.5104 - val_loss: 13.8305 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.7689 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 6.7689 - accuracy: 0.5104 - val_loss: 1.3573 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2657 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.2657 - accuracy: 0.6250 - val_loss: 0.8105 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.0882 - accuracy: 0.5833 - val_loss: 1.1149 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6576 - accuracy: 0.7083 - val_loss: 0.5421 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4887 - accuracy: 0.7812 - val_loss: 0.4914 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8229INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3824 - accuracy: 0.8229 - val_loss: 0.3882 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2966 - accuracy: 0.8958 - val_loss: 0.3541 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2232 - accuracy: 0.9583 - val_loss: 0.2992 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.1820 - accuracy: 0.9062 - val_loss: 0.3045 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1621 - accuracy: 0.9375 - val_loss: 0.2572 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1467 - accuracy: 0.9375 - val_loss: 0.2439 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1760 - accuracy: 0.9167 - val_loss: 0.2971 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0911 - accuracy: 0.9688 - val_loss: 0.3240 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0640 - accuracy: 0.9792 - val_loss: 0.2592 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0607 - accuracy: 0.9896 - val_loss: 0.3040 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0691 - accuracy: 0.9896 - val_loss: 0.3156 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0478 - accuracy: 0.9896 - val_loss: 0.3987 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0431 - accuracy: 0.9792 - val_loss: 0.3515 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0464 - accuracy: 0.9792 - val_loss: 0.3138 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.0489 - accuracy: 0.9896 - val_loss: 0.2965 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0331 - accuracy: 0.9792 - val_loss: 0.4282 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1150 - accuracy: 0.9375 - val_loss: 0.4441 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0481 - accuracy: 0.9896 - val_loss: 0.4624 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1617 - accuracy: 0.9271 - val_loss: 0.5988 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0488 - accuracy: 0.9896 - val_loss: 0.2772 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0502 - accuracy: 0.9792 - val_loss: 0.2497 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0527 - accuracy: 0.9792 - val_loss: 0.3727 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.8750 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:06:23.905045: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.62      0.69        16\n",
      "         1.0       0.68      0.81      0.74        16\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.73      0.72      0.72        32\n",
      "weighted avg       0.73      0.72      0.72        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_77 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_228 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_266 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_38 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_267 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_266 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_76 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_38 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_268 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_267 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_77 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 0.7229 - accuracy: 0.5104 - val_loss: 0.6635 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6308 - accuracy: 0.6250 - val_loss: 0.6142 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.5514 - accuracy: 0.7083 - val_loss: 0.8862 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.8515 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.4038 - accuracy: 0.8438 - val_loss: 1.0443 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.3545 - accuracy: 0.8854 - val_loss: 1.0488 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.3350 - accuracy: 0.8646 - val_loss: 1.1404 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.3181 - accuracy: 0.9062 - val_loss: 1.3107 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 1.3948 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.2439 - accuracy: 0.9479 - val_loss: 1.4339 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2236 - accuracy: 0.9479 - val_loss: 1.4442 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1969 - accuracy: 0.9688 - val_loss: 1.3640 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1900 - accuracy: 0.9896 - val_loss: 1.4188 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1641 - accuracy: 0.9792 - val_loss: 1.4801 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1540 - accuracy: 0.9896 - val_loss: 1.3147 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.1190 - accuracy: 0.9896 - val_loss: 1.2037 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.1209 - accuracy: 0.9792 - val_loss: 1.1437 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.1059 - accuracy: 0.9896 - val_loss: 1.1880 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.2694 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.1046 - accuracy: 0.9792 - val_loss: 1.3448 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0880 - accuracy: 0.9896 - val_loss: 1.4647 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 1.6338 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:10:20.825392: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.50      0.52        16\n",
      "         1.0       0.53      0.56      0.55        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.53        32\n",
      "weighted avg       0.53      0.53      0.53        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_230 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_272 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_270 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_152 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_273 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_271 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_153 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_274 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_272 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_154 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_234 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_275 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_273 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_155 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_274 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 11.1079 - accuracy: 0.4479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 11.1079 - accuracy: 0.4479 - val_loss: 5.1263 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.6297 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.6297 - accuracy: 0.5104 - val_loss: 4.6494 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0979 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.0979 - accuracy: 0.5000 - val_loss: 2.6896 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0013 - accuracy: 0.6771INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0013 - accuracy: 0.6771 - val_loss: 0.9792 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6719 - accuracy: 0.6667 - val_loss: 0.7938 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.6780 - accuracy: 0.6458 - val_loss: 1.2872 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7552 - accuracy: 0.5833 - val_loss: 0.8830 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5993 - accuracy: 0.6979 - val_loss: 0.8073 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7188INFO:tensorflow:Assets written to: log/smr_dep_sub_1in3_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5660 - accuracy: 0.7188 - val_loss: 0.7805 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.5465 - accuracy: 0.7604 - val_loss: 0.8048 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.8185 - accuracy: 0.5729 - val_loss: 0.8896 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5896 - accuracy: 0.6875 - val_loss: 0.8317 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.6166 - accuracy: 0.6979 - val_loss: 0.8375 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4884 - accuracy: 0.7708 - val_loss: 0.8626 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 1.0002 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4806 - accuracy: 0.7812 - val_loss: 0.9147 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5097 - accuracy: 0.7396 - val_loss: 1.1665 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4472 - accuracy: 0.8333 - val_loss: 0.9132 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4346 - accuracy: 0.8021 - val_loss: 0.9950 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4268 - accuracy: 0.8438 - val_loss: 0.8971 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3926 - accuracy: 0.8125 - val_loss: 1.0332 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4316 - accuracy: 0.7708 - val_loss: 0.9401 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3689 - accuracy: 0.8333 - val_loss: 1.2641 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.3210 - accuracy: 0.8750 - val_loss: 0.9477 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3217 - accuracy: 0.8333 - val_loss: 0.9742 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.2585 - accuracy: 0.9167 - val_loss: 1.1198 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2232 - accuracy: 0.8958 - val_loss: 1.1222 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.1901 - accuracy: 0.9167 - val_loss: 1.7220 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 1.3951 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:10:53.501686: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in3_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in3_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.31      0.42        16\n",
      "         1.0       0.54      0.81      0.65        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.58      0.56      0.53        32\n",
      "weighted avg       0.58      0.56      0.53        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  4\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_81 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_240 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_280 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_40 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_281 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_280 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_80 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_40 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_282 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_281 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_81 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 930ms/step - loss: 0.6960 - accuracy: 0.5104 - val_loss: 0.6967 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7151 - accuracy: 0.5417 - val_loss: 0.9925 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.5666 - accuracy: 0.6979 - val_loss: 1.0387 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.5454 - accuracy: 0.7083 - val_loss: 1.0668 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5006 - accuracy: 0.7917 - val_loss: 1.5416 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4662 - accuracy: 0.8021 - val_loss: 1.1753 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4213 - accuracy: 0.8438 - val_loss: 1.1886 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.3806 - accuracy: 0.8438 - val_loss: 1.1668 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3624 - accuracy: 0.8542 - val_loss: 1.2643 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.3516 - accuracy: 0.8854 - val_loss: 1.0828 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.2946 - accuracy: 0.9479 - val_loss: 1.0675 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.2973 - accuracy: 0.9271 - val_loss: 1.2505 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2731 - accuracy: 0.9375 - val_loss: 1.0443 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.2252 - accuracy: 0.9688 - val_loss: 1.2480 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2140 - accuracy: 0.9583 - val_loss: 1.3470 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1707 - accuracy: 0.9896 - val_loss: 1.4454 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1648 - accuracy: 0.9896 - val_loss: 1.3714 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.1623 - accuracy: 0.9896 - val_loss: 1.3391 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1582 - accuracy: 0.9792 - val_loss: 1.6384 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1373 - accuracy: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1142 - accuracy: 1.0000 - val_loss: 1.4394 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:14:44.900049: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.44      0.42        16\n",
      "         1.0       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.41      0.41      0.41        32\n",
      "weighted avg       0.41      0.41      0.41        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_83 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_286 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_284 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_160 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_287 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_285 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_161 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_245 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_288 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_286 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_162 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_246 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_289 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_287 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_163 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_288 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.2624 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 8.2624 - accuracy: 0.4792 - val_loss: 28.5672 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.1166 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 5.1166 - accuracy: 0.5625 - val_loss: 9.7377 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.7672 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.7672 - accuracy: 0.5208 - val_loss: 0.5855 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.0975 - accuracy: 0.5833 - val_loss: 0.6021 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6284 - accuracy: 0.7083 - val_loss: 0.5290 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.6190 - accuracy: 0.7083 - val_loss: 0.6196 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.6424 - accuracy: 0.6146 - val_loss: 0.5941 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5874 - accuracy: 0.6562 - val_loss: 0.5849 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5302 - accuracy: 0.7188 - val_loss: 0.6567 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5350 - accuracy: 0.7188 - val_loss: 0.6618 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5119 - accuracy: 0.7188 - val_loss: 0.6551 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4843 - accuracy: 0.7396 - val_loss: 0.7077 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5393 - accuracy: 0.6979 - val_loss: 0.6670 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5150 - accuracy: 0.7188 - val_loss: 0.6014 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4746 - accuracy: 0.7708 - val_loss: 0.6849 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.6324 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4324 - accuracy: 0.7708 - val_loss: 0.7775 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4394 - accuracy: 0.8125 - val_loss: 0.6052 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.7684 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3871 - accuracy: 0.8125 - val_loss: 0.6321 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.3618 - accuracy: 0.8333 - val_loss: 0.6982 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3772 - accuracy: 0.8229 - val_loss: 0.7991 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3411 - accuracy: 0.8229 - val_loss: 0.7453 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.2896 - accuracy: 0.8542 - val_loss: 0.8600 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.2928 - accuracy: 0.8750 - val_loss: 0.8630 - val_accuracy: 0.6250 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:15:08.811764: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.12      0.21        16\n",
      "         1.0       0.52      0.94      0.67        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.59      0.53      0.44        32\n",
      "weighted avg       0.59      0.53      0.44        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_85 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_252 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_294 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_42 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_295 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_294 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_84 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_252 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_42 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_296 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_295 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_85 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_253 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 976ms/step - loss: 0.7207 - accuracy: 0.5208 - val_loss: 0.6629 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.6358 - accuracy: 0.6250 - val_loss: 0.8250 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.5294 - accuracy: 0.7500 - val_loss: 1.0090 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.4548 - accuracy: 0.8021 - val_loss: 1.3191 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.3799 - accuracy: 0.8750 - val_loss: 1.5379 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.3403 - accuracy: 0.8854 - val_loss: 1.4978 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.3038 - accuracy: 0.9167 - val_loss: 1.4922 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.2618 - accuracy: 0.9167 - val_loss: 1.3067 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.2643 - accuracy: 0.9271 - val_loss: 1.3948 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2207 - accuracy: 0.9479 - val_loss: 1.7066 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.2339 - accuracy: 0.9375 - val_loss: 1.4461 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.1723 - accuracy: 0.9896 - val_loss: 1.3066 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1651 - accuracy: 0.9792 - val_loss: 1.5380 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1720 - accuracy: 0.9688 - val_loss: 1.2589 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1491 - accuracy: 0.9896 - val_loss: 1.2530 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1260 - accuracy: 0.9792 - val_loss: 1.2774 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1149 - accuracy: 0.9792 - val_loss: 1.2144 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1056 - accuracy: 0.9896 - val_loss: 1.1329 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 1.1547 - val_accuracy: 0.7500 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:18:46.425802: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.75      0.69        16\n",
      "         1.0       0.69      0.56      0.62        16\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.66      0.66      0.65        32\n",
      "weighted avg       0.66      0.66      0.65        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_87 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_254 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_255 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_300 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_298 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_168 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_256 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_256 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_301 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_299 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_169 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_257 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_257 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_302 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_300 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_170 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_258 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_258 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_303 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_301 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_171 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_259 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_302 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.9525 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.9525 - accuracy: 0.4688 - val_loss: 19.2514 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.9177 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.9177 - accuracy: 0.5938 - val_loss: 1.9297 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.9565 - accuracy: 0.5625 - val_loss: 2.4298 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.1073 - accuracy: 0.4792 - val_loss: 3.2378 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4074 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 2.4074 - accuracy: 0.4792 - val_loss: 1.3444 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8316 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.8316 - accuracy: 0.5208 - val_loss: 0.7051 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7208 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7208 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7568 - accuracy: 0.4167 - val_loss: 0.6938 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.7992 - accuracy: 0.4583 - val_loss: 0.6996 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.8045 - accuracy: 0.4583 - val_loss: 0.7979 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.7599 - accuracy: 0.4792 - val_loss: 0.6999 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6846 - accuracy: 0.5208 - val_loss: 0.7056 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7084 - accuracy: 0.5417 - val_loss: 0.7097 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.6482 - accuracy: 0.5938 - val_loss: 0.7091 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6145 - accuracy: 0.6562 - val_loss: 0.6851 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6106 - accuracy: 0.6979 - val_loss: 0.6835 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5607 - accuracy: 0.7396 - val_loss: 0.7044 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5032 - accuracy: 0.8021 - val_loss: 0.7955 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4728 - accuracy: 0.7917 - val_loss: 1.0518 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5018 - accuracy: 0.7500 - val_loss: 0.9235 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.3840 - accuracy: 0.8438 - val_loss: 1.0169 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3538 - accuracy: 0.8438 - val_loss: 1.0057 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 1.0927 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3396 - accuracy: 0.8333 - val_loss: 1.0521 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3123 - accuracy: 0.8646 - val_loss: 1.1081 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.2003 - accuracy: 0.9271 - val_loss: 1.3033 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.2334 - accuracy: 0.9062 - val_loss: 1.4147 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2929 - accuracy: 0.8750 - val_loss: 1.7797 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 1.1027 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 1.3456 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3683 - accuracy: 0.8333 - val_loss: 0.9048 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3480 - accuracy: 0.8125 - val_loss: 0.8295 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.2680 - accuracy: 0.8646 - val_loss: 1.1757 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.2003 - accuracy: 0.9479 - val_loss: 1.1743 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1396 - accuracy: 0.9375 - val_loss: 1.3248 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1192 - accuracy: 0.9688 - val_loss: 1.3711 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:19:23.825961: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.38      0.44        16\n",
      "         1.0       0.52      0.69      0.59        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.52        32\n",
      "weighted avg       0.53      0.53      0.52        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_89 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_264 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_308 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_44 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_309 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_308 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_88 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_44 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_310 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_309 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_89 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 0.6680 - accuracy: 0.5312 - val_loss: 0.6489 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.6325 - accuracy: 0.5833 - val_loss: 0.7205 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5281 - accuracy: 0.7604 - val_loss: 1.3462 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4254 - accuracy: 0.8125 - val_loss: 1.8763 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.3647 - accuracy: 0.8958 - val_loss: 2.5644 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3405 - accuracy: 0.9062 - val_loss: 2.7812 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3009 - accuracy: 0.8958 - val_loss: 2.8139 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.2935 - accuracy: 0.9062 - val_loss: 2.8599 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2344 - accuracy: 0.9375 - val_loss: 2.9295 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2457 - accuracy: 0.9583 - val_loss: 3.1124 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.2399 - accuracy: 0.8854 - val_loss: 2.4127 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.2119 - accuracy: 0.9375 - val_loss: 2.8579 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1733 - accuracy: 0.9583 - val_loss: 2.9651 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1427 - accuracy: 0.9896 - val_loss: 2.9315 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1505 - accuracy: 0.9688 - val_loss: 2.7197 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1309 - accuracy: 0.9792 - val_loss: 2.4346 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 2.1127 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 2.2238 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 2.3033 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1176 - accuracy: 0.9688 - val_loss: 2.4257 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0766 - accuracy: 0.9792 - val_loss: 2.0264 - val_accuracy: 0.6562 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:23:16.092133: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.56      0.47        16\n",
      "         1.0       0.30      0.19      0.23        16\n",
      "\n",
      "    accuracy                           0.38        32\n",
      "   macro avg       0.35      0.38      0.35        32\n",
      "weighted avg       0.35      0.38      0.35        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_91 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_314 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_312 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_176 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_268 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_315 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_313 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_177 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_269 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_316 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_314 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_178 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_270 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_270 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_317 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_315 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_179 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_271 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_316 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.3181 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 6.3181 - accuracy: 0.5833 - val_loss: 36.7157 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.3377 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.3377 - accuracy: 0.5000 - val_loss: 12.3609 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.0882 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 6.0882 - accuracy: 0.4792 - val_loss: 7.7217 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.6481 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 3.6481 - accuracy: 0.5417 - val_loss: 1.4766 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0303 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0303 - accuracy: 0.5625 - val_loss: 0.6545 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.6601 - accuracy: 0.5938 - val_loss: 0.8548 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7135 - accuracy: 0.5000 - val_loss: 0.6870 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6927 - accuracy: 0.4896 - val_loss: 0.7373 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7019 - accuracy: 0.5417 - val_loss: 0.7264 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.7011 - accuracy: 0.5000 - val_loss: 0.6841 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7202 - accuracy: 0.5208 - val_loss: 0.8433 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7532 - accuracy: 0.4271 - val_loss: 0.7368 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7184 - accuracy: 0.4271 - val_loss: 0.8086 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.7119 - accuracy: 0.5417 - val_loss: 0.7015 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.7456 - accuracy: 0.4479 - val_loss: 0.6954 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6969 - accuracy: 0.5312 - val_loss: 0.7500 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6879 - accuracy: 0.5417 - val_loss: 0.6866 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.7109 - accuracy: 0.4583 - val_loss: 0.6870 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6928 - accuracy: 0.5417 - val_loss: 0.7655 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.7114 - accuracy: 0.5417 - val_loss: 0.7063 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.6967 - accuracy: 0.5417 - val_loss: 0.7282 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.6922 - accuracy: 0.5417 - val_loss: 0.7087 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.6913 - accuracy: 0.5417 - val_loss: 0.7132 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.6898 - accuracy: 0.5417 - val_loss: 0.7123 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6906 - accuracy: 0.5417 - val_loss: 0.7159 - val_accuracy: 0.3750 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:23:44.136537: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.19      0.32        16\n",
      "         1.0       0.55      1.00      0.71        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.78      0.59      0.51        32\n",
      "weighted avg       0.78      0.59      0.51        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_93 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_276 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_322 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_46 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_323 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_322 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_92 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_46 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_324 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_323 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_93 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.7060 - accuracy: 0.5625 - val_loss: 0.6789 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.6547 - accuracy: 0.6146 - val_loss: 1.1181 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.5650 - accuracy: 0.6771 - val_loss: 1.0383 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.5004 - accuracy: 0.8125 - val_loss: 1.5730 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 1.7816 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.4066 - accuracy: 0.8542 - val_loss: 1.7804 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3603 - accuracy: 0.8750 - val_loss: 1.6759 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.3213 - accuracy: 0.9479 - val_loss: 1.8831 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.2932 - accuracy: 0.8958 - val_loss: 1.7368 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2449 - accuracy: 0.9479 - val_loss: 1.8410 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2360 - accuracy: 0.9479 - val_loss: 1.8436 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2205 - accuracy: 0.9583 - val_loss: 1.6808 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.1930 - accuracy: 0.9688 - val_loss: 1.6517 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1713 - accuracy: 0.9688 - val_loss: 1.9504 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1523 - accuracy: 0.9792 - val_loss: 1.8256 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1425 - accuracy: 0.9896 - val_loss: 1.8563 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 1.8318 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1398 - accuracy: 0.9896 - val_loss: 1.7898 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 1.6780 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1037 - accuracy: 0.9896 - val_loss: 1.6789 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.5938 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:27:30.688587: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.69      0.54        16\n",
      "         1.0       0.29      0.12      0.17        16\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.36      0.41      0.36        32\n",
      "weighted avg       0.36      0.41      0.36        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_95 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_278 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_279 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_328 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_326 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_184 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_280 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_280 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_329 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_327 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_185 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_281 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_281 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_330 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_328 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_186 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_282 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_282 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_331 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_329 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_187 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_283 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_330 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.3262 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 8.3262 - accuracy: 0.5729 - val_loss: 14.4250 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 8.2399 - accuracy: 0.4375 - val_loss: 22.4427 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.1837 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 7.1837 - accuracy: 0.5208 - val_loss: 8.3645 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5612 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5612 - accuracy: 0.5729 - val_loss: 2.8011 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2783 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.2783 - accuracy: 0.5938 - val_loss: 1.0777 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8381 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8381 - accuracy: 0.5729 - val_loss: 0.5769 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.7226 - accuracy: 0.5208 - val_loss: 0.8457 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7106 - accuracy: 0.5104 - val_loss: 0.7000 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.6506 - accuracy: 0.5833 - val_loss: 0.7734 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.6209 - accuracy: 0.6771 - val_loss: 0.6765 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5838 - accuracy: 0.6667 - val_loss: 0.8322 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5475 - accuracy: 0.6771 - val_loss: 0.6427 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5580 - accuracy: 0.6562 - val_loss: 0.7333 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5427 - accuracy: 0.7188 - val_loss: 0.9885 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.6905 - accuracy: 0.5938 - val_loss: 0.9872 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5218 - accuracy: 0.7188 - val_loss: 0.9907 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5220 - accuracy: 0.7396 - val_loss: 0.7994 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5079 - accuracy: 0.7812 - val_loss: 0.8712 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4976 - accuracy: 0.7500 - val_loss: 0.9582 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.8194 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4412 - accuracy: 0.7500 - val_loss: 1.2837 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.4146 - accuracy: 0.8229 - val_loss: 0.6497 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.4773 - accuracy: 0.7396 - val_loss: 1.1682 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4013 - accuracy: 0.8333 - val_loss: 0.7763 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.3420 - accuracy: 0.8438 - val_loss: 0.6272 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3193 - accuracy: 0.8438 - val_loss: 0.9243 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:27:58.217458: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        16\n",
      "         1.0       0.50      1.00      0.67        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.25      0.50      0.33        32\n",
      "weighted avg       0.25      0.50      0.33        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_97 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_288 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_336 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_48 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_337 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_336 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_96 (Avera  (None, 1, 112, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_288 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_48 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_338 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_337 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_97 (Avera  (None, 1, 14, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_289 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7237 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 0.7237 - accuracy: 0.5208 - val_loss: 0.6568 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.6821 - accuracy: 0.5625 - val_loss: 0.7763 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 1.1305 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5467 - accuracy: 0.7292 - val_loss: 1.0668 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.9976 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.4182 - accuracy: 0.8958 - val_loss: 1.2295 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3621 - accuracy: 0.8958 - val_loss: 1.2751 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3494 - accuracy: 0.8958 - val_loss: 1.9422 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3053 - accuracy: 0.9271 - val_loss: 2.3563 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.2821 - accuracy: 0.8958 - val_loss: 1.9829 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2410 - accuracy: 0.9271 - val_loss: 2.3529 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2038 - accuracy: 0.9583 - val_loss: 2.8675 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.2346 - accuracy: 0.9167 - val_loss: 1.7259 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1886 - accuracy: 0.9583 - val_loss: 1.6790 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.1595 - accuracy: 0.9792 - val_loss: 1.3752 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1306 - accuracy: 0.9792 - val_loss: 1.3153 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1149 - accuracy: 0.9896 - val_loss: 1.6029 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1153 - accuracy: 0.9792 - val_loss: 1.7465 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1083 - accuracy: 0.9896 - val_loss: 1.3621 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1035 - accuracy: 0.9792 - val_loss: 1.5493 - val_accuracy: 0.6250 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:31:45.118542: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.50      0.48        16\n",
      "         1.0       0.47      0.44      0.45        16\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.47      0.47      0.47        32\n",
      "weighted avg       0.47      0.47      0.47        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_99 (InputLayer)       [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_290 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_291 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_342 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_340 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_192 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_292 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_292 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_343 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_341 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_193 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_293 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_293 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_344 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_342 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_194 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_294 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_294 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_345 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_343 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_195 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_295 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_344 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.8160 - accuracy: 0.5312INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 6.8160 - accuracy: 0.5312 - val_loss: 14.2811 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.0633 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 7.0633 - accuracy: 0.4792 - val_loss: 0.8233 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 4.3278 - accuracy: 0.3542 - val_loss: 9.4682 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.2647 - accuracy: 0.5312 - val_loss: 1.1335 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0330 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0330 - accuracy: 0.5729 - val_loss: 0.7181 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.5680 - accuracy: 0.7083 - val_loss: 0.7077 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6433 - accuracy: 0.6042INFO:tensorflow:Assets written to: log/smr_dep_sub_1in4_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6433 - accuracy: 0.6042 - val_loss: 0.6813 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.6220 - accuracy: 0.7500 - val_loss: 0.7230 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.4818 - accuracy: 0.7917 - val_loss: 0.8325 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4422 - accuracy: 0.8021 - val_loss: 1.0160 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.3503 - accuracy: 0.8750 - val_loss: 1.0869 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.3338 - accuracy: 0.8229 - val_loss: 1.2997 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.2660 - accuracy: 0.8854 - val_loss: 1.5033 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4354 - accuracy: 0.7917 - val_loss: 1.2177 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4211 - accuracy: 0.8542 - val_loss: 1.1450 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.2687 - accuracy: 0.8854 - val_loss: 1.1816 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.2643 - accuracy: 0.9062 - val_loss: 1.0613 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.2120 - accuracy: 0.9062 - val_loss: 0.8534 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.1776 - accuracy: 0.9167 - val_loss: 1.0570 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.1489 - accuracy: 0.9688 - val_loss: 1.0718 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.1023 - accuracy: 0.9896 - val_loss: 1.2593 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.1103 - accuracy: 0.9583 - val_loss: 1.1100 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.0836 - accuracy: 0.9896 - val_loss: 1.3801 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0581 - accuracy: 0.9896 - val_loss: 1.4790 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.0908 - accuracy: 0.9688 - val_loss: 1.0875 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0886 - accuracy: 0.9792 - val_loss: 1.3477 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.1050 - accuracy: 0.9479 - val_loss: 1.2826 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:32:14.941289: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in4_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in4_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.69      0.55        16\n",
      "         1.0       0.38      0.19      0.25        16\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.42      0.44      0.40        32\n",
      "weighted avg       0.42      0.44      0.40        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  5\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_101 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_300 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_350 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_50 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_351 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_350 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_100 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_50 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_352 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_351 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_101 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in5_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7647 - accuracy: 0.5208 - val_loss: 0.7891 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.6865 - accuracy: 0.5625 - val_loss: 1.3350 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.6329 - accuracy: 0.5625 - val_loss: 1.9213 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.5814 - accuracy: 0.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0150 - accuracy: 0.9896 - val_loss: 0.2379 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0244 - accuracy: 0.9896 - val_loss: 0.1897 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 905ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 927ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.0287 - accuracy: 0.9896 - val_loss: 0.1466 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0191 - accuracy: 0.9896 - val_loss: 0.1545 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.0220 - accuracy: 0.9896 - val_loss: 0.1717 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 916ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 7.3159e-04 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 6.3650e-04 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:35:00.324203: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.93        16\n",
      "         1.0       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.94      0.94      0.94        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_163 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_482 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_483 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_566 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_564 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_320 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_484 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_484 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_567 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_565 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_321 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_485 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_485 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_568 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_566 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_322 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_486 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_486 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_569 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_567 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_323 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_487 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_568 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 11.0444 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 11.0444 - accuracy: 0.4896 - val_loss: 8.8542 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2205 - accuracy: 0.5625INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.2205 - accuracy: 0.5625 - val_loss: 0.7889 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.7478 - accuracy: 0.6979 - val_loss: 2.0660 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8461 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.8461 - accuracy: 0.6979 - val_loss: 0.5993 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8229INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.4699 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6069 - accuracy: 0.7292 - val_loss: 0.4780 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3545 - accuracy: 0.8854 - val_loss: 0.3597 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2438 - accuracy: 0.9167 - val_loss: 0.6439 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8438INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3188 - accuracy: 0.8438 - val_loss: 0.2384 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1200 - accuracy: 0.9792 - val_loss: 0.2894 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0629 - accuracy: 0.9896 - val_loss: 0.2953 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0581 - accuracy: 0.9896 - val_loss: 0.2907 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 9.4379e-04 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0173 - accuracy: 0.9896 - val_loss: 0.0876 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.2458 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0161 - accuracy: 0.9896 - val_loss: 0.0881 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0292 - accuracy: 0.9792 - val_loss: 0.2072 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0537 - accuracy: 0.9792 - val_loss: 0.2173 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0224 - accuracy: 0.9896 - val_loss: 0.3130 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:36:14.320768: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        16\n",
      "         1.0       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_165 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_492 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_574 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_82 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_575 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_574 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_164 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_492 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_82 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_576 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_575 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_165 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_493 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.6031 - accuracy: 0.6667 - val_loss: 0.3856 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.1914 - accuracy: 0.9375 - val_loss: 3.1028 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1859 - accuracy: 0.9375 - val_loss: 9.6245 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1322 - accuracy: 0.9688 - val_loss: 15.3918 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1176 - accuracy: 0.9896 - val_loss: 16.8968 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0896 - accuracy: 0.9583 - val_loss: 12.3436 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0841 - accuracy: 0.9688 - val_loss: 8.8984 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0700 - accuracy: 0.9896 - val_loss: 5.8914 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0793 - accuracy: 0.9792 - val_loss: 2.9628 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0888 - accuracy: 0.9688 - val_loss: 2.6025 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0718 - accuracy: 0.9792 - val_loss: 1.4497 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0426 - accuracy: 0.9896 - val_loss: 0.4266 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0687 - accuracy: 0.9792 - val_loss: 0.2642 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 870ms/step - loss: 0.0652 - accuracy: 0.9896 - val_loss: 0.2561 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.3086 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 859ms/step - loss: 0.0350 - accuracy: 0.9792 - val_loss: 0.2217 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 0.0271 - accuracy: 0.9896 - val_loss: 0.1251 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 888ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 842ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 858ms/step - loss: 0.0161 - accuracy: 0.9896 - val_loss: 0.0091 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 852ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:39:03.873223: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.81      0.90        16\n",
      "         1.0       0.84      1.00      0.91        16\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.92      0.91      0.91        32\n",
      "weighted avg       0.92      0.91      0.91        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_167 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_494 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_495 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_580 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_578 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_328 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_496 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_496 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_581 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_579 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_329 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_497 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_497 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_582 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_580 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_330 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_498 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_498 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_583 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_581 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_331 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_499 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_582 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 12.5280 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 12.5280 - accuracy: 0.4896 - val_loss: 1.6650 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 6.6296 - accuracy: 0.4583 - val_loss: 4.8506 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.2419 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 3.2419 - accuracy: 0.4896 - val_loss: 0.8364 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8423 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.8423 - accuracy: 0.4792 - val_loss: 0.5718 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3979 - accuracy: 0.8125 - val_loss: 0.4352 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.7188INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5252 - accuracy: 0.7188 - val_loss: 0.3920 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3458 - accuracy: 0.8438 - val_loss: 0.4050 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3259 - accuracy: 0.8854 - val_loss: 0.3389 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2591 - accuracy: 0.9062 - val_loss: 0.2867 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.2212 - accuracy: 0.9167 - val_loss: 0.2949 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3151 - accuracy: 0.8958 - val_loss: 0.2623 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1463 - accuracy: 0.9479 - val_loss: 0.2449 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.1969 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.1364 - accuracy: 0.9375 - val_loss: 0.1029 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0677 - accuracy: 0.9896 - val_loss: 0.0966 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 0.1587 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0823 - accuracy: 0.9688 - val_loss: 0.0877 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0408 - accuracy: 0.9792 - val_loss: 0.0837 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 0.0340 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.0449 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 9.7083e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 5.0723e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:40:33.305524: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        16\n",
      "         1.0       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_169 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_504 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_588 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_84 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_589 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_588 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_168 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_504 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_84 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_590 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_589 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_169 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_505 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.6354INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 0.6294 - accuracy: 0.6354 - val_loss: 0.2758 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.3014 - accuracy: 0.8854 - val_loss: 1.7692 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.1927 - accuracy: 0.9375 - val_loss: 2.4883 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.1474 - accuracy: 0.9583 - val_loss: 3.5745 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 4.0664 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.1016 - accuracy: 0.9688 - val_loss: 3.2162 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0790 - accuracy: 0.9792 - val_loss: 2.6464 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.0646 - accuracy: 0.9896 - val_loss: 1.8830 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0515 - accuracy: 0.9792 - val_loss: 1.2587 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.7779 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.5731 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.4629 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0513 - accuracy: 0.9896 - val_loss: 0.2607 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 879ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.2527 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 897ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 904ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 917ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 917ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 961ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:44:04.124996: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91        16\n",
      "         1.0       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.91      0.91      0.91        32\n",
      "weighted avg       0.91      0.91      0.91        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_171 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_506 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_507 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_594 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_592 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_336 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_508 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_508 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_595 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_593 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_337 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_509 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_509 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_596 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_594 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_338 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_510 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_510 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_597 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_595 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_339 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_511 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_596 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.1865 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.1865 - accuracy: 0.5208 - val_loss: 5.3710 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 5.9333 - accuracy: 0.5417 - val_loss: 12.1176 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 7.0779 - accuracy: 0.4375 - val_loss: 6.3617 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.2216 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.2216 - accuracy: 0.4688 - val_loss: 1.5688 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9179 - accuracy: 0.6042INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.9179 - accuracy: 0.6042 - val_loss: 0.5342 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5666 - accuracy: 0.7083 - val_loss: 0.5990 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6061 - accuracy: 0.7396 - val_loss: 0.6089 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5601 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8333INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4579 - accuracy: 0.8333 - val_loss: 0.3924 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8125INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.4020 - accuracy: 0.8125 - val_loss: 0.3266 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.3185 - accuracy: 0.8646 - val_loss: 0.3591 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.2711 - accuracy: 0.9167 - val_loss: 0.2733 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9167INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2352 - accuracy: 0.9167 - val_loss: 0.2520 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.8646INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.2738 - accuracy: 0.8646 - val_loss: 0.1808 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9271INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1839 - accuracy: 0.9271 - val_loss: 0.1503 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.1062 - accuracy: 0.9792 - val_loss: 0.2558 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0587 - accuracy: 0.9896 - val_loss: 0.1637 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0560 - accuracy: 0.9688 - val_loss: 0.1563 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0406 - accuracy: 0.9792 - val_loss: 0.1635 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.1732 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:44:48.208535: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.81      0.79        16\n",
      "         1.0       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.78      0.78        32\n",
      "weighted avg       0.78      0.78      0.78        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_173 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_516 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_602 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_86 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_603 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_602 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_172 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_516 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_86 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_604 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_603 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_173 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_517 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6354INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 0.6203 - accuracy: 0.6354 - val_loss: 0.9956 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.1824 - accuracy: 0.9479 - val_loss: 10.8118 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1907 - accuracy: 0.9271 - val_loss: 26.9605 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2317 - accuracy: 0.9479 - val_loss: 29.2541 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1346 - accuracy: 0.9583 - val_loss: 22.2236 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0959 - accuracy: 0.9688 - val_loss: 18.1856 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.0751 - accuracy: 0.9896 - val_loss: 13.5471 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0616 - accuracy: 0.9896 - val_loss: 10.1146 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0524 - accuracy: 0.9896 - val_loss: 7.1780 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0572 - accuracy: 0.9896 - val_loss: 5.2799 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1038 - accuracy: 0.9479 - val_loss: 3.4847 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0407 - accuracy: 0.9896 - val_loss: 3.7426 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.6766 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 2.1257 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.9414 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.9679 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.1223 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.1215 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.9562 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.4751 - val_accuracy: 0.7500 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:47:22.246165: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      1.00      0.68        16\n",
      "         1.0       1.00      0.06      0.12        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.76      0.53      0.40        32\n",
      "weighted avg       0.76      0.53      0.40        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_175 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_518 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_519 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_608 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_606 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_344 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_520 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_520 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_609 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_607 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_345 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_521 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_521 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_610 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_608 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_346 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_522 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_522 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_611 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_609 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_347 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_523 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_610 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.2194 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 10.2194 - accuracy: 0.4896 - val_loss: 19.5873 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.3925 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 9.3925 - accuracy: 0.5104 - val_loss: 5.6107 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.4535 - accuracy: 0.4479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 4.4535 - accuracy: 0.4479 - val_loss: 0.9574 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.5015 - accuracy: 0.6146 - val_loss: 1.6119 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8850 - accuracy: 0.6250 - val_loss: 0.3948 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.7708INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.4515 - accuracy: 0.7708 - val_loss: 0.3849 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4126 - accuracy: 0.8542 - val_loss: 0.4186 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4288 - accuracy: 0.8333 - val_loss: 0.3965 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8750INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3973 - accuracy: 0.8750 - val_loss: 0.3817 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3829 - accuracy: 0.8958 - val_loss: 0.4148 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8646INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3593 - accuracy: 0.8646 - val_loss: 0.3014 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.3180 - accuracy: 0.8646 - val_loss: 0.3631 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2594 - accuracy: 0.8854 - val_loss: 0.3360 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2331 - accuracy: 0.9167 - val_loss: 0.3359 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.1596 - accuracy: 0.9583 - val_loss: 0.3937 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1760 - accuracy: 0.9271 - val_loss: 0.3968 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1129 - accuracy: 0.9688 - val_loss: 0.1985 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0725 - accuracy: 0.9792 - val_loss: 0.1752 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0713 - accuracy: 0.9792 - val_loss: 0.1583 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0478 - accuracy: 0.9896 - val_loss: 0.1487 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0746 - accuracy: 0.9688 - val_loss: 0.1857 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0722 - accuracy: 0.9792 - val_loss: 0.1967 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0517 - accuracy: 0.9792 - val_loss: 0.0483 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0620 - accuracy: 0.9688 - val_loss: 0.1027 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0501 - accuracy: 0.9896 - val_loss: 0.0689 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0524 - accuracy: 0.9688 - val_loss: 0.1105 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0181 - accuracy: 0.9896 - val_loss: 0.0290 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.1661e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 8.1661e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 6.6824e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 6.8065e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 9.8932e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 6.4800e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:48:50.952269: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        16\n",
      "         1.0       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_177 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_528 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_616 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_88 (Depthw  (None, 1, 448, 16)       240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_617 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_616 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_176 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_528 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_88 (Separa  (None, 1, 112, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_618 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_617 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_177 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_529 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 994ms/step - loss: 0.7321 - accuracy: 0.5000 - val_loss: 0.4359 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.3428 - accuracy: 0.9375 - val_loss: 0.6475 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.1870 - accuracy: 0.9479 - val_loss: 1.3426 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.1809 - accuracy: 0.9167 - val_loss: 1.3017 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.1225 - accuracy: 0.9688 - val_loss: 1.3418 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0947 - accuracy: 0.9792 - val_loss: 0.8500 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.0954 - accuracy: 0.9792 - val_loss: 0.6710 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0691 - accuracy: 0.9896 - val_loss: 0.6776 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.1027 - accuracy: 0.9688 - val_loss: 0.8148 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.6812 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 890ms/step - loss: 0.0500 - accuracy: 0.9896 - val_loss: 0.3360 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.2952 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 918ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 952ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 0.3340 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.2694 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0422 - accuracy: 0.9896 - val_loss: 0.3939 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0183 - accuracy: 0.9896 - val_loss: 0.4578 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0448 - accuracy: 0.9896 - val_loss: 0.3688 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.0204 - accuracy: 0.9896 - val_loss: 0.2322 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 875ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 886ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.0177 - accuracy: 0.9896 - val_loss: 0.2070 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 1s 185ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:51:52.540705: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in8_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in8_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.94      0.86        16\n",
      "         1.0       0.92      0.75      0.83        16\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.86      0.84      0.84        32\n",
      "weighted avg       0.86      0.84      0.84        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_179 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_530 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_531 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_622 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_620 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_352 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_532 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_532 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_623 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_621 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_353 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_533 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_533 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_624 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_622 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_354 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_534 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_534 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_625 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_623 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_355 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_535 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_624 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.5769 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.5769 - accuracy: 0.4688 - val_loss: 4.3525 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5475 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.5475 - accuracy: 0.6458 - val_loss: 0.3691 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.8021INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5075 - accuracy: 0.8021 - val_loss: 0.3324 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.3557 - accuracy: 0.8750 - val_loss: 0.4651 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.3343 - accuracy: 0.8854 - val_loss: 0.5334 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8542INFO:tensorflow:Assets written to: log/smr_dep_sub_1in8_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2948 - accuracy: 0.8542 - val_loss: 0.2810 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 294ms/step - loss: 0.2546 - accuracy: 0.9479 - val_loss: 2.7009 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.2569 - accuracy: 0.9062 - val_loss: 2.5808 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.1983 - accuracy: 0.9583 - val_loss: 2.6987 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.1755 - accuracy: 0.9792 - val_loss: 2.8374 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.1530 - accuracy: 0.9792 - val_loss: 2.9850 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.1339 - accuracy: 0.9792 - val_loss: 2.7926 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.1511 - accuracy: 0.9792 - val_loss: 2.7347 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.1235 - accuracy: 0.9896 - val_loss: 2.8206 - val_accuracy: 0.4062 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:52:23.522597: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.69      0.63        16\n",
      "         1.0       0.62      0.50      0.55        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.60      0.59      0.59        32\n",
      "weighted avg       0.60      0.59      0.59        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_243 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_722 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_723 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_846 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_844 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_480 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_724 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_724 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_847 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_845 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_481 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_725 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_725 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_848 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_846 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_482 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_726 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_726 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_849 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_847 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_483 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_727 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_848 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.3881 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 8.3881 - accuracy: 0.4896 - val_loss: 20.5832 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.0138 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 5.0138 - accuracy: 0.5208 - val_loss: 3.9139 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.3254 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 3.3254 - accuracy: 0.4896 - val_loss: 1.7646 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6803 - accuracy: 0.4583INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.6803 - accuracy: 0.4583 - val_loss: 0.8306 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.8857 - accuracy: 0.6146 - val_loss: 0.9248 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.6452 - accuracy: 0.6562 - val_loss: 0.9390 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7219 - accuracy: 0.5521 - val_loss: 0.7281 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7292INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.5882 - accuracy: 0.7292 - val_loss: 0.6855 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.5664 - accuracy: 0.7292 - val_loss: 0.6994 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.5489 - accuracy: 0.7292 - val_loss: 0.7304 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.5383 - accuracy: 0.7396 - val_loss: 0.7316 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.5171 - accuracy: 0.7604 - val_loss: 0.7377 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.4979 - accuracy: 0.7812 - val_loss: 0.7451 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.4961 - accuracy: 0.7812 - val_loss: 0.7341 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.5144 - accuracy: 0.7812 - val_loss: 0.6587 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.5020 - accuracy: 0.7500 - val_loss: 0.8471 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.7604INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4946 - accuracy: 0.7604 - val_loss: 0.6551 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.4872 - accuracy: 0.7917 - val_loss: 0.7131 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.4394 - accuracy: 0.7708 - val_loss: 0.6644 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.4497 - accuracy: 0.8021 - val_loss: 0.7447 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.7812INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.4341 - accuracy: 0.7812 - val_loss: 0.6434 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 0.4213 - accuracy: 0.8438 - val_loss: 0.7328 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.8392 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.4649 - accuracy: 0.7917 - val_loss: 0.6712 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.4739 - accuracy: 0.7812 - val_loss: 1.0152 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.4132 - accuracy: 0.8438 - val_loss: 0.7061 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.3582 - accuracy: 0.8542 - val_loss: 0.6621 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.3473 - accuracy: 0.9062 - val_loss: 0.8817 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.3288 - accuracy: 0.8646 - val_loss: 0.8451 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.3371 - accuracy: 0.8333 - val_loss: 0.8285 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.3156 - accuracy: 0.8646 - val_loss: 0.9695 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.3565 - accuracy: 0.8542 - val_loss: 0.9373 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.3109 - accuracy: 0.8854 - val_loss: 0.9136 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.2721 - accuracy: 0.9062 - val_loss: 1.1893 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2928 - accuracy: 0.8958 - val_loss: 0.9120 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3675 - accuracy: 0.8438 - val_loss: 1.1340 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.3353 - accuracy: 0.8542 - val_loss: 0.8862 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.2776 - accuracy: 0.8750 - val_loss: 0.8755 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.2270 - accuracy: 0.9271 - val_loss: 0.8894 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.2555 - accuracy: 0.8854 - val_loss: 0.8055 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.2178 - accuracy: 0.9271 - val_loss: 1.1914 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:53:47.907372: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.56      0.53        16\n",
      "         1.0       0.50      0.44      0.47        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.50        32\n",
      "weighted avg       0.50      0.50      0.50        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_245 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_732 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_854 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_122 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_855 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_854 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_244 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_732 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_122 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_856 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_855 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_245 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_733 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7348 - accuracy: 0.4896 - val_loss: 1.4466 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.6023 - accuracy: 0.6667 - val_loss: 4.3097 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.5287 - accuracy: 0.7604 - val_loss: 5.6530 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.4914 - accuracy: 0.8125 - val_loss: 5.6628 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.4421 - accuracy: 0.8333 - val_loss: 5.9518 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.4226 - accuracy: 0.8333 - val_loss: 4.7244 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.3931 - accuracy: 0.8333 - val_loss: 4.0092 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.3603 - accuracy: 0.8750 - val_loss: 3.8292 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.3219 - accuracy: 0.9062 - val_loss: 3.4251 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2518 - accuracy: 0.9688 - val_loss: 3.3499 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.2606 - accuracy: 0.9479 - val_loss: 3.4087 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.2420 - accuracy: 0.9583 - val_loss: 3.4239 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.2067 - accuracy: 0.9792 - val_loss: 3.0293 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.2053 - accuracy: 0.9688 - val_loss: 3.1894 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1519 - accuracy: 0.9896 - val_loss: 2.9592 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1409 - accuracy: 0.9688 - val_loss: 3.0740 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.1345 - accuracy: 0.9688 - val_loss: 3.4298 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1252 - accuracy: 0.9688 - val_loss: 2.7372 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1234 - accuracy: 0.9792 - val_loss: 2.8617 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1254 - accuracy: 0.9896 - val_loss: 2.7862 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.1222 - accuracy: 0.9792 - val_loss: 3.0492 - val_accuracy: 0.4375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:57:40.804198: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.25      0.31        16\n",
      "         1.0       0.45      0.62      0.53        16\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.43      0.44      0.42        32\n",
      "weighted avg       0.43      0.44      0.42        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_247 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_734 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_735 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_860 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_858 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_488 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_736 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_736 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_861 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_859 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_489 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_737 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_737 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_862 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_860 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_490 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_738 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_738 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_863 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_861 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_491 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_739 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_862 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.5142 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 9.5142 - accuracy: 0.5208 - val_loss: 3.5366 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 2.4842 - accuracy: 0.4688 - val_loss: 4.2646 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4765 - accuracy: 0.6146INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.4765 - accuracy: 0.6146 - val_loss: 1.3099 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.9634 - accuracy: 0.6250 - val_loss: 1.6872 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.8329 - accuracy: 0.6354 - val_loss: 2.0053 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7480 - accuracy: 0.7083 - val_loss: 1.1933 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.5984 - accuracy: 0.7188 - val_loss: 1.3246 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.8694 - accuracy: 0.6354 - val_loss: 1.7571 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.7396INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5467 - accuracy: 0.7396 - val_loss: 1.1349 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.5047 - accuracy: 0.8021 - val_loss: 1.2601 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.7188INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5296 - accuracy: 0.7188 - val_loss: 1.1275 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3823 - accuracy: 0.8333 - val_loss: 1.2754 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.4139 - accuracy: 0.8438 - val_loss: 1.2464 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4165 - accuracy: 0.8125 - val_loss: 1.3029 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8333INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4149 - accuracy: 0.8333 - val_loss: 1.0808 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3811 - accuracy: 0.8229 - val_loss: 1.3845 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4259 - accuracy: 0.8542 - val_loss: 1.3181 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4227 - accuracy: 0.8021 - val_loss: 1.1611 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.3816 - accuracy: 0.8333 - val_loss: 1.5689 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.3980 - accuracy: 0.8438 - val_loss: 1.3756 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.3630 - accuracy: 0.8438 - val_loss: 1.2599 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.3412 - accuracy: 0.8750 - val_loss: 1.4422 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.3603 - accuracy: 0.8542 - val_loss: 1.3298 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.3409 - accuracy: 0.8438 - val_loss: 1.5145 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.3309 - accuracy: 0.8646 - val_loss: 1.2455 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.3328 - accuracy: 0.8854 - val_loss: 1.5465 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.3064 - accuracy: 0.8646 - val_loss: 1.4007 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.3267 - accuracy: 0.8854 - val_loss: 1.3434 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.3345 - accuracy: 0.8438 - val_loss: 1.3420 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.3413 - accuracy: 0.8438 - val_loss: 1.3945 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 132ms/step - loss: 0.2733 - accuracy: 0.8854 - val_loss: 1.3013 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.3257 - accuracy: 0.9062 - val_loss: 1.3237 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.3804 - accuracy: 0.8229 - val_loss: 1.4318 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.3771 - accuracy: 0.8125 - val_loss: 1.2587 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.3141 - accuracy: 0.8854 - val_loss: 1.5631 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:58:19.733360: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.56      0.56        16\n",
      "         1.0       0.56      0.56      0.56        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.56      0.56      0.56        32\n",
      "weighted avg       0.56      0.56      0.56        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_249 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_744 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_868 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_124 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_869 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_868 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_248 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_744 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_124 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_870 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_869 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_249 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_745 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7891 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 0.7891 - accuracy: 0.4688 - val_loss: 0.9247 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.7050 - accuracy: 0.5312 - val_loss: 1.6786 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.6510 - accuracy: 0.6042 - val_loss: 2.2973 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.6271 - accuracy: 0.6562 - val_loss: 2.8662 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.5935 - accuracy: 0.7083 - val_loss: 2.7730 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.5287 - accuracy: 0.7500 - val_loss: 2.8734 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.5205 - accuracy: 0.8125 - val_loss: 2.7914 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.4602 - accuracy: 0.8229 - val_loss: 2.6653 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.4587 - accuracy: 0.8021 - val_loss: 2.4104 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.4362 - accuracy: 0.8125 - val_loss: 2.1592 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.3771 - accuracy: 0.8542 - val_loss: 1.8540 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.3267 - accuracy: 0.9167 - val_loss: 1.6386 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.3283 - accuracy: 0.9062 - val_loss: 1.5173 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.2965 - accuracy: 0.9479 - val_loss: 1.0774 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.2838 - accuracy: 0.9167 - val_loss: 1.0903 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.2385 - accuracy: 0.9583 - val_loss: 1.2255 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.2022 - accuracy: 0.9583 - val_loss: 1.3941 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.1600 - accuracy: 0.9792 - val_loss: 1.4142 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.1681 - accuracy: 0.9792 - val_loss: 1.4529 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.1548 - accuracy: 0.9792 - val_loss: 1.6497 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.1538 - accuracy: 0.9688 - val_loss: 1.0754 - val_accuracy: 0.6875 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:01:17.254257: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.56        16\n",
      "         1.0       0.50      0.38      0.43        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.49        32\n",
      "weighted avg       0.50      0.50      0.49        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_251 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_746 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_747 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_874 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_872 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_496 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_748 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_748 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_875 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_873 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_497 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_749 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_749 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_876 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_874 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_498 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_750 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_750 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_877 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_875 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_499 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_751 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_876 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.5812 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 2s/step - loss: 4.5812 - accuracy: 0.5729 - val_loss: 27.1508 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.6931 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.6931 - accuracy: 0.5729 - val_loss: 1.0633 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4119 - accuracy: 0.6667INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.4119 - accuracy: 0.6667 - val_loss: 1.0057 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 1.0951 - accuracy: 0.5417 - val_loss: 1.1211 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9219 - accuracy: 0.5417 - val_loss: 0.9395 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 1.1332 - accuracy: 0.4375 - val_loss: 1.0916 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.9059 - accuracy: 0.5625 - val_loss: 1.1298 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.6458INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6410 - accuracy: 0.6458 - val_loss: 0.8841 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7122 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7122 - accuracy: 0.6250 - val_loss: 0.8248 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5981 - accuracy: 0.7083 - val_loss: 0.7602 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.5421 - accuracy: 0.7396 - val_loss: 0.8674 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.5482 - accuracy: 0.7396 - val_loss: 0.8717 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.5784 - accuracy: 0.7188 - val_loss: 0.8429 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.5345 - accuracy: 0.7500 - val_loss: 0.8273 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.5597 - accuracy: 0.6771 - val_loss: 0.8467 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 0.8171 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4839 - accuracy: 0.7812 - val_loss: 0.8899 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.5149 - accuracy: 0.7604 - val_loss: 0.9243 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.5100 - accuracy: 0.7708 - val_loss: 0.9402 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.4828 - accuracy: 0.7812 - val_loss: 0.9839 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4967 - accuracy: 0.7917 - val_loss: 0.9654 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4389 - accuracy: 0.7604 - val_loss: 1.0184 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.4657 - accuracy: 0.7917 - val_loss: 1.1022 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.4635 - accuracy: 0.7917 - val_loss: 1.0400 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.3906 - accuracy: 0.8542 - val_loss: 0.9677 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 134ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 1.0451 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.3322 - accuracy: 0.8646 - val_loss: 1.0051 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.3054 - accuracy: 0.9062 - val_loss: 1.2038 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.3209 - accuracy: 0.8750 - val_loss: 1.0311 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 1.5073 - val_accuracy: 0.4062 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:01:57.591283: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.56      0.60        16\n",
      "         1.0       0.61      0.69      0.65        16\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.63      0.62      0.62        32\n",
      "weighted avg       0.63      0.62      0.62        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_253 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_756 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_882 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_126 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_883 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_882 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_252 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_756 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_126 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_884 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_883 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_253 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_757 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7509 - accuracy: 0.5000 - val_loss: 0.8760 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.6091 - accuracy: 0.6875 - val_loss: 2.4118 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.5804 - accuracy: 0.7083 - val_loss: 3.3777 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.4924 - accuracy: 0.7708 - val_loss: 3.4978 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.5116 - accuracy: 0.7708 - val_loss: 3.1308 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.4315 - accuracy: 0.8333 - val_loss: 2.6185 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.4467 - accuracy: 0.8333 - val_loss: 2.7982 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.3994 - accuracy: 0.8750 - val_loss: 2.2405 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.3419 - accuracy: 0.9271 - val_loss: 2.2160 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.3306 - accuracy: 0.9583 - val_loss: 1.9948 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.2729 - accuracy: 0.9375 - val_loss: 2.0868 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.2711 - accuracy: 0.9375 - val_loss: 2.3063 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.2279 - accuracy: 0.9583 - val_loss: 1.9975 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.2429 - accuracy: 0.9479 - val_loss: 1.9196 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.2243 - accuracy: 0.9688 - val_loss: 1.9682 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.2017 - accuracy: 0.9688 - val_loss: 1.8238 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.1726 - accuracy: 0.9792 - val_loss: 2.0648 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.1518 - accuracy: 0.9896 - val_loss: 2.1454 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.1573 - accuracy: 0.9792 - val_loss: 1.9791 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.1383 - accuracy: 0.9896 - val_loss: 2.3374 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.1450 - accuracy: 0.9688 - val_loss: 1.7180 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:04:56.443602: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.62      0.56        16\n",
      "         1.0       0.50      0.38      0.43        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.49        32\n",
      "weighted avg       0.50      0.50      0.49        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_255 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_758 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_759 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_888 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_886 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_504 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_760 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_760 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_889 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_887 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_505 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_761 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_761 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_890 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_888 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_506 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_762 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_762 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_891 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_889 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_507 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_763 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_890 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.0377 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.0377 - accuracy: 0.4688 - val_loss: 27.3673 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8628 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.8628 - accuracy: 0.5208 - val_loss: 1.2682 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0254 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0254 - accuracy: 0.5417 - val_loss: 0.6720 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 1.1513 - accuracy: 0.5729 - val_loss: 0.9890 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 1.1282 - accuracy: 0.5312 - val_loss: 0.8540 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.8592 - accuracy: 0.5521 - val_loss: 0.9724 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.8182 - accuracy: 0.5417 - val_loss: 1.0549 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.7658 - accuracy: 0.6354 - val_loss: 0.7350 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.6562INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6239 - accuracy: 0.6562 - val_loss: 0.6052 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.6646 - accuracy: 0.6146 - val_loss: 0.6516 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.5847 - accuracy: 0.6771 - val_loss: 0.6193 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.5881 - accuracy: 0.6667 - val_loss: 0.6682 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.5629 - accuracy: 0.7083 - val_loss: 0.6264 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 136ms/step - loss: 0.5474 - accuracy: 0.6979 - val_loss: 0.6517 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.5481 - accuracy: 0.6875 - val_loss: 0.6835 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.5384 - accuracy: 0.7396 - val_loss: 0.6774 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4971 - accuracy: 0.7812 - val_loss: 0.6835 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.5109 - accuracy: 0.7188 - val_loss: 0.7458 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.5190 - accuracy: 0.6979 - val_loss: 0.7231 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.5024 - accuracy: 0.7083 - val_loss: 0.6967 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4922 - accuracy: 0.7500 - val_loss: 0.7728 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.5213 - accuracy: 0.6979 - val_loss: 0.7720 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.4942 - accuracy: 0.7500 - val_loss: 0.7058 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.7213 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.4734 - accuracy: 0.7500 - val_loss: 0.7381 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.4734 - accuracy: 0.7500 - val_loss: 0.6950 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.8491 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.4850 - accuracy: 0.7396 - val_loss: 0.9459 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.4671 - accuracy: 0.7500 - val_loss: 0.9302 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:05:39.671195: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.50      0.44        16\n",
      "         1.0       0.33      0.25      0.29        16\n",
      "\n",
      "    accuracy                           0.38        32\n",
      "   macro avg       0.37      0.38      0.37        32\n",
      "weighted avg       0.37      0.38      0.37        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 4\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_257 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_768 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_896 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_128 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_897 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_896 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_256 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_768 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_128 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_898 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_897 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_257 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_769 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7220 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 974ms/step - loss: 0.7220 - accuracy: 0.5417 - val_loss: 0.9985 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.6860 - accuracy: 0.6042 - val_loss: 3.6965 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.6016 - accuracy: 0.6875 - val_loss: 4.4867 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.5515 - accuracy: 0.6979 - val_loss: 3.6838 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.5182 - accuracy: 0.7604 - val_loss: 3.6615 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.4734 - accuracy: 0.8125 - val_loss: 3.5433 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.4264 - accuracy: 0.8646 - val_loss: 3.4051 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.4037 - accuracy: 0.8542 - val_loss: 3.2377 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3858 - accuracy: 0.8750 - val_loss: 2.8631 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.3705 - accuracy: 0.8750 - val_loss: 2.7995 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3191 - accuracy: 0.8854 - val_loss: 2.3370 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.3206 - accuracy: 0.9167 - val_loss: 2.3535 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2783 - accuracy: 0.9062 - val_loss: 2.4303 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2833 - accuracy: 0.8854 - val_loss: 2.1052 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.2462 - accuracy: 0.9271 - val_loss: 2.1435 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.2438 - accuracy: 0.9271 - val_loss: 2.2541 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.2191 - accuracy: 0.9688 - val_loss: 2.0907 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.1936 - accuracy: 0.9479 - val_loss: 2.1942 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1590 - accuracy: 0.9792 - val_loss: 2.3811 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1571 - accuracy: 0.9792 - val_loss: 2.2225 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 2.0719 - val_accuracy: 0.4375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:09:42.430560: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.44      0.42        16\n",
      "         1.0       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.41      0.41      0.41        32\n",
      "weighted avg       0.41      0.41      0.41        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_259 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_770 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_771 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_902 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_900 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_512 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_772 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_772 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_903 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_901 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_513 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_773 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_773 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_904 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_902 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_514 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_774 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_774 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_905 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_903 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_515 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_775 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_904 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.2601 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 8.2601 - accuracy: 0.5000 - val_loss: 25.7214 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5109 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5109 - accuracy: 0.6250 - val_loss: 12.4064 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5326 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5326 - accuracy: 0.5833 - val_loss: 2.0222 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2251 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.2251 - accuracy: 0.5521 - val_loss: 0.9388 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.7872 - accuracy: 0.6146 - val_loss: 1.2762 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.2479 - accuracy: 0.5208 - val_loss: 1.4634 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9420 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in12_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9420 - accuracy: 0.5729 - val_loss: 0.8533 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.6292 - accuracy: 0.6458 - val_loss: 1.0065 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.6210 - accuracy: 0.6875 - val_loss: 0.9397 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5970 - accuracy: 0.6875 - val_loss: 0.9324 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.5537 - accuracy: 0.6979 - val_loss: 0.9040 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5789 - accuracy: 0.6979 - val_loss: 0.9360 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5613 - accuracy: 0.7188 - val_loss: 0.9767 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5312 - accuracy: 0.7708 - val_loss: 1.0752 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5262 - accuracy: 0.7500 - val_loss: 1.1026 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5055 - accuracy: 0.7500 - val_loss: 1.0850 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5094 - accuracy: 0.7604 - val_loss: 1.1114 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4755 - accuracy: 0.7604 - val_loss: 1.0826 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 1.1681 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4590 - accuracy: 0.8021 - val_loss: 1.2215 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4643 - accuracy: 0.7604 - val_loss: 1.1798 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 1.1489 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4833 - accuracy: 0.7917 - val_loss: 1.2705 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4267 - accuracy: 0.7708 - val_loss: 1.2538 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4721 - accuracy: 0.7812 - val_loss: 1.2434 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4176 - accuracy: 0.8229 - val_loss: 1.2284 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 1.3295 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:10:10.884687: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in12_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in12_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.44      0.58        16\n",
      "         1.0       0.62      0.94      0.75        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.75      0.69      0.67        32\n",
      "weighted avg       0.75      0.69      0.67        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB =  13\n",
      "batch : 0\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_260\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_261 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_780 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_910 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_130 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_911 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_910 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_260 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_780 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_130 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_912 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_911 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_261 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_781 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7229 - accuracy: 0.5521 - val_loss: 1.0044 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.6471 - accuracy: 0.6250 - val_loss: 1.7275 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.5997 - accuracy: 0.6771 - val_loss: 2.5702 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.5189 - accuracy: 0.7708 - val_loss: 3.2185 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.4863 - accuracy: 0.8333 - val_loss: 2.5751 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.4366 - accuracy: 0.8125 - val_loss: 2.6380 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3941 - accuracy: 0.8542 - val_loss: 2.0007 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.3593 - accuracy: 0.8646 - val_loss: 2.0512 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.3379 - accuracy: 0.8958 - val_loss: 1.5230 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.3367 - accuracy: 0.8333 - val_loss: 1.9211 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.3049 - accuracy: 0.8958 - val_loss: 1.9385 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.2792 - accuracy: 0.8958 - val_loss: 1.6960 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.2347 - accuracy: 0.9479 - val_loss: 1.7858 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.2322 - accuracy: 0.9583 - val_loss: 1.8360 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.2015 - accuracy: 0.9583 - val_loss: 1.7911 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2069 - accuracy: 0.9583 - val_loss: 1.6548 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1863 - accuracy: 0.9792 - val_loss: 1.6291 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2036 - accuracy: 0.9375 - val_loss: 1.5118 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.1718 - accuracy: 0.9792 - val_loss: 1.6812 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.1535 - accuracy: 0.9688 - val_loss: 1.6260 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.1363 - accuracy: 0.9896 - val_loss: 1.7437 - val_accuracy: 0.5000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:13:54.885666: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.56      0.55        16\n",
      "         1.0       0.53      0.50      0.52        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.53        32\n",
      "weighted avg       0.53      0.53      0.53        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_262\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_263 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_782 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_783 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_916 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_914 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_520 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_784 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_784 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_917 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_915 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_521 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_785 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_785 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_918 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_916 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_522 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_786 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_786 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_919 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_917 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_523 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_787 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_918 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.4768 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 9.4768 - accuracy: 0.5000 - val_loss: 16.9416 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.8686 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.8686 - accuracy: 0.5104 - val_loss: 12.3438 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.2281 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.2281 - accuracy: 0.5104 - val_loss: 5.3729 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1946 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.1946 - accuracy: 0.5208 - val_loss: 1.2527 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.6354INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7014 - accuracy: 0.6354 - val_loss: 0.8565 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6360 - accuracy: 0.6250 - val_loss: 1.4645 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.4688INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 1.0046 - accuracy: 0.4688 - val_loss: 0.7181 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.9050 - accuracy: 0.5625 - val_loss: 1.0785 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6968 - accuracy: 0.5938 - val_loss: 0.6503 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6712 - accuracy: 0.5312 - val_loss: 0.7798 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.6117 - accuracy: 0.6458 - val_loss: 0.7635 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6066 - accuracy: 0.6875 - val_loss: 0.8623 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5823 - accuracy: 0.6354 - val_loss: 0.8614 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5739 - accuracy: 0.6771 - val_loss: 0.9738 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5992 - accuracy: 0.6875 - val_loss: 0.8411 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5079 - accuracy: 0.7292 - val_loss: 0.9114 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5364 - accuracy: 0.7292 - val_loss: 0.9640 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.8808 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4873 - accuracy: 0.7812 - val_loss: 0.7933 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.4397 - accuracy: 0.8021 - val_loss: 0.9819 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4667 - accuracy: 0.7917 - val_loss: 1.0233 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4122 - accuracy: 0.7708 - val_loss: 0.9913 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.4320 - accuracy: 0.7500 - val_loss: 0.9555 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3813 - accuracy: 0.8646 - val_loss: 1.0135 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.3896 - accuracy: 0.8125 - val_loss: 1.0729 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 1.1717 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3969 - accuracy: 0.8021 - val_loss: 1.1759 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3801 - accuracy: 0.8229 - val_loss: 1.1843 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5239 - accuracy: 0.7500 - val_loss: 1.0290 - val_accuracy: 0.6250 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:14:32.750277: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        16\n",
      "         1.0       0.50      1.00      0.67        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.25      0.50      0.33        32\n",
      "weighted avg       0.25      0.50      0.33        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_264\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_265 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_792 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_924 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_132 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_925 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_924 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_264 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_792 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_132 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_926 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_925 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_265 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_793 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.5208INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 0.7169 - accuracy: 0.5208 - val_loss: 1.1974 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.6282 - accuracy: 0.6354 - val_loss: 4.7161 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5627 - accuracy: 0.6979 - val_loss: 5.0172 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.5173 - accuracy: 0.7812 - val_loss: 7.9445 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.5062 - accuracy: 0.8333 - val_loss: 7.3679 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.4597 - accuracy: 0.8333 - val_loss: 5.7854 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.4370 - accuracy: 0.8333 - val_loss: 6.2965 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.3935 - accuracy: 0.8542 - val_loss: 4.9773 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.3933 - accuracy: 0.8542 - val_loss: 3.2796 - val_accuracy: 0.2812 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3434 - accuracy: 0.9062 - val_loss: 3.5310 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3520 - accuracy: 0.8750 - val_loss: 3.6643 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2926 - accuracy: 0.9479 - val_loss: 2.9551 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2752 - accuracy: 0.9271 - val_loss: 3.2476 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.2617 - accuracy: 0.8958 - val_loss: 3.5272 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2101 - accuracy: 0.9688 - val_loss: 2.8118 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.2450 - accuracy: 0.8958 - val_loss: 2.9386 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.2001 - accuracy: 0.9688 - val_loss: 2.4131 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1865 - accuracy: 0.9896 - val_loss: 2.7926 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1742 - accuracy: 0.9688 - val_loss: 2.2881 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.1620 - accuracy: 0.9792 - val_loss: 2.2349 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1669 - accuracy: 0.9688 - val_loss: 2.4233 - val_accuracy: 0.5000 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:17:23.234245: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.81      0.58        16\n",
      "         1.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.22      0.41      0.29        32\n",
      "weighted avg       0.22      0.41      0.29        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_266\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_267 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_794 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_795 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_930 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_928 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_528 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_796 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_796 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_931 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_929 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_529 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_797 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_797 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_932 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_930 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_530 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_798 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_798 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_933 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_931 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_531 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_799 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_132 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_932 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.6540 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 8.6540 - accuracy: 0.5521 - val_loss: 26.4881 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.3393 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.3393 - accuracy: 0.5417 - val_loss: 1.5744 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1324 - accuracy: 0.5521INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.1324 - accuracy: 0.5521 - val_loss: 1.3164 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 1.1854 - accuracy: 0.5833 - val_loss: 1.4454 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7360 - accuracy: 0.6979INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7360 - accuracy: 0.6979 - val_loss: 1.0402 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.6875INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7471 - accuracy: 0.6875 - val_loss: 1.0076 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5759 - accuracy: 0.7396 - val_loss: 1.1323 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5321 - accuracy: 0.7292 - val_loss: 1.2918 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4125 - accuracy: 0.8229 - val_loss: 1.1814 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4369 - accuracy: 0.7708 - val_loss: 1.2392 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4155 - accuracy: 0.7917 - val_loss: 1.2075 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5081 - accuracy: 0.7917 - val_loss: 1.1180 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5379 - accuracy: 0.7708 - val_loss: 1.6314 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 1.1381 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3671 - accuracy: 0.8125 - val_loss: 1.0224 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3681 - accuracy: 0.8438 - val_loss: 1.0701 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.3054 - accuracy: 0.8229 - val_loss: 1.0800 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2861 - accuracy: 0.9167 - val_loss: 1.3934 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.3475 - accuracy: 0.8333 - val_loss: 1.4319 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3569 - accuracy: 0.8750 - val_loss: 1.6072 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3831 - accuracy: 0.8333 - val_loss: 1.2652 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3524 - accuracy: 0.8438 - val_loss: 1.3791 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3476 - accuracy: 0.8438 - val_loss: 1.2683 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.2391 - accuracy: 0.9167 - val_loss: 1.2870 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.2503 - accuracy: 0.9167 - val_loss: 1.4018 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.2983 - accuracy: 0.8750 - val_loss: 1.4050 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:17:51.254790: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.38      0.44        16\n",
      "         1.0       0.52      0.69      0.59        16\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.53      0.53      0.52        32\n",
      "weighted avg       0.53      0.53      0.52        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 2\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_268\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_269 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_804 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_938 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_134 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_939 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_938 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_268 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_804 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_134 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_940 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_939 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_269 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_805 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.4375INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7779 - accuracy: 0.4375 - val_loss: 0.9003 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.6577 - accuracy: 0.5208 - val_loss: 1.4892 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.5986 - accuracy: 0.6458 - val_loss: 1.8280 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.5707 - accuracy: 0.6875 - val_loss: 2.1830 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.5260 - accuracy: 0.7292 - val_loss: 2.3974 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 2.2233 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 2.1524 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.4418 - accuracy: 0.8333 - val_loss: 2.0961 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.3879 - accuracy: 0.8229 - val_loss: 2.0154 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.3884 - accuracy: 0.8542 - val_loss: 1.8306 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.3323 - accuracy: 0.9062 - val_loss: 1.9109 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.3187 - accuracy: 0.8958 - val_loss: 2.1253 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.2868 - accuracy: 0.9062 - val_loss: 1.6068 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.3190 - accuracy: 0.8958 - val_loss: 1.4865 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.2514 - accuracy: 0.9375 - val_loss: 1.8492 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.2262 - accuracy: 0.9479 - val_loss: 1.8906 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.2142 - accuracy: 0.9375 - val_loss: 1.9372 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.2111 - accuracy: 0.9583 - val_loss: 1.7995 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.1785 - accuracy: 0.9792 - val_loss: 1.7710 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.1649 - accuracy: 0.9792 - val_loss: 1.7470 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1570 - accuracy: 0.9896 - val_loss: 1.6602 - val_accuracy: 0.4062 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:20:26.934796: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.40        16\n",
      "         1.0       0.57      1.00      0.73        16\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.79      0.62      0.56        32\n",
      "weighted avg       0.79      0.62      0.56        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_270\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_271 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_806 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_807 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_944 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_942 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_536 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_808 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_808 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_945 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_943 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_537 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_809 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_809 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_946 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_944 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_538 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_810 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_810 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_947 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_945 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_539 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_811 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_946 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.8207 - accuracy: 0.4896INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 5s 1s/step - loss: 10.8207 - accuracy: 0.4896 - val_loss: 7.1378 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.3313 - accuracy: 0.4062INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.3313 - accuracy: 0.4062 - val_loss: 2.3184 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3138 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.3138 - accuracy: 0.5938 - val_loss: 1.5313 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9894 - accuracy: 0.5104 - val_loss: 0.9655 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2789 - accuracy: 0.5417INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.2789 - accuracy: 0.5417 - val_loss: 0.9561 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9415 - accuracy: 0.4479INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9415 - accuracy: 0.4479 - val_loss: 0.8615 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.7417 - accuracy: 0.5521 - val_loss: 0.9814 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.8276 - accuracy: 0.5625 - val_loss: 1.1494 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.7679 - accuracy: 0.5833 - val_loss: 0.9531 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6806 - accuracy: 0.5938INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6806 - accuracy: 0.5938 - val_loss: 0.8195 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.6146INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6324 - accuracy: 0.6146 - val_loss: 0.7853 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5924 - accuracy: 0.6771 - val_loss: 0.8135 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.6035 - accuracy: 0.6979 - val_loss: 0.8140 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.6331 - accuracy: 0.6458 - val_loss: 0.7934 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6379 - accuracy: 0.6875 - val_loss: 0.8678 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.6325 - accuracy: 0.6250 - val_loss: 0.7753 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5843 - accuracy: 0.6979 - val_loss: 0.7953 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5617 - accuracy: 0.7188 - val_loss: 0.8290 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5807 - accuracy: 0.7083 - val_loss: 0.8120 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5458 - accuracy: 0.6458 - val_loss: 0.7901 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5043 - accuracy: 0.7500 - val_loss: 0.8572 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.5403 - accuracy: 0.7604 - val_loss: 0.8913 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5439 - accuracy: 0.6875 - val_loss: 0.8845 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5027 - accuracy: 0.7396 - val_loss: 0.8308 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5545 - accuracy: 0.6979 - val_loss: 0.8730 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5751 - accuracy: 0.6667 - val_loss: 1.2631 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.6250INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6285 - accuracy: 0.6250 - val_loss: 0.7673 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.7083INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6170 - accuracy: 0.7083 - val_loss: 0.7165 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5908 - accuracy: 0.7083 - val_loss: 0.8170 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.7628 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4063 - accuracy: 0.7708 - val_loss: 0.7800 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 1.0145 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4294 - accuracy: 0.8229 - val_loss: 0.9069 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4032 - accuracy: 0.8542 - val_loss: 0.8541 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3298 - accuracy: 0.8750 - val_loss: 0.8575 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3755 - accuracy: 0.8229 - val_loss: 0.7910 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.3406 - accuracy: 0.8438 - val_loss: 1.4245 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.3645 - accuracy: 0.8646 - val_loss: 1.5593 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8333INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 3s 1s/step - loss: 0.3818 - accuracy: 0.8333 - val_loss: 0.6683 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.4019 - accuracy: 0.8021 - val_loss: 0.8724 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3533 - accuracy: 0.8333 - val_loss: 0.8939 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3132 - accuracy: 0.8646 - val_loss: 1.0656 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.2501 - accuracy: 0.8854 - val_loss: 0.9532 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3727 - accuracy: 0.8333 - val_loss: 1.8675 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3126 - accuracy: 0.8542 - val_loss: 0.9907 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.3238 - accuracy: 0.8542 - val_loss: 0.8053 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3172 - accuracy: 0.8542 - val_loss: 0.7689 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.2257 - accuracy: 0.9167 - val_loss: 1.3054 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.1630 - accuracy: 0.9479 - val_loss: 0.8897 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.2124 - accuracy: 0.9062 - val_loss: 1.0856 - val_accuracy: 0.6562 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.2127 - accuracy: 0.9062 - val_loss: 0.9145 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.1763 - accuracy: 0.9375 - val_loss: 1.3910 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.2836 - accuracy: 0.8646 - val_loss: 0.9885 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1926 - accuracy: 0.9167 - val_loss: 0.9733 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4964 - accuracy: 0.7917 - val_loss: 1.2967 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4063 - accuracy: 0.8333 - val_loss: 1.2231 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.3437 - accuracy: 0.8229 - val_loss: 0.7786 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1894 - accuracy: 0.8958 - val_loss: 0.9716 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.1635 - accuracy: 0.9479 - val_loss: 1.1144 - val_accuracy: 0.5312 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:21:29.309153: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.62      0.61        16\n",
      "         1.0       0.60      0.56      0.58        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.59      0.59      0.59        32\n",
      "weighted avg       0.59      0.59      0.59        32\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 3\n",
      "(128, 15, 448) (32, 15, 448)\n",
      "method =  covariance\n",
      "method =  raw\n",
      "method =  fft2\n",
      "method =  fft\n",
      "method =  cross_correlate\n",
      "method =  maxmin\n",
      "method =  meanstd\n",
      "method =  variance\n",
      "method =  spectral_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method =  all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no delete\n",
      "Model: \"model_272\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_273 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_816 (Conv2D)         (None, 15, 448, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_952 (Ba  (None, 15, 448, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_136 (Depth  (None, 1, 448, 16)       240       \n",
      " wiseConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_953 (Ba  (None, 1, 448, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_952 (Activation)  (None, 1, 448, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_272 (Aver  (None, 1, 112, 16)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_816 (Dropout)       (None, 1, 112, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_136 (Separ  (None, 1, 112, 16)       1056      \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_954 (Ba  (None, 1, 112, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_953 (Activation)  (None, 1, 112, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_273 (Aver  (None, 1, 14, 16)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_817 (Dropout)       (None, 1, 14, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 450       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.4792INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7452 - accuracy: 0.4792 - val_loss: 1.0861 - val_accuracy: 0.3125 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.6077 - accuracy: 0.6875 - val_loss: 4.4331 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.5263 - accuracy: 0.7500 - val_loss: 6.2043 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.4707 - accuracy: 0.8021 - val_loss: 7.1470 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.4209 - accuracy: 0.8229 - val_loss: 6.4966 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.3745 - accuracy: 0.8646 - val_loss: 6.0390 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.3503 - accuracy: 0.8958 - val_loss: 4.7829 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.2835 - accuracy: 0.9479 - val_loss: 4.1699 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.2735 - accuracy: 0.9062 - val_loss: 4.0551 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.2555 - accuracy: 0.9271 - val_loss: 3.3723 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.2356 - accuracy: 0.9271 - val_loss: 3.2051 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.2016 - accuracy: 0.9792 - val_loss: 3.1860 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.2101 - accuracy: 0.9479 - val_loss: 2.8229 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.2136 - accuracy: 0.9479 - val_loss: 3.0035 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.1628 - accuracy: 0.9792 - val_loss: 2.6301 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.1858 - accuracy: 0.9479 - val_loss: 2.6763 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.1568 - accuracy: 0.9792 - val_loss: 2.7695 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.1405 - accuracy: 0.9792 - val_loss: 2.5536 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.1473 - accuracy: 0.9896 - val_loss: 2.0995 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.1196 - accuracy: 0.9896 - val_loss: 2.2600 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1103 - accuracy: 0.9896 - val_loss: 2.3224 - val_accuracy: 0.4688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:23:57.442519: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/smr_dep_sub_1in13_out_weights.tf: FAILED_PRECONDITION: log/smr_dep_sub_1in13_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50        16\n",
      "         1.0       0.50      0.50      0.50        16\n",
      "\n",
      "    accuracy                           0.50        32\n",
      "   macro avg       0.50      0.50      0.50        32\n",
      "weighted avg       0.50      0.50      0.50        32\n",
      "\n",
      "F1-score is computed based on binary\n",
      "no delete\n",
      "Model: \"model_274\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_275 (InputLayer)      [(None, 15, 448, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_818 (Conv2D)         (None, 15, 444, 25)       150       \n",
      "                                                                 \n",
      " conv2d_819 (Conv2D)         (None, 1, 444, 25)        9400      \n",
      "                                                                 \n",
      " batch_normalization_958 (Ba  (None, 1, 444, 25)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_956 (Activation)  (None, 1, 444, 25)       0         \n",
      "                                                                 \n",
      " max_pooling2d_544 (MaxPooli  (None, 1, 222, 25)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_820 (Dropout)       (None, 1, 222, 25)        0         \n",
      "                                                                 \n",
      " conv2d_820 (Conv2D)         (None, 1, 218, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_959 (Ba  (None, 1, 218, 50)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_957 (Activation)  (None, 1, 218, 50)       0         \n",
      "                                                                 \n",
      " max_pooling2d_545 (MaxPooli  (None, 1, 109, 50)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_821 (Dropout)       (None, 1, 109, 50)        0         \n",
      "                                                                 \n",
      " conv2d_821 (Conv2D)         (None, 1, 105, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_960 (Ba  (None, 1, 105, 100)      4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_958 (Activation)  (None, 1, 105, 100)      0         \n",
      "                                                                 \n",
      " max_pooling2d_546 (MaxPooli  (None, 1, 52, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_822 (Dropout)       (None, 1, 52, 100)        0         \n",
      "                                                                 \n",
      " conv2d_822 (Conv2D)         (None, 1, 48, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_961 (Ba  (None, 1, 48, 200)       4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_959 (Activation)  (None, 1, 48, 200)       0         \n",
      "                                                                 \n",
      " max_pooling2d_547 (MaxPooli  (None, 1, 24, 200)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_823 (Dropout)       (None, 1, 24, 200)        0         \n",
      "                                                                 \n",
      " flatten_136 (Flatten)       (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 2)                 9602      \n",
      "                                                                 \n",
      " activation_960 (Activation)  (None, 2)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,768\n",
      "Trainable params: 150,760\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.3840 - accuracy: 0.5729INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 6s 1s/step - loss: 8.3840 - accuracy: 0.5729 - val_loss: 3.5355 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 2.2507 - accuracy: 0.5312 - val_loss: 3.9741 - val_accuracy: 0.2500 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1236 - accuracy: 0.6771INFO:tensorflow:Assets written to: log/smr_dep_sub_1in13_out_weights.tf/assets\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.1236 - accuracy: 0.6771 - val_loss: 1.1191 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.9257 - accuracy: 0.6458 - val_loss: 1.5769 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.9683 - accuracy: 0.5938 - val_loss: 1.6815 - val_accuracy: 0.3438 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.6952 - accuracy: 0.7292 - val_loss: 1.3440 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.7848 - accuracy: 0.6042 - val_loss: 1.2653 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.6135 - accuracy: 0.7396 - val_loss: 1.2682 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.5227 - accuracy: 0.7604 - val_loss: 1.4232 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.5035 - accuracy: 0.7812 - val_loss: 1.1826 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4878 - accuracy: 0.8021 - val_loss: 1.1415 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4139 - accuracy: 0.8125 - val_loss: 1.2440 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4154 - accuracy: 0.8229 - val_loss: 1.1906 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.3996 - accuracy: 0.7917 - val_loss: 1.2845 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.3722 - accuracy: 0.8229 - val_loss: 1.4641 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3713 - accuracy: 0.8438 - val_loss: 1.3613 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.3318 - accuracy: 0.8438 - val_loss: 1.2036 - val_accuracy: 0.4688 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = []\n",
    "for sub in range(len(X_smr)):\n",
    "    print('SUB = ',sub)\n",
    "    smr_dep = Experiment.single_subject_dependent_cv(X_smr[sub],y_smr[sub],\n",
    "                                                      seed=0,verbose=1,model_name='smr_dep_sub_1in'+str(sub),\n",
    "                                                      benchmarks=['EEGNet','DeepConvNet','EEGene']\n",
    "                                                     )\n",
    "    scores.append(smr_dep)\n",
    "    np.save('final_report/smr_dep_1in.npy',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ac309e-c0ee-4345-ac80-0382f5db7897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>+-acc</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>+-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EEGene</td>\n",
       "      <td>72.99</td>\n",
       "      <td>14.33</td>\n",
       "      <td>71.05</td>\n",
       "      <td>17.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>69.06</td>\n",
       "      <td>15.51</td>\n",
       "      <td>67.88</td>\n",
       "      <td>17.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cross_correlate</td>\n",
       "      <td>68.93</td>\n",
       "      <td>16.96</td>\n",
       "      <td>67.57</td>\n",
       "      <td>19.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covariance</td>\n",
       "      <td>68.62</td>\n",
       "      <td>13.64</td>\n",
       "      <td>67.82</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>variance</td>\n",
       "      <td>65.85</td>\n",
       "      <td>13.59</td>\n",
       "      <td>64.72</td>\n",
       "      <td>14.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meanstd</td>\n",
       "      <td>64.06</td>\n",
       "      <td>15.77</td>\n",
       "      <td>62.51</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeepConvNet</td>\n",
       "      <td>62.19</td>\n",
       "      <td>16.67</td>\n",
       "      <td>60.28</td>\n",
       "      <td>21.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>61.79</td>\n",
       "      <td>13.63</td>\n",
       "      <td>60.46</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>57.86</td>\n",
       "      <td>14.08</td>\n",
       "      <td>54.83</td>\n",
       "      <td>18.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>maxmin</td>\n",
       "      <td>57.32</td>\n",
       "      <td>12.95</td>\n",
       "      <td>55.51</td>\n",
       "      <td>14.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>56.07</td>\n",
       "      <td>10.10</td>\n",
       "      <td>53.15</td>\n",
       "      <td>12.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fft2</td>\n",
       "      <td>54.87</td>\n",
       "      <td>10.56</td>\n",
       "      <td>51.56</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fft</td>\n",
       "      <td>53.62</td>\n",
       "      <td>11.81</td>\n",
       "      <td>49.94</td>\n",
       "      <td>13.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method  accuracy  +-acc  f1-score  +-f1\n",
       "12            EEGene     72.99  14.33     71.05 17.58\n",
       "9                all     69.06  15.51     67.88 17.47\n",
       "4    cross_correlate     68.93  16.96     67.57 19.04\n",
       "0         covariance     68.62  13.64     67.82 14.62\n",
       "7           variance     65.85  13.59     64.72 14.85\n",
       "6            meanstd     64.06  15.77     62.51 17.00\n",
       "11       DeepConvNet     62.19  16.67     60.28 21.42\n",
       "8   spectral_entropy     61.79  13.63     60.46 15.09\n",
       "10            EEGNet     57.86  14.08     54.83 18.44\n",
       "5             maxmin     57.32  12.95     55.51 14.38\n",
       "1                raw     56.07  10.10     53.15 12.03\n",
       "2               fft2     54.87  10.56     51.56 13.09\n",
       "3                fft     53.62  11.81     49.94 13.41"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment.make_final_report(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75316ef5-b08d-481b-a70c-b80d3564d8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:07:51.692363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-05 22:07:51.692435: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import EEGene\n",
    "import misc\n",
    "import Benchmarks\n",
    "from EEGene import EEGene,Processing\n",
    "from misc import Experiment,Data_Loader,Baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa9a758-b302-425e-aeba-fbaa3dcaa0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing from all possible events\n"
     ]
    }
   ],
   "source": [
    "DL = Data_Loader()\n",
    "X_faller,y_faller = DL.load_faller(sub=-1,fmin=0.5,fmax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355487f0-7766-4558-ac1e-ae862930703a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:19:06.495349: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-12-05 22:19:06.495421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: bob\n",
      "2022-12-05 22:19:06.495431: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: bob\n",
      "2022-12-05 22:19:06.496507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2022-12-05 22:19:06.496547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.85.2\n",
      "2022-12-05 22:19:06.496555: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 510.85.2 does not match DSO version 510.108.3 -- cannot find working devices in this configuration\n",
      "2022-12-05 22:19:06.497520: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 500, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 13, 500, 8)       32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 1, 500, 16)       208       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 500, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 125, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1, 125, 16)       1056      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 125, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 15, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.5142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:19:45.890959: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.7187 - accuracy: 0.5142 - val_loss: 0.6926 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5717INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 36s 9s/step - loss: 0.6763 - accuracy: 0.5717 - val_loss: 0.6904 - val_accuracy: 0.5225 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 36s 9s/step - loss: 0.6576 - accuracy: 0.6094 - val_loss: 0.7005 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.6227INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 40s 11s/step - loss: 0.6442 - accuracy: 0.6227 - val_loss: 0.6879 - val_accuracy: 0.5425 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.6364 - accuracy: 0.6435 - val_loss: 0.6932 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 34s 9s/step - loss: 0.6320 - accuracy: 0.6513 - val_loss: 0.7053 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.6248 - accuracy: 0.6562 - val_loss: 0.7121 - val_accuracy: 0.5425 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 30s 8s/step - loss: 0.6174 - accuracy: 0.6658 - val_loss: 0.7373 - val_accuracy: 0.5225 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 29s 7s/step - loss: 0.5991 - accuracy: 0.6815 - val_loss: 0.8190 - val_accuracy: 0.5050 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.5859 - accuracy: 0.6933 - val_loss: 0.8460 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.5692 - accuracy: 0.7073 - val_loss: 0.7143 - val_accuracy: 0.5675 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 32s 8s/step - loss: 0.5491 - accuracy: 0.7135 - val_loss: 0.6952 - val_accuracy: 0.5925 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7273INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.5379 - accuracy: 0.7273 - val_loss: 0.6651 - val_accuracy: 0.6225 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.7273INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 32s 8s/step - loss: 0.5304 - accuracy: 0.7273 - val_loss: 0.6523 - val_accuracy: 0.6275 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 37s 9s/step - loss: 0.5266 - accuracy: 0.7319 - val_loss: 0.6547 - val_accuracy: 0.6275 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 33s 9s/step - loss: 0.5180 - accuracy: 0.7402 - val_loss: 0.7013 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.5167 - accuracy: 0.7352 - val_loss: 0.7767 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.5096 - accuracy: 0.7415 - val_loss: 0.7177 - val_accuracy: 0.5925 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.5055 - accuracy: 0.7415 - val_loss: 0.7492 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 36s 9s/step - loss: 0.5067 - accuracy: 0.7462 - val_loss: 0.7601 - val_accuracy: 0.5825 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.5017 - accuracy: 0.7446 - val_loss: 0.7380 - val_accuracy: 0.5875 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 34s 9s/step - loss: 0.5021 - accuracy: 0.7442 - val_loss: 0.7686 - val_accuracy: 0.5775 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.4966 - accuracy: 0.7527 - val_loss: 0.8233 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 34s 8s/step - loss: 0.4942 - accuracy: 0.7529 - val_loss: 0.8710 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 33s 9s/step - loss: 0.4915 - accuracy: 0.7517 - val_loss: 0.8286 - val_accuracy: 0.5600 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 42s 11s/step - loss: 0.4934 - accuracy: 0.7569 - val_loss: 0.9170 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.4875 - accuracy: 0.7531 - val_loss: 0.7123 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 37s 9s/step - loss: 0.4824 - accuracy: 0.7627 - val_loss: 1.0110 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 36s 9s/step - loss: 0.4787 - accuracy: 0.7638 - val_loss: 0.7713 - val_accuracy: 0.5900 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 38s 9s/step - loss: 0.4784 - accuracy: 0.7606 - val_loss: 0.8912 - val_accuracy: 0.5775 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.4737 - accuracy: 0.7623 - val_loss: 0.8133 - val_accuracy: 0.5875 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.4729 - accuracy: 0.7683 - val_loss: 0.7660 - val_accuracy: 0.6100 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.7735INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 33s 9s/step - loss: 0.4664 - accuracy: 0.7735 - val_loss: 0.6400 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 31s 8s/step - loss: 0.4663 - accuracy: 0.7752 - val_loss: 0.6400 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.7625INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 35s 9s/step - loss: 0.4700 - accuracy: 0.7625 - val_loss: 0.6377 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.7700INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.4634 - accuracy: 0.7700 - val_loss: 0.6323 - val_accuracy: 0.6750 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.4650 - accuracy: 0.7773 - val_loss: 0.6417 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.4562 - accuracy: 0.7798 - val_loss: 0.6445 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.4576 - accuracy: 0.7815 - val_loss: 0.6407 - val_accuracy: 0.6750 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7842INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.4537 - accuracy: 0.7842 - val_loss: 0.6258 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.4508 - accuracy: 0.7808 - val_loss: 0.6908 - val_accuracy: 0.6525 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.4457 - accuracy: 0.7806 - val_loss: 0.7614 - val_accuracy: 0.6400 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.4423 - accuracy: 0.7877 - val_loss: 0.6590 - val_accuracy: 0.6925 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 29s 7s/step - loss: 0.4424 - accuracy: 0.7783 - val_loss: 0.6654 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 32s 8s/step - loss: 0.4401 - accuracy: 0.7873 - val_loss: 0.6696 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 32s 8s/step - loss: 0.4351 - accuracy: 0.7902 - val_loss: 0.9145 - val_accuracy: 0.5875 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 35s 9s/step - loss: 0.4430 - accuracy: 0.7860 - val_loss: 0.6372 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.4310 - accuracy: 0.7933 - val_loss: 0.7422 - val_accuracy: 0.6350 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 32s 8s/step - loss: 0.4236 - accuracy: 0.7992 - val_loss: 0.9258 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 33s 9s/step - loss: 0.4197 - accuracy: 0.8017 - val_loss: 0.8892 - val_accuracy: 0.5900 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.4237 - accuracy: 0.7990 - val_loss: 0.7774 - val_accuracy: 0.6300 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.4140 - accuracy: 0.8037 - val_loss: 0.9535 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.4122 - accuracy: 0.8142 - val_loss: 0.9621 - val_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.4168 - accuracy: 0.8000 - val_loss: 0.9376 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.4191 - accuracy: 0.7994 - val_loss: 0.9914 - val_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.4106 - accuracy: 0.8083 - val_loss: 0.7495 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.4139 - accuracy: 0.8069 - val_loss: 0.8631 - val_accuracy: 0.6200 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.4123 - accuracy: 0.8098 - val_loss: 0.7951 - val_accuracy: 0.6275 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 30s 7s/step - loss: 0.4009 - accuracy: 0.8148 - val_loss: 0.7872 - val_accuracy: 0.6175 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 31s 8s/step - loss: 0.4044 - accuracy: 0.8077 - val_loss: 0.8878 - val_accuracy: 0.6025 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:51:26.279556: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81       200\n",
      "         1.0       1.00      0.53      0.69       200\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.84      0.76      0.75       400\n",
      "weighted avg       0.84      0.76      0.75       400\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 496, 25)       150       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 496, 25)        8150      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 1, 496, 25)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 496, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 248, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 248, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 244, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1, 244, 50)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1, 244, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 122, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 122, 50)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 118, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1, 118, 100)      4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 118, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 59, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 59, 100)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 1, 55, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 1, 55, 200)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 55, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 27, 200)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 27, 200)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 10802     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,718\n",
      "Trainable params: 150,710\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.8441 - accuracy: 0.5131INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 7.8441 - accuracy: 0.5131 - val_loss: 18.2699 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.3557 - accuracy: 0.4933INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 21s 6s/step - loss: 6.3557 - accuracy: 0.4933 - val_loss: 9.3806 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4151 - accuracy: 0.4988INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 3.4151 - accuracy: 0.4988 - val_loss: 4.0241 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2643 - accuracy: 0.5125INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 2.2643 - accuracy: 0.5125 - val_loss: 3.2778 - val_accuracy: 0.5050 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.5060INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 1.6564 - accuracy: 0.5060 - val_loss: 2.2269 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3276 - accuracy: 0.4938INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.3276 - accuracy: 0.4938 - val_loss: 1.7293 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.5029INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 1.0842 - accuracy: 0.5029 - val_loss: 1.0796 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.9867 - accuracy: 0.5081 - val_loss: 1.1345 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8995 - accuracy: 0.5023INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.8995 - accuracy: 0.5023 - val_loss: 0.8110 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8193 - accuracy: 0.5163INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.8193 - accuracy: 0.5163 - val_loss: 0.7452 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.5077INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.7790 - accuracy: 0.5077 - val_loss: 0.7004 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7604 - accuracy: 0.5090 - val_loss: 0.7072 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7354 - accuracy: 0.5194 - val_loss: 0.7676 - val_accuracy: 0.5150 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7193 - accuracy: 0.5217 - val_loss: 0.7277 - val_accuracy: 0.4950 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7215 - accuracy: 0.5240 - val_loss: 0.7614 - val_accuracy: 0.5050 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7192 - accuracy: 0.5192 - val_loss: 0.7017 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.5285INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.7037 - accuracy: 0.5285 - val_loss: 0.6819 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.7044 - accuracy: 0.5329 - val_loss: 0.7320 - val_accuracy: 0.4975 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.5398INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.6978 - accuracy: 0.5398 - val_loss: 0.6812 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6971 - accuracy: 0.5448 - val_loss: 0.6886 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6917 - accuracy: 0.5440 - val_loss: 0.6932 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6946 - accuracy: 0.5310 - val_loss: 0.6971 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6892 - accuracy: 0.5467 - val_loss: 0.6897 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6935 - accuracy: 0.5435 - val_loss: 0.6940 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6957 - accuracy: 0.5358 - val_loss: 0.6943 - val_accuracy: 0.5225 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6925 - accuracy: 0.5437 - val_loss: 0.6856 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6960 - accuracy: 0.5481 - val_loss: 0.7179 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6957 - accuracy: 0.5385 - val_loss: 0.6969 - val_accuracy: 0.5400 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6937 - accuracy: 0.5481 - val_loss: 0.6913 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6952 - accuracy: 0.5392 - val_loss: 0.6971 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6860 - accuracy: 0.5577 - val_loss: 0.6856 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6895 - accuracy: 0.5508 - val_loss: 0.6911 - val_accuracy: 0.5425 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6897 - accuracy: 0.5490 - val_loss: 0.7148 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6949 - accuracy: 0.5427 - val_loss: 0.7087 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6935 - accuracy: 0.5419 - val_loss: 0.6827 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6923 - accuracy: 0.5477 - val_loss: 0.7057 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6930 - accuracy: 0.5510 - val_loss: 0.6901 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6954 - accuracy: 0.5429 - val_loss: 0.6889 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6907 - accuracy: 0.5546 - val_loss: 0.6989 - val_accuracy: 0.5375 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 23:01:44.431167: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.73      0.62       200\n",
      "         1.0       0.59      0.38      0.46       200\n",
      "\n",
      "    accuracy                           0.56       400\n",
      "   macro avg       0.56      0.55      0.54       400\n",
      "weighted avg       0.56      0.56      0.54       400\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  0\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "0         covariance     79.00   0.00     74.85  0.00\n",
      "12            EEGene     78.00   0.00     72.33  0.00\n",
      "10            EEGNet     76.25   0.00     68.85  0.00\n",
      "7           variance     69.50   0.00     60.39  0.00\n",
      "4    cross_correlate     67.75   0.00     55.05  0.00\n",
      "6            meanstd     67.50   0.00     54.23  0.00\n",
      "9                all     65.00   0.00     47.76  0.00\n",
      "8   spectral_entropy     59.00   0.00     52.60  0.00\n",
      "3                fft     57.75   0.00     50.15  0.00\n",
      "2               fft2     56.25   0.00     50.42  0.00\n",
      "5             maxmin     56.00   0.00     51.65  0.00\n",
      "1                raw     56.00   0.00     47.31  0.00\n",
      "11       DeepConvNet     55.50   0.00     45.73  0.00\n",
      "subject :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 13, 500, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 13, 500, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 1, 500, 16)       208       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 500, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 1, 125, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 1, 125, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 125, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 1, 15, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.5127INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.7198 - accuracy: 0.5127 - val_loss: 0.6945 - val_accuracy: 0.5350 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.6705 - accuracy: 0.5840 - val_loss: 0.7281 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.6153 - accuracy: 0.6565 - val_loss: 1.0358 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5763 - accuracy: 0.6946 - val_loss: 1.6336 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.5475 - accuracy: 0.7169 - val_loss: 2.0113 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5434 - accuracy: 0.7133 - val_loss: 2.2362 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5316 - accuracy: 0.7219 - val_loss: 2.5261 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5255 - accuracy: 0.7283 - val_loss: 2.6372 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5171 - accuracy: 0.7250 - val_loss: 2.6303 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5145 - accuracy: 0.7329 - val_loss: 2.5626 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5114 - accuracy: 0.7312 - val_loss: 2.1810 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5078 - accuracy: 0.7373 - val_loss: 2.4832 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5071 - accuracy: 0.7412 - val_loss: 2.5121 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4997 - accuracy: 0.7450 - val_loss: 2.3986 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.5011 - accuracy: 0.7431 - val_loss: 2.2221 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.4989 - accuracy: 0.7423 - val_loss: 2.3645 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 29s 8s/step - loss: 0.5005 - accuracy: 0.7494 - val_loss: 2.3096 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.4947 - accuracy: 0.7531 - val_loss: 2.4728 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 26s 7s/step - loss: 0.4908 - accuracy: 0.7525 - val_loss: 1.6559 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 29s 7s/step - loss: 0.4920 - accuracy: 0.7502 - val_loss: 2.4997 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.4862 - accuracy: 0.7540 - val_loss: 1.8537 - val_accuracy: 0.5100 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 03:55:24.955719: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.88      0.65       200\n",
      "         1.0       0.62      0.20      0.30       200\n",
      "\n",
      "    accuracy                           0.54       400\n",
      "   macro avg       0.57      0.54      0.48       400\n",
      "weighted avg       0.57      0.54      0.48       400\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 13, 496, 25)       150       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 496, 25)        8150      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 496, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1, 496, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 248, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1, 248, 25)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1, 244, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 244, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1, 244, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 122, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1, 122, 50)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, 118, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 118, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 1, 118, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 59, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 59, 100)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 1, 55, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 55, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1, 55, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 27, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1, 27, 200)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 10802     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,718\n",
      "Trainable params: 150,710\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.4040 - accuracy: 0.5163INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6.4040 - accuracy: 0.5163 - val_loss: 37.8722 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.0446 - accuracy: 0.4938INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10.0446 - accuracy: 0.4938 - val_loss: 12.9184 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.3061 - accuracy: 0.4942INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4.3061 - accuracy: 0.4942 - val_loss: 2.0271 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5682 - accuracy: 0.4913INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 2.5682 - accuracy: 0.4913 - val_loss: 0.9033 - val_accuracy: 0.5350 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.3766 - accuracy: 0.5031 - val_loss: 1.5825 - val_accuracy: 0.4925 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.1719 - accuracy: 0.5104 - val_loss: 1.1149 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.0464 - accuracy: 0.5013 - val_loss: 0.9338 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8546 - accuracy: 0.5098INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.8546 - accuracy: 0.5098 - val_loss: 0.7098 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.8093 - accuracy: 0.5102 - val_loss: 0.7549 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.7921 - accuracy: 0.5104 - val_loss: 0.7376 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7651 - accuracy: 0.5098 - val_loss: 0.7377 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7308 - accuracy: 0.5315 - val_loss: 0.7170 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7401 - accuracy: 0.5165 - val_loss: 0.7203 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.5281INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.7233 - accuracy: 0.5281 - val_loss: 0.6901 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7060 - accuracy: 0.5348 - val_loss: 0.6958 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.7066 - accuracy: 0.5256 - val_loss: 0.6907 - val_accuracy: 0.5550 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7063 - accuracy: 0.5448INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7063 - accuracy: 0.5448 - val_loss: 0.6867 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.7015 - accuracy: 0.5354 - val_loss: 0.6877 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5415INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6947 - accuracy: 0.5415 - val_loss: 0.6854 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6943 - accuracy: 0.5475 - val_loss: 0.6942 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6966 - accuracy: 0.5394 - val_loss: 0.6916 - val_accuracy: 0.5450 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5415INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6962 - accuracy: 0.5415 - val_loss: 0.6812 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6967 - accuracy: 0.5408 - val_loss: 0.7145 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6959 - accuracy: 0.5535 - val_loss: 0.6842 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.5506INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.6945 - accuracy: 0.5506 - val_loss: 0.6753 - val_accuracy: 0.5675 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6910 - accuracy: 0.5542 - val_loss: 0.7166 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6954 - accuracy: 0.5523 - val_loss: 0.6840 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6942 - accuracy: 0.5506 - val_loss: 0.6933 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6922 - accuracy: 0.5577 - val_loss: 0.6915 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7008 - accuracy: 0.5371 - val_loss: 0.6901 - val_accuracy: 0.5450 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6941 - accuracy: 0.5537 - val_loss: 0.6858 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.5527INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.6909 - accuracy: 0.5527 - val_loss: 0.6728 - val_accuracy: 0.5900 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6907 - accuracy: 0.5577 - val_loss: 0.7154 - val_accuracy: 0.4925 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7033 - accuracy: 0.5369 - val_loss: 0.6955 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6970 - accuracy: 0.5571 - val_loss: 0.6776 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7034 - accuracy: 0.5427 - val_loss: 0.7068 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6942 - accuracy: 0.5554 - val_loss: 0.6919 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6922 - accuracy: 0.5600 - val_loss: 0.7023 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6890 - accuracy: 0.5656 - val_loss: 0.6953 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6951 - accuracy: 0.5554 - val_loss: 0.6997 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6972 - accuracy: 0.5508 - val_loss: 0.6811 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6895 - accuracy: 0.5631 - val_loss: 0.6798 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6844 - accuracy: 0.5590 - val_loss: 0.7068 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6857 - accuracy: 0.5692 - val_loss: 0.7011 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6803 - accuracy: 0.5763 - val_loss: 0.6818 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6833 - accuracy: 0.5698 - val_loss: 0.6804 - val_accuracy: 0.5400 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6813 - accuracy: 0.5738 - val_loss: 0.6870 - val_accuracy: 0.5450 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6855 - accuracy: 0.5683 - val_loss: 0.6906 - val_accuracy: 0.5675 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6787 - accuracy: 0.5754 - val_loss: 0.6924 - val_accuracy: 0.5650 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6849 - accuracy: 0.5654 - val_loss: 0.6743 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6760 - accuracy: 0.5854 - val_loss: 0.6785 - val_accuracy: 0.5775 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6809 - accuracy: 0.5863 - val_loss: 0.6806 - val_accuracy: 0.5625 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:08:54.239285: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.55      0.53       200\n",
      "         1.0       0.51      0.47      0.49       200\n",
      "\n",
      "    accuracy                           0.51       400\n",
      "   macro avg       0.51      0.51      0.51       400\n",
      "weighted avg       0.51      0.51      0.51       400\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  1\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "12            EEGene     76.62   1.38     71.56  0.77\n",
      "0         covariance     75.25   3.75     70.05  4.80\n",
      "4    cross_correlate     72.12   4.38     65.22 10.17\n",
      "9                all     70.25   5.25     60.71 12.95\n",
      "7           variance     69.75   0.25     62.44  2.05\n",
      "6            meanstd     68.00   0.50     59.71  5.48\n",
      "10            EEGNet     65.00  11.25     49.52 19.33\n",
      "3                fft     61.00   3.25     53.86  3.71\n",
      "8   spectral_entropy     59.50   0.50     56.88  4.28\n",
      "5             maxmin     57.75   1.75     50.35  1.30\n",
      "2               fft2     57.38   1.12     53.14  2.71\n",
      "1                raw     57.12   1.12     50.90  3.60\n",
      "11       DeepConvNet     53.12   2.38     47.28  1.55\n",
      "subject :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 13, 500, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 13, 500, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 1, 500, 16)       208       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 500, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_8 (Averag  (None, 1, 125, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 1, 125, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 125, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_9 (Averag  (None, 1, 15, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7309 - accuracy: 0.5077INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.7309 - accuracy: 0.5077 - val_loss: 0.6854 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5504INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.6926 - accuracy: 0.5504 - val_loss: 0.6745 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6734 - accuracy: 0.5821 - val_loss: 0.7196 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6605 - accuracy: 0.6127 - val_loss: 0.8176 - val_accuracy: 0.5825 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6511 - accuracy: 0.6231 - val_loss: 0.8005 - val_accuracy: 0.5825 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6455 - accuracy: 0.6277 - val_loss: 0.8212 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6404 - accuracy: 0.6344 - val_loss: 0.8424 - val_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6330 - accuracy: 0.6402 - val_loss: 0.8333 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6302 - accuracy: 0.6450 - val_loss: 0.8905 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6255 - accuracy: 0.6500 - val_loss: 0.8454 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6226 - accuracy: 0.6488 - val_loss: 0.7953 - val_accuracy: 0.5825 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6210 - accuracy: 0.6504 - val_loss: 0.7241 - val_accuracy: 0.6275 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.6602INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.6187 - accuracy: 0.6602 - val_loss: 0.6705 - val_accuracy: 0.6300 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6656INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.6136 - accuracy: 0.6656 - val_loss: 0.6461 - val_accuracy: 0.6550 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6698INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.6073 - accuracy: 0.6698 - val_loss: 0.6140 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6673INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.6093 - accuracy: 0.6673 - val_loss: 0.5752 - val_accuracy: 0.6925 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.6796INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.6043 - accuracy: 0.6796 - val_loss: 0.5703 - val_accuracy: 0.7150 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.6783INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.6010 - accuracy: 0.6783 - val_loss: 0.5523 - val_accuracy: 0.7175 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.6785INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5980 - accuracy: 0.6785 - val_loss: 0.5078 - val_accuracy: 0.7275 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.6865INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.5937 - accuracy: 0.6865 - val_loss: 0.4770 - val_accuracy: 0.7725 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.7002INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5793 - accuracy: 0.7002 - val_loss: 0.4720 - val_accuracy: 0.7650 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7198INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5658 - accuracy: 0.7198 - val_loss: 0.4151 - val_accuracy: 0.7850 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.7208INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5567 - accuracy: 0.7208 - val_loss: 0.3991 - val_accuracy: 0.7650 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5480 - accuracy: 0.7231 - val_loss: 0.4175 - val_accuracy: 0.7550 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5357 - accuracy: 0.7340 - val_loss: 0.5123 - val_accuracy: 0.7125 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5327 - accuracy: 0.7329 - val_loss: 0.4570 - val_accuracy: 0.7275 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5237 - accuracy: 0.7371 - val_loss: 0.4862 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5219 - accuracy: 0.7394 - val_loss: 0.4885 - val_accuracy: 0.7150 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.5139 - accuracy: 0.7483 - val_loss: 0.4906 - val_accuracy: 0.7075 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.5096 - accuracy: 0.7481 - val_loss: 0.5186 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.4992 - accuracy: 0.7583 - val_loss: 0.5921 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4996 - accuracy: 0.7548 - val_loss: 0.5864 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4991 - accuracy: 0.7579 - val_loss: 0.6614 - val_accuracy: 0.6400 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4920 - accuracy: 0.7573 - val_loss: 0.7940 - val_accuracy: 0.6050 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4923 - accuracy: 0.7583 - val_loss: 0.6493 - val_accuracy: 0.6500 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.4837 - accuracy: 0.7615 - val_loss: 0.6302 - val_accuracy: 0.6500 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.4857 - accuracy: 0.7673 - val_loss: 0.5541 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4884 - accuracy: 0.7544 - val_loss: 0.5163 - val_accuracy: 0.7175 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4773 - accuracy: 0.7702 - val_loss: 0.6052 - val_accuracy: 0.6900 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4761 - accuracy: 0.7677 - val_loss: 0.5058 - val_accuracy: 0.7200 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4701 - accuracy: 0.7706 - val_loss: 0.5616 - val_accuracy: 0.6975 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4705 - accuracy: 0.7683 - val_loss: 0.5392 - val_accuracy: 0.7175 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4615 - accuracy: 0.7748 - val_loss: 0.5200 - val_accuracy: 0.7300 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:22:15.997096: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.99      0.71       200\n",
      "         1.0       0.97      0.20      0.33       200\n",
      "\n",
      "    accuracy                           0.59       400\n",
      "   macro avg       0.76      0.59      0.52       400\n",
      "weighted avg       0.76      0.59      0.52       400\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 13, 496, 25)       150       \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 496, 25)        8150      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 496, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 1, 496, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 248, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 1, 248, 25)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 244, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 244, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 1, 244, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 122, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 1, 122, 50)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 118, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 118, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 1, 118, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 59, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1, 59, 100)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 55, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 55, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 1, 55, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 27, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 1, 27, 200)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 5400)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 10802     \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,718\n",
      "Trainable params: 150,710\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.7257 - accuracy: 0.5129INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.7257 - accuracy: 0.5129 - val_loss: 19.5340 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.4402 - accuracy: 0.4996INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.4402 - accuracy: 0.4996 - val_loss: 2.3337 - val_accuracy: 0.4950 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.6665 - accuracy: 0.4975INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 3.6665 - accuracy: 0.4975 - val_loss: 1.8324 - val_accuracy: 0.4775 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7445 - accuracy: 0.5102INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7445 - accuracy: 0.5102 - val_loss: 1.2614 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2652 - accuracy: 0.4992INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.2652 - accuracy: 0.4992 - val_loss: 0.8432 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.9079 - accuracy: 0.5325 - val_loss: 0.8539 - val_accuracy: 0.4975 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.5119INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.8471 - accuracy: 0.5119 - val_loss: 0.7599 - val_accuracy: 0.5225 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.5233INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7678 - accuracy: 0.5233 - val_loss: 0.7464 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7430 - accuracy: 0.5275INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7430 - accuracy: 0.5275 - val_loss: 0.7106 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.7368 - accuracy: 0.5260 - val_loss: 0.7345 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7233 - accuracy: 0.5435 - val_loss: 0.7414 - val_accuracy: 0.5050 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.5592INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6990 - accuracy: 0.5592 - val_loss: 0.6797 - val_accuracy: 0.5775 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7007 - accuracy: 0.5527 - val_loss: 0.6997 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6939 - accuracy: 0.5531 - val_loss: 0.6817 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5531INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6935 - accuracy: 0.5531 - val_loss: 0.6767 - val_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6842 - accuracy: 0.5656 - val_loss: 0.6979 - val_accuracy: 0.5350 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5692INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6794 - accuracy: 0.5692 - val_loss: 0.6708 - val_accuracy: 0.6075 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6784 - accuracy: 0.5700 - val_loss: 0.6790 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6752 - accuracy: 0.5923 - val_loss: 0.6731 - val_accuracy: 0.5900 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6826 - accuracy: 0.5648 - val_loss: 0.6782 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.5835INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6754 - accuracy: 0.5835 - val_loss: 0.6655 - val_accuracy: 0.6325 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6779 - accuracy: 0.5821 - val_loss: 0.6868 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6753 - accuracy: 0.5808 - val_loss: 0.6693 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.5833INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6685 - accuracy: 0.5833 - val_loss: 0.6571 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6677 - accuracy: 0.5892 - val_loss: 0.6792 - val_accuracy: 0.5650 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.5819INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6713 - accuracy: 0.5819 - val_loss: 0.6520 - val_accuracy: 0.6375 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6692 - accuracy: 0.5888 - val_loss: 0.6727 - val_accuracy: 0.5800 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6667 - accuracy: 0.5996 - val_loss: 0.6555 - val_accuracy: 0.6300 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.5956INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6705 - accuracy: 0.5956 - val_loss: 0.6511 - val_accuracy: 0.6500 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.5971INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6651 - accuracy: 0.5971 - val_loss: 0.6481 - val_accuracy: 0.6550 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6603 - accuracy: 0.5962 - val_loss: 0.6539 - val_accuracy: 0.6400 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6600 - accuracy: 0.6090 - val_loss: 0.6487 - val_accuracy: 0.6225 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6649 - accuracy: 0.6050 - val_loss: 0.6529 - val_accuracy: 0.6075 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.5925INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6637 - accuracy: 0.5925 - val_loss: 0.6458 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.5990INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6624 - accuracy: 0.5990 - val_loss: 0.6404 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6665 - accuracy: 0.5985 - val_loss: 0.6532 - val_accuracy: 0.6175 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.6127INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6604 - accuracy: 0.6127 - val_loss: 0.6358 - val_accuracy: 0.6450 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.5975INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6741 - accuracy: 0.5975 - val_loss: 0.6342 - val_accuracy: 0.6575 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6694 - accuracy: 0.6012 - val_loss: 0.6456 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.6140INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6603 - accuracy: 0.6140 - val_loss: 0.6337 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.6073INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6596 - accuracy: 0.6073 - val_loss: 0.6264 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.6017INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6609 - accuracy: 0.6017 - val_loss: 0.6223 - val_accuracy: 0.6450 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.6242INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6537 - accuracy: 0.6242 - val_loss: 0.6207 - val_accuracy: 0.6400 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.6219INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6456 - accuracy: 0.6219 - val_loss: 0.6146 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6485 - accuracy: 0.6229 - val_loss: 0.6166 - val_accuracy: 0.6450 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6225INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 5s/step - loss: 0.6475 - accuracy: 0.6225 - val_loss: 0.6133 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6427 - accuracy: 0.6306 - val_loss: 0.6183 - val_accuracy: 0.6425 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.6267INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6471 - accuracy: 0.6267 - val_loss: 0.6116 - val_accuracy: 0.6475 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6420 - accuracy: 0.6275 - val_loss: 0.6123 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.6204INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6471 - accuracy: 0.6204 - val_loss: 0.6074 - val_accuracy: 0.6650 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6467 - accuracy: 0.6233 - val_loss: 0.6104 - val_accuracy: 0.6650 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.6196INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6464 - accuracy: 0.6196 - val_loss: 0.6071 - val_accuracy: 0.6550 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6431 - accuracy: 0.6350 - val_loss: 0.6097 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.6227INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6453 - accuracy: 0.6227 - val_loss: 0.6070 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6433 - accuracy: 0.6313 - val_loss: 0.6098 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6464 - accuracy: 0.6215 - val_loss: 0.6115 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.6246INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6460 - accuracy: 0.6246 - val_loss: 0.6034 - val_accuracy: 0.6850 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6489 - accuracy: 0.6242 - val_loss: 0.6070 - val_accuracy: 0.6850 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6493 - accuracy: 0.6252INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6493 - accuracy: 0.6252 - val_loss: 0.6003 - val_accuracy: 0.6650 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6440 - accuracy: 0.6354 - val_loss: 0.6234 - val_accuracy: 0.6525 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6444 - accuracy: 0.6267 - val_loss: 0.6020 - val_accuracy: 0.6950 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6429 - accuracy: 0.6335 - val_loss: 0.6027 - val_accuracy: 0.6675 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6497 - accuracy: 0.6179 - val_loss: 0.6048 - val_accuracy: 0.6750 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.6373INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6401 - accuracy: 0.6373 - val_loss: 0.5961 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6460 - accuracy: 0.6306 - val_loss: 0.6035 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.6271INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.6445 - accuracy: 0.6271 - val_loss: 0.5957 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6417 - accuracy: 0.6356 - val_loss: 0.6157 - val_accuracy: 0.6425 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6464 - accuracy: 0.6237 - val_loss: 0.5973 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6413 - accuracy: 0.6338 - val_loss: 0.6066 - val_accuracy: 0.6525 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6406 - accuracy: 0.6325 - val_loss: 0.6067 - val_accuracy: 0.6650 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.6260INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6392 - accuracy: 0.6260 - val_loss: 0.5927 - val_accuracy: 0.7050 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6459 - accuracy: 0.6360 - val_loss: 0.5980 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6419 - accuracy: 0.6250 - val_loss: 0.6055 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.6436 - accuracy: 0.6306 - val_loss: 0.5976 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6391 - accuracy: 0.6333 - val_loss: 0.6069 - val_accuracy: 0.6575 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.6304INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.6373 - accuracy: 0.6304 - val_loss: 0.5893 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6420 - accuracy: 0.6390 - val_loss: 0.6001 - val_accuracy: 0.6775 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6360 - accuracy: 0.6406 - val_loss: 0.5969 - val_accuracy: 0.6750 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.6285INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.6413 - accuracy: 0.6285 - val_loss: 0.5891 - val_accuracy: 0.6900 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6357 - accuracy: 0.6388 - val_loss: 0.6024 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6323 - accuracy: 0.6417 - val_loss: 0.5930 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6374 - accuracy: 0.6373 - val_loss: 0.5920 - val_accuracy: 0.6575 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6388 - accuracy: 0.6310 - val_loss: 0.6022 - val_accuracy: 0.6450 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.6377INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6381 - accuracy: 0.6377 - val_loss: 0.5848 - val_accuracy: 0.7025 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6349 - accuracy: 0.6369 - val_loss: 0.5957 - val_accuracy: 0.6750 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6299 - accuracy: 0.6429 - val_loss: 0.5967 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6307 - accuracy: 0.6390 - val_loss: 0.5903 - val_accuracy: 0.6925 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6335 - accuracy: 0.6463 - val_loss: 0.6145 - val_accuracy: 0.6600 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6510 - accuracy: 0.6260 - val_loss: 0.5910 - val_accuracy: 0.6950 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6390 - accuracy: 0.6331 - val_loss: 0.5899 - val_accuracy: 0.6825 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6309 - accuracy: 0.6473 - val_loss: 0.5970 - val_accuracy: 0.6900 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.6425INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6311 - accuracy: 0.6425 - val_loss: 0.5717 - val_accuracy: 0.7200 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6330 - accuracy: 0.6454 - val_loss: 0.5927 - val_accuracy: 0.6800 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6361 - accuracy: 0.6419 - val_loss: 0.5879 - val_accuracy: 0.6975 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6268 - accuracy: 0.6573 - val_loss: 0.5811 - val_accuracy: 0.6975 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6257 - accuracy: 0.6513 - val_loss: 0.5819 - val_accuracy: 0.7025 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6544INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6205 - accuracy: 0.6544 - val_loss: 0.5555 - val_accuracy: 0.7275 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6209 - accuracy: 0.6583 - val_loss: 0.5756 - val_accuracy: 0.7025 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6186 - accuracy: 0.6554 - val_loss: 0.5564 - val_accuracy: 0.7125 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.6621INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6124 - accuracy: 0.6621 - val_loss: 0.5513 - val_accuracy: 0.7200 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6090 - accuracy: 0.6767 - val_loss: 0.5721 - val_accuracy: 0.6950 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.6756INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.6030 - accuracy: 0.6756 - val_loss: 0.5408 - val_accuracy: 0.7375 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.6710INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 5s/step - loss: 0.6085 - accuracy: 0.6710 - val_loss: 0.5342 - val_accuracy: 0.7400 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6058 - accuracy: 0.6673 - val_loss: 0.5878 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6082 - accuracy: 0.6760 - val_loss: 0.6324 - val_accuracy: 0.6350 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6078 - accuracy: 0.6750 - val_loss: 0.6055 - val_accuracy: 0.6350 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6025 - accuracy: 0.6767 - val_loss: 0.5719 - val_accuracy: 0.6725 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5945 - accuracy: 0.6837 - val_loss: 0.6459 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6052 - accuracy: 0.6740 - val_loss: 0.5434 - val_accuracy: 0.7025 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.6821INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5881 - accuracy: 0.6821 - val_loss: 0.5233 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5810 - accuracy: 0.6965 - val_loss: 0.5387 - val_accuracy: 0.6900 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5799 - accuracy: 0.6958 - val_loss: 0.5503 - val_accuracy: 0.6975 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.7017INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.5685 - accuracy: 0.7017 - val_loss: 0.4395 - val_accuracy: 0.8000 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5634 - accuracy: 0.7075 - val_loss: 0.4476 - val_accuracy: 0.7725 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5687 - accuracy: 0.7090 - val_loss: 0.4642 - val_accuracy: 0.7375 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7092INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5637 - accuracy: 0.7092 - val_loss: 0.3999 - val_accuracy: 0.8050 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5599 - accuracy: 0.7044 - val_loss: 0.4373 - val_accuracy: 0.7575 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5541 - accuracy: 0.7156 - val_loss: 0.5035 - val_accuracy: 0.7175 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5598 - accuracy: 0.7081 - val_loss: 0.6191 - val_accuracy: 0.6325 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5580 - accuracy: 0.7135 - val_loss: 0.6749 - val_accuracy: 0.6225 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5666 - accuracy: 0.7040 - val_loss: 0.7347 - val_accuracy: 0.6025 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5508 - accuracy: 0.7123 - val_loss: 0.4238 - val_accuracy: 0.7700 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.5385 - accuracy: 0.7298 - val_loss: 0.5107 - val_accuracy: 0.7250 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.7279INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.5370 - accuracy: 0.7279 - val_loss: 0.3913 - val_accuracy: 0.8150 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5359 - accuracy: 0.7258 - val_loss: 0.8096 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5147 - accuracy: 0.7481 - val_loss: 1.2508 - val_accuracy: 0.5325 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5217 - accuracy: 0.7387 - val_loss: 0.8554 - val_accuracy: 0.5600 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5087 - accuracy: 0.7444 - val_loss: 0.6016 - val_accuracy: 0.7000 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5004 - accuracy: 0.7567 - val_loss: 0.5366 - val_accuracy: 0.7225 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5009 - accuracy: 0.7498 - val_loss: 0.5797 - val_accuracy: 0.7025 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.4988 - accuracy: 0.7473 - val_loss: 0.5125 - val_accuracy: 0.7475 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4952 - accuracy: 0.7515 - val_loss: 0.9211 - val_accuracy: 0.5775 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4731 - accuracy: 0.7706 - val_loss: 0.9301 - val_accuracy: 0.6000 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.4803 - accuracy: 0.7640 - val_loss: 1.0893 - val_accuracy: 0.5575 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4842 - accuracy: 0.7606 - val_loss: 2.0551 - val_accuracy: 0.5150 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.4818 - accuracy: 0.7606 - val_loss: 1.2497 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4668 - accuracy: 0.7706 - val_loss: 0.7936 - val_accuracy: 0.6275 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.4582 - accuracy: 0.7758 - val_loss: 1.5771 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4648 - accuracy: 0.7771 - val_loss: 1.2229 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4465 - accuracy: 0.7860 - val_loss: 1.3932 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4531 - accuracy: 0.7796 - val_loss: 1.7039 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4548 - accuracy: 0.7756 - val_loss: 1.7493 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4614 - accuracy: 0.7798 - val_loss: 1.1672 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4490 - accuracy: 0.7827 - val_loss: 1.1385 - val_accuracy: 0.5675 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:55:16.343748: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.99      0.70       200\n",
      "         1.0       0.97      0.14      0.24       200\n",
      "\n",
      "    accuracy                           0.57       400\n",
      "   macro avg       0.75      0.57      0.47       400\n",
      "weighted avg       0.75      0.57      0.47       400\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  2\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "12            EEGene     71.33   7.57     60.99 14.96\n",
      "0         covariance     70.75   7.06     61.62 12.55\n",
      "7           variance     68.67   1.55     61.18  2.45\n",
      "4    cross_correlate     68.67   6.06     57.12 14.15\n",
      "9                all     67.17   6.11     54.40 13.83\n",
      "6            meanstd     66.50   2.16     58.66  4.72\n",
      "10            EEGNet     63.17   9.54     43.85 17.71\n",
      "3                fft     59.25   3.63     49.64  6.69\n",
      "8   spectral_entropy     59.17   0.62     54.28  5.07\n",
      "2               fft2     57.58   0.96     51.58  3.12\n",
      "1                raw     56.83   1.01     52.57  3.77\n",
      "5             maxmin     56.67   2.09     50.59  1.11\n",
      "11       DeepConvNet     54.33   2.58     39.67 10.84\n",
      "subject :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 13, 500, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 13, 500, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 1, 500, 16)       208       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 1, 500, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 1, 125, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 1, 125, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 1, 125, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_13 (Avera  (None, 1, 15, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.5121INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.7218 - accuracy: 0.5121 - val_loss: 0.6882 - val_accuracy: 0.5725 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6795 - accuracy: 0.5727 - val_loss: 0.6965 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6306 - accuracy: 0.6425 - val_loss: 0.8581 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5971 - accuracy: 0.6700 - val_loss: 1.5486 - val_accuracy: 0.5350 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5644 - accuracy: 0.6988 - val_loss: 2.8427 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5512 - accuracy: 0.7088 - val_loss: 4.7687 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5434 - accuracy: 0.7121 - val_loss: 5.6811 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5372 - accuracy: 0.7177 - val_loss: 5.9336 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5326 - accuracy: 0.7242 - val_loss: 4.9837 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5303 - accuracy: 0.7177 - val_loss: 5.3366 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5223 - accuracy: 0.7308 - val_loss: 4.1866 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5200 - accuracy: 0.7373 - val_loss: 3.9127 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5173 - accuracy: 0.7333 - val_loss: 3.2036 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5121 - accuracy: 0.7404 - val_loss: 3.0779 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5026 - accuracy: 0.7469 - val_loss: 2.8527 - val_accuracy: 0.5025 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5006 - accuracy: 0.7502 - val_loss: 2.3075 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4986 - accuracy: 0.7504 - val_loss: 2.2471 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4874 - accuracy: 0.7515 - val_loss: 2.3296 - val_accuracy: 0.5050 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4800 - accuracy: 0.7671 - val_loss: 2.2572 - val_accuracy: 0.5100 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4850 - accuracy: 0.7529 - val_loss: 2.1013 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.4693 - accuracy: 0.7642 - val_loss: 1.7926 - val_accuracy: 0.5300 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 12:36:44.155627: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.82      0.65       200\n",
      "         1.0       0.62      0.28      0.39       200\n",
      "\n",
      "    accuracy                           0.56       400\n",
      "   macro avg       0.58      0.55      0.52       400\n",
      "weighted avg       0.58      0.56      0.52       400\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 13, 496, 25)       150       \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 1, 496, 25)        8150      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 1, 496, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 1, 496, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 248, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1, 248, 25)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 1, 244, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 1, 244, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 1, 244, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 122, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 1, 122, 50)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 1, 118, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 1, 118, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 1, 118, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 59, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1, 59, 100)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 1, 55, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 1, 55, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 1, 55, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 27, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 1, 27, 200)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 5400)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 10802     \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,718\n",
      "Trainable params: 150,710\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.5909 - accuracy: 0.5133INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 8.5909 - accuracy: 0.5133 - val_loss: 17.4738 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.7184 - accuracy: 0.4923INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7184 - accuracy: 0.4923 - val_loss: 1.5108 - val_accuracy: 0.5675 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.0818 - accuracy: 0.5096 - val_loss: 1.8104 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3889 - accuracy: 0.5140INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.3889 - accuracy: 0.5140 - val_loss: 0.7866 - val_accuracy: 0.5425 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.5219INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.9088 - accuracy: 0.5219 - val_loss: 0.7772 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8198 - accuracy: 0.5113INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.8198 - accuracy: 0.5113 - val_loss: 0.7305 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.5379INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7320 - accuracy: 0.5379 - val_loss: 0.7186 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.7276 - accuracy: 0.5273 - val_loss: 0.7369 - val_accuracy: 0.5425 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.7129 - accuracy: 0.5319 - val_loss: 0.7896 - val_accuracy: 0.4750 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.7075 - accuracy: 0.5367 - val_loss: 0.7191 - val_accuracy: 0.5150 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5542INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.6905 - accuracy: 0.5542 - val_loss: 0.7058 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6923 - accuracy: 0.5519 - val_loss: 0.7316 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6870 - accuracy: 0.5638 - val_loss: 0.7304 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6833 - accuracy: 0.5638 - val_loss: 0.7462 - val_accuracy: 0.4950 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.5565INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6867 - accuracy: 0.5565 - val_loss: 0.6847 - val_accuracy: 0.5525 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6834 - accuracy: 0.5592 - val_loss: 0.7002 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.7128 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6749 - accuracy: 0.5831 - val_loss: 0.7200 - val_accuracy: 0.5175 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6755 - accuracy: 0.5775 - val_loss: 0.7199 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6746 - accuracy: 0.5708 - val_loss: 0.7305 - val_accuracy: 0.5200 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6730 - accuracy: 0.5829 - val_loss: 0.7041 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6748 - accuracy: 0.5860 - val_loss: 0.6977 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6733 - accuracy: 0.5817 - val_loss: 0.7064 - val_accuracy: 0.5275 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6709 - accuracy: 0.5875 - val_loss: 0.7623 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6730 - accuracy: 0.5858 - val_loss: 0.7052 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6683 - accuracy: 0.5829 - val_loss: 0.7263 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6661 - accuracy: 0.5917 - val_loss: 0.6992 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6694 - accuracy: 0.5892 - val_loss: 0.7135 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6676 - accuracy: 0.5896 - val_loss: 0.7174 - val_accuracy: 0.5075 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6685 - accuracy: 0.5871 - val_loss: 0.7108 - val_accuracy: 0.5150 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6633 - accuracy: 0.6029 - val_loss: 0.7038 - val_accuracy: 0.5375 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.6640 - accuracy: 0.5923 - val_loss: 0.7040 - val_accuracy: 0.5125 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6654 - accuracy: 0.5971 - val_loss: 0.6859 - val_accuracy: 0.5475 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6670 - accuracy: 0.5913 - val_loss: 0.6963 - val_accuracy: 0.5225 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6662 - accuracy: 0.5971 - val_loss: 0.7323 - val_accuracy: 0.5075 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 12:44:41.790713: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.86      0.66       200\n",
      "         1.0       0.63      0.24      0.35       200\n",
      "\n",
      "    accuracy                           0.55       400\n",
      "   macro avg       0.58      0.55      0.50       400\n",
      "weighted avg       0.58      0.55      0.50       400\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  3\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "12            EEGene     69.38   7.38     62.09 13.10\n",
      "0         covariance     68.62   7.14     62.37 10.94\n",
      "4    cross_correlate     68.31   5.28     59.99 13.22\n",
      "9                all     67.12   5.30     57.63 13.22\n",
      "7           variance     65.19   6.17     61.11  2.13\n",
      "6            meanstd     64.12   4.52     59.39  4.28\n",
      "10            EEGNet     61.25   8.91     42.65 15.47\n",
      "3                fft     59.25   3.14     50.06  5.84\n",
      "8   spectral_entropy     59.12   0.54     54.51  4.41\n",
      "2               fft2     56.50   2.05     50.66  3.14\n",
      "1                raw     56.44   1.11     51.68  3.61\n",
      "5             maxmin     55.44   2.80     51.03  1.23\n",
      "11       DeepConvNet     54.50   2.26     38.45  9.62\n",
      "subject :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 13, 500, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 13, 500, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthwi  (None, 1, 500, 16)       208       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 1, 500, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 1, 500, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_16 (Avera  (None, 1, 125, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 1, 125, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 1, 125, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 1, 125, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_17 (Avera  (None, 1, 15, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 1, 15, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 482       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.5052INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.7241 - accuracy: 0.5052 - val_loss: 0.6850 - val_accuracy: 0.5533 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.6704 - accuracy: 0.5863 - val_loss: 0.7205 - val_accuracy: 0.5817 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.6404 - accuracy: 0.6376 - val_loss: 0.9458 - val_accuracy: 0.5450 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5981 - accuracy: 0.6726 - val_loss: 1.7067 - val_accuracy: 0.5217 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5619 - accuracy: 0.7052 - val_loss: 2.4507 - val_accuracy: 0.5117 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5343 - accuracy: 0.7202 - val_loss: 2.8149 - val_accuracy: 0.5067 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5177 - accuracy: 0.7415 - val_loss: 2.0130 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5071 - accuracy: 0.7498 - val_loss: 1.5414 - val_accuracy: 0.5767 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5033 - accuracy: 0.7422 - val_loss: 1.5197 - val_accuracy: 0.5617 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4894 - accuracy: 0.7515 - val_loss: 1.4921 - val_accuracy: 0.5733 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4871 - accuracy: 0.7570 - val_loss: 1.3939 - val_accuracy: 0.5850 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4786 - accuracy: 0.7607 - val_loss: 1.6386 - val_accuracy: 0.5933 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4714 - accuracy: 0.7667 - val_loss: 1.3864 - val_accuracy: 0.5883 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 1.3701 - val_accuracy: 0.6033 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4563 - accuracy: 0.7824 - val_loss: 1.2722 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4489 - accuracy: 0.7820 - val_loss: 1.2833 - val_accuracy: 0.6150 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4477 - accuracy: 0.7802 - val_loss: 1.3146 - val_accuracy: 0.6033 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4416 - accuracy: 0.7867 - val_loss: 1.1102 - val_accuracy: 0.6183 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4395 - accuracy: 0.7913 - val_loss: 1.3063 - val_accuracy: 0.5917 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4305 - accuracy: 0.7935 - val_loss: 1.1735 - val_accuracy: 0.6050 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4293 - accuracy: 0.7980 - val_loss: 1.2847 - val_accuracy: 0.6017 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 17:05:34.713209: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/faller_indep_1_out_weights.tf: FAILED_PRECONDITION: log/faller_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.53      0.54       200\n",
      "         1.0       0.54      0.55      0.54       200\n",
      "\n",
      "    accuracy                           0.54       400\n",
      "   macro avg       0.54      0.54      0.54       400\n",
      "weighted avg       0.54      0.54      0.54       400\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 13, 500, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 13, 496, 25)       150       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 1, 496, 25)        8150      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 1, 496, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 1, 496, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 248, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 1, 248, 25)        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 1, 244, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 1, 244, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 1, 244, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 122, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 1, 122, 50)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 1, 118, 100)       25100     \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 1, 118, 100)      4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 1, 118, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 1, 59, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 1, 59, 100)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 1, 55, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 1, 55, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 1, 55, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 1, 27, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 1, 27, 200)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 5400)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 10802     \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 150,718\n",
      "Trainable params: 150,710\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.5097 - accuracy: 0.4967INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.5097 - accuracy: 0.4967 - val_loss: 14.0665 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.4557 - accuracy: 0.5007INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4557 - accuracy: 0.5007 - val_loss: 5.4166 - val_accuracy: 0.4983 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2781 - accuracy: 0.5163INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2781 - accuracy: 0.5163 - val_loss: 1.2484 - val_accuracy: 0.5083 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4260 - accuracy: 0.5170INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.4260 - accuracy: 0.5170 - val_loss: 0.7987 - val_accuracy: 0.5150 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.9474 - accuracy: 0.5209 - val_loss: 1.0836 - val_accuracy: 0.4983 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.9410 - accuracy: 0.5254 - val_loss: 0.9653 - val_accuracy: 0.4917 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.5135INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.9226 - accuracy: 0.5135 - val_loss: 0.7606 - val_accuracy: 0.5250 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7946 - accuracy: 0.5200INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.7946 - accuracy: 0.5200 - val_loss: 0.6994 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.7228 - accuracy: 0.5409 - val_loss: 0.7109 - val_accuracy: 0.5583 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5700INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6955 - accuracy: 0.5700 - val_loss: 0.6828 - val_accuracy: 0.5783 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.5774INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6823 - accuracy: 0.5774 - val_loss: 0.6694 - val_accuracy: 0.5917 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6826 - accuracy: 0.5713 - val_loss: 0.6784 - val_accuracy: 0.5717 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6800 - accuracy: 0.5759 - val_loss: 0.6936 - val_accuracy: 0.5617 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6773 - accuracy: 0.5826 - val_loss: 0.6756 - val_accuracy: 0.5683 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6787 - accuracy: 0.5883 - val_loss: 0.6760 - val_accuracy: 0.5767 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6761 - accuracy: 0.5820 - val_loss: 0.6895 - val_accuracy: 0.5650 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6701 - accuracy: 0.5859 - val_loss: 0.6720 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6660 - accuracy: 0.5924 - val_loss: 0.6836 - val_accuracy: 0.5483 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6675 - accuracy: 0.5915 - val_loss: 0.6744 - val_accuracy: 0.5667 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6645 - accuracy: 0.5993 - val_loss: 0.6794 - val_accuracy: 0.5683 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6652 - accuracy: 0.5976 - val_loss: 0.6744 - val_accuracy: 0.5683 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6637 - accuracy: 0.6041 - val_loss: 0.6706 - val_accuracy: 0.6067 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6680 - accuracy: 0.5998 - val_loss: 0.6956 - val_accuracy: 0.5600 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.6017INFO:tensorflow:Assets written to: log/faller_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6638 - accuracy: 0.6017 - val_loss: 0.6646 - val_accuracy: 0.5967 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6617 - accuracy: 0.6009 - val_loss: 0.6689 - val_accuracy: 0.5683 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6614 - accuracy: 0.6015 - val_loss: 0.6802 - val_accuracy: 0.5750 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6571 - accuracy: 0.6124 - val_loss: 0.6689 - val_accuracy: 0.5967 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6571 - accuracy: 0.6143 - val_loss: 0.6865 - val_accuracy: 0.5700 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6531 - accuracy: 0.6115 - val_loss: 0.6739 - val_accuracy: 0.5950 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6520 - accuracy: 0.6130 - val_loss: 0.7000 - val_accuracy: 0.5583 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6509 - accuracy: 0.6209 - val_loss: 0.6731 - val_accuracy: 0.5967 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6497 - accuracy: 0.6246 - val_loss: 0.7083 - val_accuracy: 0.5500 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.6519 - accuracy: 0.6196 - val_loss: 0.6971 - val_accuracy: 0.5883 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6494 - accuracy: 0.6228 - val_loss: 0.7022 - val_accuracy: 0.5567 - lr: 0.0100\n",
      "Epoch 35/200\n"
     ]
    }
   ],
   "source": [
    "faller_indep = Experiment.subject_independent_cv(X_faller,y_faller,\n",
    "                                                 seed=0,verbose=1,\n",
    "                                                 model_name='faller_indep_1',\n",
    "                                                 benchmarks=['EEGNet','DeepConvNet','EEGene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0cfd68c-c8e3-449d-8b9c-26ea6e3fa14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>+-acc</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>+-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>60.16</td>\n",
       "      <td>6.92</td>\n",
       "      <td>58.56</td>\n",
       "      <td>10.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EEGene</td>\n",
       "      <td>59.60</td>\n",
       "      <td>8.48</td>\n",
       "      <td>61.63</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cross_correlate</td>\n",
       "      <td>59.37</td>\n",
       "      <td>7.33</td>\n",
       "      <td>58.19</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covariance</td>\n",
       "      <td>59.05</td>\n",
       "      <td>8.19</td>\n",
       "      <td>60.62</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>58.01</td>\n",
       "      <td>7.30</td>\n",
       "      <td>44.90</td>\n",
       "      <td>16.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>variance</td>\n",
       "      <td>57.86</td>\n",
       "      <td>7.07</td>\n",
       "      <td>59.20</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meanstd</td>\n",
       "      <td>57.60</td>\n",
       "      <td>5.92</td>\n",
       "      <td>59.09</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>56.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>54.39</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeepConvNet</td>\n",
       "      <td>55.72</td>\n",
       "      <td>3.11</td>\n",
       "      <td>51.44</td>\n",
       "      <td>11.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fft</td>\n",
       "      <td>55.26</td>\n",
       "      <td>3.74</td>\n",
       "      <td>52.45</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fft2</td>\n",
       "      <td>54.10</td>\n",
       "      <td>2.47</td>\n",
       "      <td>51.53</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>53.13</td>\n",
       "      <td>4.37</td>\n",
       "      <td>52.89</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>maxmin</td>\n",
       "      <td>52.53</td>\n",
       "      <td>2.93</td>\n",
       "      <td>51.96</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method  accuracy  +-acc  f1-score  +-f1\n",
       "9                all     60.16   6.92     58.56 10.09\n",
       "12            EEGene     59.60   8.48     61.63  9.18\n",
       "4    cross_correlate     59.37   7.33     58.19  9.88\n",
       "0         covariance     59.05   8.19     60.62  7.62\n",
       "10            EEGNet     58.01   7.30     44.90 16.23\n",
       "7           variance     57.86   7.07     59.20  5.09\n",
       "6            meanstd     57.60   5.92     59.09  3.88\n",
       "1                raw     56.75   1.95     54.39  3.51\n",
       "11       DeepConvNet     55.72   3.11     51.44 11.79\n",
       "3                fft     55.26   3.74     52.45  5.34\n",
       "2               fft2     54.10   2.47     51.53  4.11\n",
       "8   spectral_entropy     53.13   4.37     52.89  4.00\n",
       "5             maxmin     52.53   2.93     51.96  4.47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment.make_df(faller_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f08f69-1c4c-4e03-a1a9-274eb7b911f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f96604-ae87-4c6f-9cb4-74e9a3385091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

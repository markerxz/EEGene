{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75316ef5-b08d-481b-a70c-b80d3564d8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:07:29.445583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-05 22:07:29.445669: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import EEGene\n",
    "import misc\n",
    "import Benchmarks\n",
    "from EEGene import EEGene,Processing\n",
    "from misc import Experiment,Data_Loader,Baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa9a758-b302-425e-aeba-fbaa3dcaa0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DL = Data_Loader()\n",
    "X_bcic,y_bcic = DL.load_bcic(sub=-1,fmin=0.5,fmax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ef3b3-9d30-40e0-8377-16857c657184",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 22, 400, 8)       32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 1, 400, 16)       352       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 400, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 100, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1, 100, 16)       1056      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 100, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 12, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:16:02.895407: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-12-05 22:16:02.895462: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: bob\n",
      "2022-12-05 22:16:02.895482: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: bob\n",
      "2022-12-05 22:16:02.895657: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.108.3\n",
      "2022-12-05 22:16:02.895688: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.85.2\n",
      "2022-12-05 22:16:02.895696: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 510.85.2 does not match DSO version 510.108.3 -- cannot find working devices in this configuration\n",
      "2022-12-05 22:16:02.896123: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.5218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:16:18.913674: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.7175 - accuracy: 0.5218 - val_loss: 0.6813 - val_accuracy: 0.6528 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.6587INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6305 - accuracy: 0.6587 - val_loss: 0.6578 - val_accuracy: 0.7326 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7034INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5802 - accuracy: 0.7034 - val_loss: 0.6124 - val_accuracy: 0.7326 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7247INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5481 - accuracy: 0.7247 - val_loss: 0.5484 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5200 - accuracy: 0.7421INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.5200 - accuracy: 0.7421 - val_loss: 0.5388 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.7500INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.5100 - accuracy: 0.7500 - val_loss: 0.5350 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4858 - accuracy: 0.7679 - val_loss: 0.5413 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.7907INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4615 - accuracy: 0.7907 - val_loss: 0.5102 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.4402 - accuracy: 0.7991 - val_loss: 0.5332 - val_accuracy: 0.7535 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4096 - accuracy: 0.8170 - val_loss: 0.5509 - val_accuracy: 0.6840 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.3825 - accuracy: 0.8467 - val_loss: 0.6019 - val_accuracy: 0.6458 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.3619 - accuracy: 0.8527 - val_loss: 0.5860 - val_accuracy: 0.6701 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.3590 - accuracy: 0.8457 - val_loss: 0.5833 - val_accuracy: 0.6840 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3389 - accuracy: 0.8695 - val_loss: 0.5573 - val_accuracy: 0.6806 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.3318 - accuracy: 0.8690 - val_loss: 0.6011 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.3274 - accuracy: 0.8547 - val_loss: 0.7030 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.3185 - accuracy: 0.8730 - val_loss: 0.6930 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.3118 - accuracy: 0.8695 - val_loss: 0.6128 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.3058 - accuracy: 0.8735 - val_loss: 0.6081 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.3059 - accuracy: 0.8805 - val_loss: 0.5805 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.8715INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 25s 7s/step - loss: 0.3005 - accuracy: 0.8715 - val_loss: 0.4944 - val_accuracy: 0.7535 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.2944 - accuracy: 0.8755 - val_loss: 0.5244 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.8844INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.2863 - accuracy: 0.8844 - val_loss: 0.4806 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2735 - accuracy: 0.8899 - val_loss: 0.5148 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.2771 - accuracy: 0.8904 - val_loss: 0.5344 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2607 - accuracy: 0.9003 - val_loss: 0.4917 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.2646 - accuracy: 0.8938 - val_loss: 0.4834 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9043INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.2423 - accuracy: 0.9043 - val_loss: 0.4651 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2491 - accuracy: 0.9038 - val_loss: 0.4761 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.2420 - accuracy: 0.9023 - val_loss: 0.4751 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9033INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 24s 7s/step - loss: 0.2453 - accuracy: 0.9033 - val_loss: 0.4262 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.2350 - accuracy: 0.9112 - val_loss: 0.4883 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2322 - accuracy: 0.9048 - val_loss: 0.4318 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9067INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.2319 - accuracy: 0.9067 - val_loss: 0.3928 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.2305 - accuracy: 0.9038 - val_loss: 0.4036 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.2175 - accuracy: 0.9196 - val_loss: 0.5092 - val_accuracy: 0.7535 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.2344 - accuracy: 0.8963 - val_loss: 0.4238 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.2146 - accuracy: 0.9152 - val_loss: 0.4196 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.2103 - accuracy: 0.9132 - val_loss: 0.5460 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.2104 - accuracy: 0.9137 - val_loss: 0.4089 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.2101 - accuracy: 0.9182 - val_loss: 0.4146 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.1959 - accuracy: 0.9296 - val_loss: 0.4088 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.1967 - accuracy: 0.9281 - val_loss: 0.4141 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9256INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.1953 - accuracy: 0.9256 - val_loss: 0.3759 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.1908 - accuracy: 0.9266 - val_loss: 0.3891 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1848 - accuracy: 0.9301 - val_loss: 0.4192 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 26s 7s/step - loss: 0.1849 - accuracy: 0.9311 - val_loss: 0.4045 - val_accuracy: 0.8299 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 25s 7s/step - loss: 0.1822 - accuracy: 0.9315 - val_loss: 0.4317 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.1829 - accuracy: 0.9335 - val_loss: 0.5018 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1841 - accuracy: 0.9241 - val_loss: 0.4131 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.1866 - accuracy: 0.9296 - val_loss: 0.3996 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.1820 - accuracy: 0.9246 - val_loss: 0.4060 - val_accuracy: 0.8229 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.1802 - accuracy: 0.9306 - val_loss: 0.4277 - val_accuracy: 0.8299 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9390INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.1711 - accuracy: 0.9390 - val_loss: 0.3731 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9370INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.1628 - accuracy: 0.9370 - val_loss: 0.3647 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.1561 - accuracy: 0.9444 - val_loss: 0.3756 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.1708 - accuracy: 0.9370 - val_loss: 0.4131 - val_accuracy: 0.8299 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.1663 - accuracy: 0.9370 - val_loss: 0.4031 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9435INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 24s 6s/step - loss: 0.1560 - accuracy: 0.9435 - val_loss: 0.3635 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1680 - accuracy: 0.9291 - val_loss: 0.3659 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 21s 5s/step - loss: 0.1547 - accuracy: 0.9425 - val_loss: 0.3746 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1550 - accuracy: 0.9390 - val_loss: 0.3938 - val_accuracy: 0.8611 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1473 - accuracy: 0.9449 - val_loss: 0.3699 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9444INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 21s 6s/step - loss: 0.1543 - accuracy: 0.9444 - val_loss: 0.3574 - val_accuracy: 0.8785 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1464 - accuracy: 0.9435 - val_loss: 0.3636 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1477 - accuracy: 0.9509 - val_loss: 0.3667 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1513 - accuracy: 0.9410 - val_loss: 0.3756 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1494 - accuracy: 0.9479 - val_loss: 0.3697 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1446 - accuracy: 0.9469 - val_loss: 0.3625 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1480 - accuracy: 0.9385 - val_loss: 0.3706 - val_accuracy: 0.8611 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1344 - accuracy: 0.9529 - val_loss: 0.3688 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1653 - accuracy: 0.9390 - val_loss: 0.3663 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1380 - accuracy: 0.9474 - val_loss: 0.3892 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1400 - accuracy: 0.9454 - val_loss: 0.3950 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1386 - accuracy: 0.9420 - val_loss: 0.3607 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1302 - accuracy: 0.9509 - val_loss: 0.3940 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9494INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1397 - accuracy: 0.9494 - val_loss: 0.3562 - val_accuracy: 0.8785 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9509INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 21s 6s/step - loss: 0.1303 - accuracy: 0.9509 - val_loss: 0.3458 - val_accuracy: 0.8785 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1273 - accuracy: 0.9499 - val_loss: 0.3840 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1363 - accuracy: 0.9459 - val_loss: 0.4008 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1331 - accuracy: 0.9524 - val_loss: 0.3753 - val_accuracy: 0.8715 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1245 - accuracy: 0.9549 - val_loss: 0.3815 - val_accuracy: 0.8889 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1286 - accuracy: 0.9559 - val_loss: 0.3622 - val_accuracy: 0.8819 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1361 - accuracy: 0.9459 - val_loss: 0.4016 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.1331 - accuracy: 0.9484 - val_loss: 0.3924 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 22s 5s/step - loss: 0.1232 - accuracy: 0.9554 - val_loss: 0.3680 - val_accuracy: 0.8785 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1323 - accuracy: 0.9494 - val_loss: 0.4029 - val_accuracy: 0.8611 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1293 - accuracy: 0.9544 - val_loss: 0.3813 - val_accuracy: 0.8854 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1241 - accuracy: 0.9568 - val_loss: 0.3785 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1252 - accuracy: 0.9539 - val_loss: 0.3551 - val_accuracy: 0.8993 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 23s 6s/step - loss: 0.1152 - accuracy: 0.9593 - val_loss: 0.3580 - val_accuracy: 0.8819 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1147 - accuracy: 0.9583 - val_loss: 0.4101 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1110 - accuracy: 0.9563 - val_loss: 0.3797 - val_accuracy: 0.8889 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1101 - accuracy: 0.9618 - val_loss: 0.3814 - val_accuracy: 0.8924 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1196 - accuracy: 0.9534 - val_loss: 0.3865 - val_accuracy: 0.8611 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 0.3632 - val_accuracy: 0.8785 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1217 - accuracy: 0.9539 - val_loss: 0.3654 - val_accuracy: 0.8715 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1262 - accuracy: 0.9479 - val_loss: 0.3894 - val_accuracy: 0.8750 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:48:55.016218: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.74      0.80       144\n",
      "         1.0       0.77      0.88      0.82       144\n",
      "\n",
      "    accuracy                           0.81       288\n",
      "   macro avg       0.82      0.81      0.81       288\n",
      "weighted avg       0.82      0.81      0.81       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 1, 396, 25)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 198, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1, 194, 50)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 97, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1, 93, 100)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 46, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 1, 42, 200)       4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 21, 200)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.8298 - accuracy: 0.5005INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 12s 3s/step - loss: 6.8298 - accuracy: 0.5005 - val_loss: 16.8842 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.9980 - accuracy: 0.5079INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 11s 3s/step - loss: 6.9980 - accuracy: 0.5079 - val_loss: 8.4130 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.2718 - accuracy: 0.5079INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 3s/step - loss: 3.2718 - accuracy: 0.5079 - val_loss: 4.8870 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0398 - accuracy: 0.5159INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2.0398 - accuracy: 0.5159 - val_loss: 3.0138 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6032 - accuracy: 0.5109INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6032 - accuracy: 0.5109 - val_loss: 2.1016 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2954 - accuracy: 0.5139INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.2954 - accuracy: 0.5139 - val_loss: 1.4827 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0198 - accuracy: 0.5293INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.0198 - accuracy: 0.5293 - val_loss: 1.2674 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.5084INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.9175 - accuracy: 0.5084 - val_loss: 0.7668 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8089 - accuracy: 0.5298INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 11s 3s/step - loss: 0.8089 - accuracy: 0.5298 - val_loss: 0.7205 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7646 - accuracy: 0.5124 - val_loss: 0.8916 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7710 - accuracy: 0.4955 - val_loss: 0.7710 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7413 - accuracy: 0.5263 - val_loss: 0.7370 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7212 - accuracy: 0.5139 - val_loss: 0.7571 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7114 - accuracy: 0.5387 - val_loss: 0.7364 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7130 - accuracy: 0.5213 - val_loss: 0.7371 - val_accuracy: 0.4826 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7000 - accuracy: 0.5382 - val_loss: 0.7262 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5660INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 3s/step - loss: 0.6907 - accuracy: 0.5660 - val_loss: 0.6975 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6975 - accuracy: 0.5352 - val_loss: 0.7175 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6891 - accuracy: 0.5565 - val_loss: 0.7434 - val_accuracy: 0.4757 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6985 - accuracy: 0.5273 - val_loss: 0.7199 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6938 - accuracy: 0.5441 - val_loss: 0.7462 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7166 - accuracy: 0.5312 - val_loss: 0.7497 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7078 - accuracy: 0.5317 - val_loss: 0.7464 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7030 - accuracy: 0.5441 - val_loss: 0.7194 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7031 - accuracy: 0.5407 - val_loss: 0.7111 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6927 - accuracy: 0.5650 - val_loss: 0.7249 - val_accuracy: 0.4653 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6904 - accuracy: 0.5595 - val_loss: 0.7235 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6942 - accuracy: 0.5402 - val_loss: 0.7382 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6922 - accuracy: 0.5615 - val_loss: 0.7050 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6858 - accuracy: 0.5551 - val_loss: 0.7187 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6881 - accuracy: 0.5605 - val_loss: 0.7148 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6828 - accuracy: 0.5590 - val_loss: 0.7167 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6994 - accuracy: 0.5407 - val_loss: 0.7360 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6818 - accuracy: 0.5625 - val_loss: 0.7430 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6821 - accuracy: 0.5774 - val_loss: 0.7196 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6884 - accuracy: 0.5635 - val_loss: 0.7114 - val_accuracy: 0.4757 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6791 - accuracy: 0.5868 - val_loss: 0.7418 - val_accuracy: 0.4444 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 22:53:37.947095: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.51      0.49       144\n",
      "         1.0       0.48      0.46      0.47       144\n",
      "\n",
      "    accuracy                           0.48       288\n",
      "   macro avg       0.48      0.48      0.48       288\n",
      "weighted avg       0.48      0.48      0.48       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  0\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     81.25   0.00     82.47  0.00\n",
      "9                all     69.79   0.00     70.10  0.00\n",
      "4    cross_correlate     67.01   0.00     70.03  0.00\n",
      "12            EEGene     67.01   0.00     69.65  0.00\n",
      "6            meanstd     62.15   0.00     61.75  0.00\n",
      "1                raw     62.15   0.00     60.93  0.00\n",
      "0         covariance     61.46   0.00     64.54  0.00\n",
      "7           variance     61.11   0.00     61.90  0.00\n",
      "8   spectral_entropy     56.25   0.00     58.28  0.00\n",
      "5             maxmin     55.90   0.00     59.42  0.00\n",
      "2               fft2     51.74   0.00     50.18  0.00\n",
      "3                fft     51.39   0.00     50.70  0.00\n",
      "11       DeepConvNet     48.26   0.00     46.98  0.00\n",
      "subject :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 1, 400, 16)       352       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 1, 100, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 1, 100, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 1, 12, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7271 - accuracy: 0.5069INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 22s 6s/step - loss: 0.7271 - accuracy: 0.5069 - val_loss: 0.6612 - val_accuracy: 0.6146 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.6012INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.6486 - accuracy: 0.6012 - val_loss: 0.4908 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.7034INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5730 - accuracy: 0.7034 - val_loss: 0.4867 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5421 - accuracy: 0.7297 - val_loss: 0.5017 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.5234 - accuracy: 0.7381 - val_loss: 0.7744 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5087 - accuracy: 0.7490 - val_loss: 0.7171 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.7128 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 17s 5s/step - loss: 0.4911 - accuracy: 0.7555 - val_loss: 0.7002 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.4797 - accuracy: 0.7708 - val_loss: 1.2590 - val_accuracy: 0.6910 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4635 - accuracy: 0.7768 - val_loss: 1.1921 - val_accuracy: 0.6840 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4533 - accuracy: 0.7907 - val_loss: 0.9159 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.4418 - accuracy: 0.8036 - val_loss: 0.8503 - val_accuracy: 0.7292 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4310 - accuracy: 0.8046 - val_loss: 0.7810 - val_accuracy: 0.7292 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4265 - accuracy: 0.8125 - val_loss: 0.6271 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4199 - accuracy: 0.8170 - val_loss: 0.8227 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4129 - accuracy: 0.8189 - val_loss: 0.5488 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.8214INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4138 - accuracy: 0.8214 - val_loss: 0.4297 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.3923 - accuracy: 0.8348 - val_loss: 0.4406 - val_accuracy: 0.7743 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8373INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.3834 - accuracy: 0.8373 - val_loss: 0.4202 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3892 - accuracy: 0.8358 - val_loss: 0.4207 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8328INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3838 - accuracy: 0.8328 - val_loss: 0.3719 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8328INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3769 - accuracy: 0.8328 - val_loss: 0.3685 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.8353INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3750 - accuracy: 0.8353 - val_loss: 0.3537 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3705 - accuracy: 0.8378 - val_loss: 0.3895 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3458 - accuracy: 0.8542 - val_loss: 0.3642 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8527INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.3394 - accuracy: 0.8527 - val_loss: 0.3516 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3291 - accuracy: 0.8566 - val_loss: 0.4257 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3250 - accuracy: 0.8581 - val_loss: 0.3652 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.3186 - accuracy: 0.8661 - val_loss: 0.3897 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.3060 - accuracy: 0.8695 - val_loss: 0.4253 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3053 - accuracy: 0.8715 - val_loss: 0.4793 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2837 - accuracy: 0.8800 - val_loss: 0.4112 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.2881 - accuracy: 0.8810 - val_loss: 0.3894 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.8805INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.2826 - accuracy: 0.8805 - val_loss: 0.3498 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.2767 - accuracy: 0.8839 - val_loss: 0.3633 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.2726 - accuracy: 0.8854 - val_loss: 0.3569 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.2566 - accuracy: 0.9023 - val_loss: 0.4453 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2442 - accuracy: 0.9038 - val_loss: 0.4168 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.2338 - accuracy: 0.9033 - val_loss: 0.4303 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.2388 - accuracy: 0.9013 - val_loss: 0.3856 - val_accuracy: 0.8264 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.2283 - accuracy: 0.9062 - val_loss: 0.4336 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.2224 - accuracy: 0.9097 - val_loss: 0.4461 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.2132 - accuracy: 0.9167 - val_loss: 0.4354 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2236 - accuracy: 0.9053 - val_loss: 0.3866 - val_accuracy: 0.8229 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2080 - accuracy: 0.9157 - val_loss: 0.3726 - val_accuracy: 0.8403 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.2025 - accuracy: 0.9271 - val_loss: 0.3635 - val_accuracy: 0.8299 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.2049 - accuracy: 0.9211 - val_loss: 0.4182 - val_accuracy: 0.8264 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.1933 - accuracy: 0.9251 - val_loss: 0.4410 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1991 - accuracy: 0.9162 - val_loss: 0.4253 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.2032 - accuracy: 0.9187 - val_loss: 0.5469 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1969 - accuracy: 0.9236 - val_loss: 0.3749 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1858 - accuracy: 0.9251 - val_loss: 0.3553 - val_accuracy: 0.8438 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1819 - accuracy: 0.9311 - val_loss: 0.5201 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1920 - accuracy: 0.9256 - val_loss: 0.6047 - val_accuracy: 0.7639 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 01:56:24.275512: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.84      0.74       144\n",
      "         1.0       0.79      0.58      0.67       144\n",
      "\n",
      "    accuracy                           0.71       288\n",
      "   macro avg       0.73      0.71      0.71       288\n",
      "weighted avg       0.73      0.71      0.71       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 396, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 198, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 194, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 97, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 93, 100)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 46, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 42, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 21, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4200)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.3989 - accuracy: 0.5000INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 2s/step - loss: 5.3989 - accuracy: 0.5000 - val_loss: 33.3500 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.5049 - accuracy: 0.5154 INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 9.5049 - accuracy: 0.5154 - val_loss: 11.1286 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.7546 - accuracy: 0.5010INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 3.7546 - accuracy: 0.5010 - val_loss: 1.8730 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.1413 - accuracy: 0.5119 - val_loss: 2.2562 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5371 - accuracy: 0.5129 - val_loss: 2.1230 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3698 - accuracy: 0.4965INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.3698 - accuracy: 0.4965 - val_loss: 1.3551 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0763 - accuracy: 0.4846 - val_loss: 1.3713 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9820 - accuracy: 0.5198INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9820 - accuracy: 0.5198 - val_loss: 1.1968 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9333 - accuracy: 0.5114INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9333 - accuracy: 0.5114 - val_loss: 1.0616 - val_accuracy: 0.4826 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8150 - accuracy: 0.5055INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.8150 - accuracy: 0.5055 - val_loss: 0.7763 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7653 - accuracy: 0.5288 - val_loss: 0.7955 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7658 - accuracy: 0.5154 - val_loss: 0.9298 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.5104INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 3s/step - loss: 0.7660 - accuracy: 0.5104 - val_loss: 0.7348 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.5258INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7227 - accuracy: 0.5258 - val_loss: 0.7184 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7172 - accuracy: 0.5308 - val_loss: 0.9059 - val_accuracy: 0.4583 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.5377INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.7238 - accuracy: 0.5377 - val_loss: 0.7137 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5600INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.6941 - accuracy: 0.5600 - val_loss: 0.7107 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7035 - accuracy: 0.5367 - val_loss: 0.7773 - val_accuracy: 0.3924 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7029 - accuracy: 0.5481 - val_loss: 0.7614 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6951 - accuracy: 0.5466 - val_loss: 0.7493 - val_accuracy: 0.4410 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7041 - accuracy: 0.5397 - val_loss: 0.7108 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7024 - accuracy: 0.5511 - val_loss: 0.8180 - val_accuracy: 0.4549 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6991 - accuracy: 0.5521 - val_loss: 0.7278 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6993 - accuracy: 0.5531 - val_loss: 0.7347 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7105 - accuracy: 0.5565 - val_loss: 0.8074 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6969 - accuracy: 0.5689 - val_loss: 0.7322 - val_accuracy: 0.4653 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6911 - accuracy: 0.5744 - val_loss: 0.7500 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6824 - accuracy: 0.5714 - val_loss: 0.7611 - val_accuracy: 0.4583 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.5724INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 3s/step - loss: 0.6840 - accuracy: 0.5724 - val_loss: 0.6989 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6916 - accuracy: 0.5660 - val_loss: 0.7551 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6859 - accuracy: 0.5734 - val_loss: 0.7401 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6765 - accuracy: 0.5813 - val_loss: 0.7723 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6831 - accuracy: 0.5799 - val_loss: 0.7182 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6742 - accuracy: 0.5987 - val_loss: 0.7814 - val_accuracy: 0.4549 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6678 - accuracy: 0.5938 - val_loss: 0.7271 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6719 - accuracy: 0.5938 - val_loss: 0.7526 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6675 - accuracy: 0.5878 - val_loss: 0.7453 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6635 - accuracy: 0.6176 - val_loss: 0.7142 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6559 - accuracy: 0.6022 - val_loss: 0.7622 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6580 - accuracy: 0.6181 - val_loss: 0.7604 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6584 - accuracy: 0.6076 - val_loss: 0.7463 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6567 - accuracy: 0.6220 - val_loss: 0.7309 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6576 - accuracy: 0.6086 - val_loss: 0.8001 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6576 - accuracy: 0.6195 - val_loss: 0.7207 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6532 - accuracy: 0.6220 - val_loss: 0.7332 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6538 - accuracy: 0.6151 - val_loss: 0.8044 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6544 - accuracy: 0.6156 - val_loss: 0.8079 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.6245INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.6486 - accuracy: 0.6245 - val_loss: 0.6913 - val_accuracy: 0.5660 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6435 - accuracy: 0.6344 - val_loss: 0.8916 - val_accuracy: 0.4410 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6553 - accuracy: 0.6225 - val_loss: 0.7290 - val_accuracy: 0.5764 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6578 - accuracy: 0.6111 - val_loss: 0.7919 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6763 - accuracy: 0.6081 - val_loss: 0.7841 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6480 - accuracy: 0.6359 - val_loss: 0.8114 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6449 - accuracy: 0.6215 - val_loss: 0.7517 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6402 - accuracy: 0.6334 - val_loss: 0.7408 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6413 - accuracy: 0.6255 - val_loss: 0.8109 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6404 - accuracy: 0.6453 - val_loss: 0.7366 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6293 - accuracy: 0.6483 - val_loss: 0.7781 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6203 - accuracy: 0.6637 - val_loss: 0.8179 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6048 - accuracy: 0.6761 - val_loss: 0.7168 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6000 - accuracy: 0.6746 - val_loss: 0.7783 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5879 - accuracy: 0.6900 - val_loss: 0.7730 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5771 - accuracy: 0.6964 - val_loss: 0.8101 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5515 - accuracy: 0.7148 - val_loss: 0.7584 - val_accuracy: 0.5382 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5627 - accuracy: 0.7009 - val_loss: 0.7350 - val_accuracy: 0.5590 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.5285 - accuracy: 0.7326 - val_loss: 0.7418 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5040 - accuracy: 0.7520 - val_loss: 0.7784 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4947 - accuracy: 0.7540 - val_loss: 0.8747 - val_accuracy: 0.5660 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 02:03:04.740589: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.74      0.60       144\n",
      "         1.0       0.51      0.27      0.35       144\n",
      "\n",
      "    accuracy                           0.50       288\n",
      "   macro avg       0.50      0.50      0.48       288\n",
      "weighted avg       0.50      0.50      0.48       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  1\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     76.22   5.03     74.70  7.77\n",
      "9                all     64.93   4.86     66.07  4.03\n",
      "4    cross_correlate     61.11   5.90     64.54  5.49\n",
      "12            EEGene     60.76   6.25     64.79  4.85\n",
      "1                raw     59.03   3.12     58.49  2.44\n",
      "0         covariance     57.47   3.99     58.17  6.37\n",
      "6            meanstd     56.60   5.56     58.35  3.40\n",
      "7           variance     55.21   5.90     56.94  4.97\n",
      "8   spectral_entropy     55.03   1.22     54.04  4.23\n",
      "5             maxmin     52.08   3.82     53.39  6.04\n",
      "3                fft     50.00   1.39     48.15  2.56\n",
      "11       DeepConvNet     49.31   1.04     41.13  5.84\n",
      "2               fft2     48.96   2.78     47.90  2.28\n",
      "subject :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 1, 400, 16)       352       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_8 (Averag  (None, 1, 100, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 1, 100, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_9 (Averag  (None, 1, 12, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7152 - accuracy: 0.5317INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7152 - accuracy: 0.5317 - val_loss: 0.6903 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6349 - accuracy: 0.6438 - val_loss: 0.8661 - val_accuracy: 0.5590 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5714 - accuracy: 0.7049 - val_loss: 1.3555 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5225 - accuracy: 0.7555 - val_loss: 1.7689 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5017 - accuracy: 0.7693 - val_loss: 1.8922 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4878 - accuracy: 0.7743 - val_loss: 1.9223 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4677 - accuracy: 0.7753 - val_loss: 1.6928 - val_accuracy: 0.5382 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4566 - accuracy: 0.7941 - val_loss: 1.7234 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4469 - accuracy: 0.7976 - val_loss: 1.7284 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4345 - accuracy: 0.8006 - val_loss: 1.5287 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4227 - accuracy: 0.8135 - val_loss: 1.4242 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4072 - accuracy: 0.8150 - val_loss: 1.3001 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4006 - accuracy: 0.8229 - val_loss: 1.1969 - val_accuracy: 0.5694 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3866 - accuracy: 0.8269 - val_loss: 1.1174 - val_accuracy: 0.6007 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.3788 - accuracy: 0.8323 - val_loss: 1.0497 - val_accuracy: 0.5799 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3680 - accuracy: 0.8428 - val_loss: 0.9889 - val_accuracy: 0.6042 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3546 - accuracy: 0.8557 - val_loss: 1.0608 - val_accuracy: 0.5868 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3490 - accuracy: 0.8502 - val_loss: 1.2804 - val_accuracy: 0.5868 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3326 - accuracy: 0.8611 - val_loss: 1.1369 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3309 - accuracy: 0.8576 - val_loss: 1.1448 - val_accuracy: 0.5972 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3239 - accuracy: 0.8606 - val_loss: 1.0571 - val_accuracy: 0.5868 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:34:37.005770: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.65      0.60       144\n",
      "         1.0       0.57      0.47      0.51       144\n",
      "\n",
      "    accuracy                           0.56       288\n",
      "   macro avg       0.56      0.56      0.56       288\n",
      "weighted avg       0.56      0.56      0.56       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 396, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 198, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 194, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 97, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 93, 100)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 46, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 42, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 21, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4200)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.7159 - accuracy: 0.5060INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 10s 2s/step - loss: 7.7159 - accuracy: 0.5060 - val_loss: 12.8386 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.2294 - accuracy: 0.5064INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 3.2294 - accuracy: 0.5064 - val_loss: 1.1498 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.9517 - accuracy: 0.4940 - val_loss: 3.6428 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.7105 - accuracy: 0.5099 - val_loss: 1.2108 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.5159INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9954 - accuracy: 0.5159 - val_loss: 0.8426 - val_accuracy: 0.4757 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.5119INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 3s/step - loss: 0.7781 - accuracy: 0.5119 - val_loss: 0.7577 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7365 - accuracy: 0.5119 - val_loss: 0.7913 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7234 - accuracy: 0.5283INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7234 - accuracy: 0.5283 - val_loss: 0.7480 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7238 - accuracy: 0.5154 - val_loss: 0.7733 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7341 - accuracy: 0.4980INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.7341 - accuracy: 0.4980 - val_loss: 0.7219 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7241 - accuracy: 0.5278 - val_loss: 0.7510 - val_accuracy: 0.4340 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7178 - accuracy: 0.5203 - val_loss: 0.7287 - val_accuracy: 0.4653 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7072 - accuracy: 0.5422 - val_loss: 0.7634 - val_accuracy: 0.4132 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7137 - accuracy: 0.5243 - val_loss: 0.7592 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7229 - accuracy: 0.5184 - val_loss: 0.7508 - val_accuracy: 0.4201 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7118 - accuracy: 0.5248 - val_loss: 0.7277 - val_accuracy: 0.4167 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7061 - accuracy: 0.5228 - val_loss: 0.7337 - val_accuracy: 0.4410 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7114 - accuracy: 0.5303 - val_loss: 0.7224 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6985 - accuracy: 0.5437 - val_loss: 0.7449 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6928 - accuracy: 0.5585 - val_loss: 0.7365 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6965 - accuracy: 0.5392 - val_loss: 0.7520 - val_accuracy: 0.4236 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6996 - accuracy: 0.5422 - val_loss: 0.7386 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7001 - accuracy: 0.5327 - val_loss: 0.7791 - val_accuracy: 0.4062 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7087 - accuracy: 0.5288 - val_loss: 0.7481 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7120 - accuracy: 0.5258 - val_loss: 0.7706 - val_accuracy: 0.4236 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7048 - accuracy: 0.5441 - val_loss: 0.7293 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6986 - accuracy: 0.5432 - val_loss: 0.7454 - val_accuracy: 0.4375 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7024 - accuracy: 0.5417 - val_loss: 0.7230 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6909 - accuracy: 0.5615 - val_loss: 0.7527 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6889 - accuracy: 0.5694 - val_loss: 0.7308 - val_accuracy: 0.4896 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:37:29.886598: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.80      0.61       144\n",
      "         1.0       0.50      0.20      0.29       144\n",
      "\n",
      "    accuracy                           0.50       288\n",
      "   macro avg       0.50      0.50      0.45       288\n",
      "weighted avg       0.50      0.50      0.45       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  2\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     69.44  10.42     66.91 12.71\n",
      "9                all     69.33   7.38     70.07  6.53\n",
      "4    cross_correlate     67.71  10.50     69.97  8.90\n",
      "12            EEGene     67.36  10.63     70.47  8.95\n",
      "0         covariance     63.19   8.73     63.92  9.65\n",
      "6            meanstd     62.50   9.50     63.43  7.69\n",
      "1                raw     61.57   4.41     62.07  5.44\n",
      "8   spectral_entropy     60.07   7.19     59.55  8.51\n",
      "7           variance     58.56   6.76     58.95  4.95\n",
      "5             maxmin     53.82   3.97     56.07  6.22\n",
      "3                fft     52.31   3.46     50.35  3.75\n",
      "2               fft2     50.35   3.00     48.28  1.94\n",
      "11       DeepConvNet     49.54   0.91     36.99  7.55\n",
      "subject :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 1, 400, 16)       352       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 1, 100, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 1, 100, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_13 (Avera  (None, 1, 12, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.5238INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7207 - accuracy: 0.5238 - val_loss: 0.6970 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.6057INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6605 - accuracy: 0.6057 - val_loss: 0.4361 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5775 - accuracy: 0.7054 - val_loss: 0.5268 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.5504 - accuracy: 0.7227 - val_loss: 0.4923 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.5297 - accuracy: 0.7396 - val_loss: 0.5981 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.5217 - accuracy: 0.7495 - val_loss: 0.6744 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4917 - accuracy: 0.7644 - val_loss: 0.4642 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4850 - accuracy: 0.7679 - val_loss: 0.8691 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4737 - accuracy: 0.7798 - val_loss: 0.5638 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4573 - accuracy: 0.7857 - val_loss: 0.5422 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4396 - accuracy: 0.8026 - val_loss: 0.7443 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4268 - accuracy: 0.8120 - val_loss: 0.4649 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.4148 - accuracy: 0.8120 - val_loss: 0.5199 - val_accuracy: 0.7743 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4098 - accuracy: 0.8259 - val_loss: 0.5156 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8279INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3912 - accuracy: 0.8279 - val_loss: 0.4168 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3979 - accuracy: 0.8145 - val_loss: 0.4992 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3760 - accuracy: 0.8338 - val_loss: 0.4647 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3585 - accuracy: 0.8462 - val_loss: 0.5724 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3546 - accuracy: 0.8438 - val_loss: 0.4734 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3397 - accuracy: 0.8576 - val_loss: 0.4867 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3389 - accuracy: 0.8557 - val_loss: 0.5012 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3216 - accuracy: 0.8616 - val_loss: 0.4508 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2924 - accuracy: 0.8810 - val_loss: 0.5187 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2830 - accuracy: 0.8834 - val_loss: 0.4410 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2647 - accuracy: 0.8879 - val_loss: 0.5150 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2560 - accuracy: 0.8998 - val_loss: 0.5418 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2388 - accuracy: 0.9038 - val_loss: 0.4872 - val_accuracy: 0.7986 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2428 - accuracy: 0.9048 - val_loss: 0.7032 - val_accuracy: 0.7118 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2346 - accuracy: 0.9023 - val_loss: 0.6903 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2317 - accuracy: 0.9043 - val_loss: 0.4953 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2134 - accuracy: 0.9231 - val_loss: 0.4903 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2095 - accuracy: 0.9177 - val_loss: 0.5880 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9231INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2103 - accuracy: 0.9231 - val_loss: 0.3922 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2103 - accuracy: 0.9221 - val_loss: 0.4368 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1995 - accuracy: 0.9226 - val_loss: 0.4747 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1947 - accuracy: 0.9291 - val_loss: 0.5824 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1891 - accuracy: 0.9216 - val_loss: 0.6800 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1953 - accuracy: 0.9281 - val_loss: 0.5386 - val_accuracy: 0.7743 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1780 - accuracy: 0.9276 - val_loss: 0.5178 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1866 - accuracy: 0.9241 - val_loss: 0.5482 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1909 - accuracy: 0.9177 - val_loss: 0.7470 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1788 - accuracy: 0.9291 - val_loss: 0.5222 - val_accuracy: 0.7917 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1852 - accuracy: 0.9251 - val_loss: 0.4009 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1730 - accuracy: 0.9315 - val_loss: 0.3994 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1689 - accuracy: 0.9390 - val_loss: 0.5355 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1750 - accuracy: 0.9306 - val_loss: 0.4362 - val_accuracy: 0.8229 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1680 - accuracy: 0.9311 - val_loss: 0.5102 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1635 - accuracy: 0.9400 - val_loss: 0.4666 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.4126 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9301INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1738 - accuracy: 0.9301 - val_loss: 0.3603 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1695 - accuracy: 0.9355 - val_loss: 0.4518 - val_accuracy: 0.8333 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1594 - accuracy: 0.9415 - val_loss: 0.4454 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1527 - accuracy: 0.9400 - val_loss: 0.3785 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1577 - accuracy: 0.9415 - val_loss: 0.3934 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1504 - accuracy: 0.9454 - val_loss: 0.3839 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1748 - accuracy: 0.9296 - val_loss: 0.4897 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1570 - accuracy: 0.9400 - val_loss: 0.4894 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1416 - accuracy: 0.9474 - val_loss: 0.4028 - val_accuracy: 0.8403 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1655 - accuracy: 0.9370 - val_loss: 0.4262 - val_accuracy: 0.8403 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1411 - accuracy: 0.9509 - val_loss: 0.4089 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1404 - accuracy: 0.9454 - val_loss: 0.4942 - val_accuracy: 0.8229 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1372 - accuracy: 0.9469 - val_loss: 0.4441 - val_accuracy: 0.8403 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1471 - accuracy: 0.9425 - val_loss: 0.4139 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1451 - accuracy: 0.9435 - val_loss: 0.4063 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1409 - accuracy: 0.9494 - val_loss: 0.4480 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1342 - accuracy: 0.9484 - val_loss: 0.3688 - val_accuracy: 0.8681 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1362 - accuracy: 0.9464 - val_loss: 0.3749 - val_accuracy: 0.8715 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.4905 - val_accuracy: 0.8472 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1437 - accuracy: 0.9474 - val_loss: 0.4098 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1445 - accuracy: 0.9345 - val_loss: 0.4530 - val_accuracy: 0.8368 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 06:52:19.180742: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.81      0.77       144\n",
      "         1.0       0.78      0.70      0.74       144\n",
      "\n",
      "    accuracy                           0.75       288\n",
      "   macro avg       0.76      0.75      0.75       288\n",
      "weighted avg       0.76      0.75      0.75       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 1, 396, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 198, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 1, 194, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 97, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 1, 93, 100)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 46, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 1, 42, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 21, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 4200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.6459 - accuracy: 0.5203INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 7.6459 - accuracy: 0.5203 - val_loss: 14.6565 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4156 - accuracy: 0.5050INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 3.4156 - accuracy: 0.5050 - val_loss: 2.5009 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.5114INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4815 - accuracy: 0.5114 - val_loss: 1.1722 - val_accuracy: 0.4896 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8364 - accuracy: 0.5243INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.8364 - accuracy: 0.5243 - val_loss: 1.1488 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.5035INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.8424 - accuracy: 0.5035 - val_loss: 0.7963 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8414 - accuracy: 0.5114 - val_loss: 0.9311 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8099 - accuracy: 0.5154 - val_loss: 0.9165 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7972 - accuracy: 0.5223INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7972 - accuracy: 0.5223 - val_loss: 0.7913 - val_accuracy: 0.4340 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.5347INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7445 - accuracy: 0.5347 - val_loss: 0.7527 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7373 - accuracy: 0.5268 - val_loss: 0.7657 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7247 - accuracy: 0.5278 - val_loss: 0.8011 - val_accuracy: 0.4479 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7168 - accuracy: 0.5516 - val_loss: 0.7700 - val_accuracy: 0.4583 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7274 - accuracy: 0.5293INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7274 - accuracy: 0.5293 - val_loss: 0.7328 - val_accuracy: 0.4688 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7323 - accuracy: 0.5174 - val_loss: 0.8177 - val_accuracy: 0.4653 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7277 - accuracy: 0.5402 - val_loss: 0.8640 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7599 - accuracy: 0.5193 - val_loss: 0.8625 - val_accuracy: 0.4826 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7555 - accuracy: 0.5298 - val_loss: 0.7751 - val_accuracy: 0.4653 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7365 - accuracy: 0.5451 - val_loss: 0.7972 - val_accuracy: 0.4722 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7025 - accuracy: 0.5580 - val_loss: 0.8073 - val_accuracy: 0.4271 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6986 - accuracy: 0.5724 - val_loss: 0.7526 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7019 - accuracy: 0.5645 - val_loss: 0.7727 - val_accuracy: 0.4410 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7013 - accuracy: 0.5630 - val_loss: 0.7583 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6852 - accuracy: 0.5823 - val_loss: 0.7838 - val_accuracy: 0.4549 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6663 - accuracy: 0.6116 - val_loss: 0.7546 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6727 - accuracy: 0.5957 - val_loss: 0.7627 - val_accuracy: 0.4826 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6581 - accuracy: 0.6141 - val_loss: 0.7705 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6470 - accuracy: 0.6205 - val_loss: 0.7541 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6361 - accuracy: 0.6384 - val_loss: 0.8302 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6151 - accuracy: 0.6558 - val_loss: 0.7377 - val_accuracy: 0.5660 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.6696INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5976 - accuracy: 0.6696 - val_loss: 0.7109 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.6801INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.5809 - accuracy: 0.6801 - val_loss: 0.6290 - val_accuracy: 0.6285 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7024INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5502 - accuracy: 0.7024 - val_loss: 0.5892 - val_accuracy: 0.6944 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5398 - accuracy: 0.7158 - val_loss: 0.6052 - val_accuracy: 0.6736 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.7416INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5139 - accuracy: 0.7416 - val_loss: 0.5069 - val_accuracy: 0.7465 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.7639INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.4764 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4602 - accuracy: 0.7679 - val_loss: 0.7053 - val_accuracy: 0.6285 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 1.1282 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.6993 - val_accuracy: 0.6319 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4238 - accuracy: 0.7887 - val_loss: 1.3244 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8145INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3921 - accuracy: 0.8145 - val_loss: 0.4163 - val_accuracy: 0.8229 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3683 - accuracy: 0.8313 - val_loss: 0.5038 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3569 - accuracy: 0.8398 - val_loss: 0.4616 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3348 - accuracy: 0.8497 - val_loss: 1.5661 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3550 - accuracy: 0.8403 - val_loss: 0.9491 - val_accuracy: 0.5729 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3215 - accuracy: 0.8581 - val_loss: 0.5026 - val_accuracy: 0.7535 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3339 - accuracy: 0.8487 - val_loss: 1.2316 - val_accuracy: 0.5243 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3238 - accuracy: 0.8507 - val_loss: 0.4670 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3059 - accuracy: 0.8606 - val_loss: 0.5168 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2795 - accuracy: 0.8770 - val_loss: 0.4431 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2845 - accuracy: 0.8760 - val_loss: 0.7106 - val_accuracy: 0.6736 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2856 - accuracy: 0.8844 - val_loss: 0.7379 - val_accuracy: 0.6181 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2695 - accuracy: 0.8839 - val_loss: 0.5551 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2613 - accuracy: 0.8904 - val_loss: 0.4523 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2717 - accuracy: 0.8874 - val_loss: 0.4656 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2635 - accuracy: 0.8869 - val_loss: 0.4590 - val_accuracy: 0.8125 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2667 - accuracy: 0.8849 - val_loss: 1.1417 - val_accuracy: 0.5590 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2532 - accuracy: 0.8968 - val_loss: 0.5902 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2613 - accuracy: 0.8924 - val_loss: 0.5643 - val_accuracy: 0.7326 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2443 - accuracy: 0.8983 - val_loss: 0.6059 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2573 - accuracy: 0.8929 - val_loss: 0.4282 - val_accuracy: 0.8229 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 06:57:43.416022: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.97      0.72       144\n",
      "         1.0       0.90      0.26      0.40       144\n",
      "\n",
      "    accuracy                           0.61       288\n",
      "   macro avg       0.73      0.61      0.56       288\n",
      "weighted avg       0.73      0.61      0.56       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  3\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     70.92   9.38     68.68 11.42\n",
      "9                all     67.27   7.31     65.78  9.33\n",
      "12            EEGene     67.01   9.23     67.47  9.33\n",
      "4    cross_correlate     64.76  10.43     63.85 13.10\n",
      "6            meanstd     62.50   8.23     61.94  7.14\n",
      "0         covariance     62.24   7.74     61.90  9.06\n",
      "1                raw     62.07   3.92     60.38  5.54\n",
      "8   spectral_entropy     59.20   6.40     58.30  7.68\n",
      "7           variance     57.03   6.43     53.71 10.03\n",
      "5             maxmin     54.95   3.95     55.60  5.45\n",
      "3                fft     52.95   3.20     51.07  3.48\n",
      "11       DeepConvNet     52.52   5.22     37.75  6.67\n",
      "2               fft2     50.52   2.62     49.18  2.29\n",
      "subject :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthwi  (None, 1, 400, 16)       352       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_16 (Avera  (None, 1, 100, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 1, 100, 16)       1056      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_17 (Avera  (None, 1, 12, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7444 - accuracy: 0.5005INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7444 - accuracy: 0.5005 - val_loss: 0.6928 - val_accuracy: 0.5382 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.6560 - accuracy: 0.6136 - val_loss: 0.7457 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5838 - accuracy: 0.6935 - val_loss: 2.2747 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5402 - accuracy: 0.7326 - val_loss: 5.3209 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.5099 - accuracy: 0.7515 - val_loss: 7.1017 - val_accuracy: 0.5104 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4765 - accuracy: 0.7808 - val_loss: 3.0753 - val_accuracy: 0.6285 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4312 - accuracy: 0.8075 - val_loss: 2.2013 - val_accuracy: 0.6215 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3856 - accuracy: 0.8289 - val_loss: 2.5775 - val_accuracy: 0.6146 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3636 - accuracy: 0.8423 - val_loss: 3.4638 - val_accuracy: 0.6319 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3407 - accuracy: 0.8532 - val_loss: 2.6069 - val_accuracy: 0.6493 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3223 - accuracy: 0.8641 - val_loss: 3.0824 - val_accuracy: 0.6424 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3180 - accuracy: 0.8661 - val_loss: 1.7796 - val_accuracy: 0.6667 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3039 - accuracy: 0.8824 - val_loss: 2.2133 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2957 - accuracy: 0.8800 - val_loss: 1.4294 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2845 - accuracy: 0.8834 - val_loss: 1.4944 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2811 - accuracy: 0.8844 - val_loss: 1.3885 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2689 - accuracy: 0.8819 - val_loss: 1.4334 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2784 - accuracy: 0.8755 - val_loss: 1.4048 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2707 - accuracy: 0.8879 - val_loss: 1.4302 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2597 - accuracy: 0.8978 - val_loss: 1.3508 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2459 - accuracy: 0.8983 - val_loss: 1.3332 - val_accuracy: 0.7396 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 10:20:16.047145: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.32      0.41       144\n",
      "         1.0       0.53      0.77      0.63       144\n",
      "\n",
      "    accuracy                           0.55       288\n",
      "   macro avg       0.56      0.55      0.52       288\n",
      "weighted avg       0.56      0.55      0.52       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 1, 396, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 198, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 1, 194, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 97, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 1, 93, 100)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 1, 46, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 1, 42, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 1, 21, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 4200)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.2448 - accuracy: 0.5149INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.2448 - accuracy: 0.5149 - val_loss: 16.2149 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.1834 - accuracy: 0.4965INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 4.1834 - accuracy: 0.4965 - val_loss: 0.7460 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.5119INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4644 - accuracy: 0.5119 - val_loss: 0.7064 - val_accuracy: 0.5660 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.1200 - accuracy: 0.4826 - val_loss: 0.7406 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.9105 - accuracy: 0.5084 - val_loss: 0.8486 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8657 - accuracy: 0.5278 - val_loss: 0.7856 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8135 - accuracy: 0.4980INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.8135 - accuracy: 0.4980 - val_loss: 0.6617 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7451 - accuracy: 0.5169 - val_loss: 0.6943 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7328 - accuracy: 0.5179 - val_loss: 0.7032 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7288 - accuracy: 0.5060 - val_loss: 0.6929 - val_accuracy: 0.4965 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7189 - accuracy: 0.5238 - val_loss: 0.7366 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7188 - accuracy: 0.5099 - val_loss: 0.7059 - val_accuracy: 0.5208 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7108 - accuracy: 0.5298 - val_loss: 0.7060 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7042 - accuracy: 0.5094 - val_loss: 0.6718 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6961 - accuracy: 0.5317 - val_loss: 0.6867 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6914 - accuracy: 0.5471 - val_loss: 0.6725 - val_accuracy: 0.5868 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6973 - accuracy: 0.5377 - val_loss: 0.6782 - val_accuracy: 0.5799 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6937 - accuracy: 0.5372 - val_loss: 0.7070 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7056 - accuracy: 0.5352 - val_loss: 0.6738 - val_accuracy: 0.5729 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7137 - accuracy: 0.5114 - val_loss: 0.7099 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7197 - accuracy: 0.5134 - val_loss: 0.6716 - val_accuracy: 0.6007 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7071 - accuracy: 0.5203 - val_loss: 0.6862 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6981 - accuracy: 0.5476 - val_loss: 0.7088 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7028 - accuracy: 0.5342 - val_loss: 0.6851 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5476INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.6925 - accuracy: 0.5476 - val_loss: 0.6552 - val_accuracy: 0.6146 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6855 - accuracy: 0.5526 - val_loss: 0.6883 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6851 - accuracy: 0.5620 - val_loss: 0.6698 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6844 - accuracy: 0.5551 - val_loss: 0.6706 - val_accuracy: 0.5729 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6862 - accuracy: 0.5650 - val_loss: 0.7014 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6945 - accuracy: 0.5660 - val_loss: 0.6595 - val_accuracy: 0.6076 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6718 - accuracy: 0.5863 - val_loss: 0.6594 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6641 - accuracy: 0.5972 - val_loss: 0.6711 - val_accuracy: 0.5833 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6547 - accuracy: 0.6071 - val_loss: 0.6558 - val_accuracy: 0.5972 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6454 - accuracy: 0.6290 - val_loss: 0.6959 - val_accuracy: 0.5833 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6202 - accuracy: 0.6513 - val_loss: 0.7416 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5930 - accuracy: 0.6825 - val_loss: 0.9287 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5662 - accuracy: 0.7029 - val_loss: 0.9055 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5242 - accuracy: 0.7282 - val_loss: 0.8721 - val_accuracy: 0.5694 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4859 - accuracy: 0.7589 - val_loss: 0.9737 - val_accuracy: 0.5347 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4580 - accuracy: 0.7788 - val_loss: 1.2491 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4360 - accuracy: 0.7892 - val_loss: 1.3449 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4293 - accuracy: 0.7857 - val_loss: 0.7324 - val_accuracy: 0.6736 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8026INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3938 - accuracy: 0.8026 - val_loss: 0.6479 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3736 - accuracy: 0.8165 - val_loss: 0.9889 - val_accuracy: 0.6910 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3705 - accuracy: 0.8313 - val_loss: 1.2038 - val_accuracy: 0.5799 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3492 - accuracy: 0.8438 - val_loss: 0.7963 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3427 - accuracy: 0.8383 - val_loss: 0.6966 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3296 - accuracy: 0.8442 - val_loss: 0.7842 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3199 - accuracy: 0.8576 - val_loss: 0.9931 - val_accuracy: 0.6736 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3230 - accuracy: 0.8507 - val_loss: 0.8669 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3130 - accuracy: 0.8571 - val_loss: 0.7740 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2991 - accuracy: 0.8686 - val_loss: 0.7424 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2987 - accuracy: 0.8661 - val_loss: 0.8411 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3096 - accuracy: 0.8611 - val_loss: 0.9083 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3047 - accuracy: 0.8557 - val_loss: 0.8053 - val_accuracy: 0.7222 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2908 - accuracy: 0.8666 - val_loss: 0.7775 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2986 - accuracy: 0.8626 - val_loss: 0.8123 - val_accuracy: 0.7396 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2661 - accuracy: 0.8834 - val_loss: 0.8113 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2681 - accuracy: 0.8790 - val_loss: 0.9311 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2812 - accuracy: 0.8760 - val_loss: 0.9205 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2785 - accuracy: 0.8775 - val_loss: 1.5298 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2819 - accuracy: 0.8710 - val_loss: 0.9241 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2577 - accuracy: 0.8800 - val_loss: 1.0884 - val_accuracy: 0.6701 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 10:25:28.173392: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.69      0.77       144\n",
      "         1.0       0.74      0.90      0.81       144\n",
      "\n",
      "    accuracy                           0.79       288\n",
      "   macro avg       0.80      0.79      0.79       288\n",
      "weighted avg       0.80      0.79      0.79       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  4\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     67.64  10.65     67.52 10.48\n",
      "12            EEGene     66.60   8.30     66.94  8.41\n",
      "9                all     65.14   7.81     64.38  8.80\n",
      "1                raw     64.31   5.69     62.90  7.07\n",
      "4    cross_correlate     62.64  10.25     62.93 11.86\n",
      "0         covariance     60.97   7.37     61.89  8.10\n",
      "6            meanstd     60.69   8.20     61.48  6.45\n",
      "8   spectral_entropy     57.85   6.34     56.74  7.54\n",
      "11       DeepConvNet     57.85  11.64     46.42 18.35\n",
      "7           variance     56.74   5.78     55.82  9.91\n",
      "5             maxmin     54.86   3.54     55.02  5.01\n",
      "3                fft     53.12   2.88     52.13  3.77\n",
      "2               fft2     50.83   2.42     49.56  2.18\n",
      "subject :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depthw  (None, 1, 400, 16)       352       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_70 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_20 (Avera  (None, 1, 100, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_10 (Separa  (None, 1, 100, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_71 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_21 (Avera  (None, 1, 12, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.4812INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7546 - accuracy: 0.4812 - val_loss: 0.7099 - val_accuracy: 0.5243 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6703 - accuracy: 0.5893 - val_loss: 0.7569 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6135 - accuracy: 0.6701 - val_loss: 0.7770 - val_accuracy: 0.6632 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5664 - accuracy: 0.7173 - val_loss: 0.7238 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5407 - accuracy: 0.7391 - val_loss: 0.7810 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5279 - accuracy: 0.7331 - val_loss: 0.9085 - val_accuracy: 0.7222 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5116 - accuracy: 0.7465 - val_loss: 0.9345 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4954 - accuracy: 0.7594 - val_loss: 0.9239 - val_accuracy: 0.7257 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4830 - accuracy: 0.7708 - val_loss: 0.8842 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4661 - accuracy: 0.7842 - val_loss: 1.0145 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4563 - accuracy: 0.7803 - val_loss: 0.9901 - val_accuracy: 0.6736 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4423 - accuracy: 0.8011 - val_loss: 0.9489 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4325 - accuracy: 0.8041 - val_loss: 0.7455 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4305 - accuracy: 0.8065 - val_loss: 0.8361 - val_accuracy: 0.7083 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4213 - accuracy: 0.7991 - val_loss: 1.1948 - val_accuracy: 0.6632 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.4039 - accuracy: 0.8170 - val_loss: 0.8250 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3867 - accuracy: 0.8318 - val_loss: 0.7473 - val_accuracy: 0.7188 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8408INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3737 - accuracy: 0.8408 - val_loss: 0.5768 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3686 - accuracy: 0.8433 - val_loss: 0.8024 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3578 - accuracy: 0.8537 - val_loss: 0.9899 - val_accuracy: 0.6632 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3526 - accuracy: 0.8462 - val_loss: 0.6227 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3499 - accuracy: 0.8442 - val_loss: 0.6377 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8502INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3443 - accuracy: 0.8502 - val_loss: 0.5376 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3421 - accuracy: 0.8562 - val_loss: 0.5932 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3178 - accuracy: 0.8681 - val_loss: 0.6268 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3218 - accuracy: 0.8666 - val_loss: 0.5544 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.8760INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3066 - accuracy: 0.8760 - val_loss: 0.5157 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.8611INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.3142 - accuracy: 0.8611 - val_loss: 0.4510 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3088 - accuracy: 0.8730 - val_loss: 0.4662 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3084 - accuracy: 0.8695 - val_loss: 0.4612 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2972 - accuracy: 0.8710 - val_loss: 0.5322 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2755 - accuracy: 0.8869 - val_loss: 0.4885 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2758 - accuracy: 0.8894 - val_loss: 0.4769 - val_accuracy: 0.7986 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.8958INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2680 - accuracy: 0.8958 - val_loss: 0.4433 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2687 - accuracy: 0.8973 - val_loss: 0.4585 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2693 - accuracy: 0.8943 - val_loss: 0.4635 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2578 - accuracy: 0.8993 - val_loss: 0.4583 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9033INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2509 - accuracy: 0.9033 - val_loss: 0.4182 - val_accuracy: 0.8194 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.9003INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2523 - accuracy: 0.9003 - val_loss: 0.3570 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2390 - accuracy: 0.9038 - val_loss: 0.3814 - val_accuracy: 0.8507 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2329 - accuracy: 0.9077 - val_loss: 0.4710 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2436 - accuracy: 0.8993 - val_loss: 0.4144 - val_accuracy: 0.8368 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9077INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2271 - accuracy: 0.9077 - val_loss: 0.3482 - val_accuracy: 0.8646 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9043INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2321 - accuracy: 0.9043 - val_loss: 0.3387 - val_accuracy: 0.8715 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9152INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2150 - accuracy: 0.9152 - val_loss: 0.3132 - val_accuracy: 0.8750 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.2292 - accuracy: 0.9077 - val_loss: 0.4163 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2228 - accuracy: 0.9132 - val_loss: 0.3191 - val_accuracy: 0.8611 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9107INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2260 - accuracy: 0.9107 - val_loss: 0.2771 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9256INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2077 - accuracy: 0.9256 - val_loss: 0.2253 - val_accuracy: 0.9028 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9201INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2042 - accuracy: 0.9201 - val_loss: 0.2177 - val_accuracy: 0.9062 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1995 - accuracy: 0.9231 - val_loss: 0.2559 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9147INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.2040 - accuracy: 0.9147 - val_loss: 0.2110 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9301INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1893 - accuracy: 0.9301 - val_loss: 0.2090 - val_accuracy: 0.9236 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1868 - accuracy: 0.9286 - val_loss: 0.2748 - val_accuracy: 0.8924 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1897 - accuracy: 0.9251 - val_loss: 0.2351 - val_accuracy: 0.9167 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9390INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1763 - accuracy: 0.9390 - val_loss: 0.1728 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1896 - accuracy: 0.9216 - val_loss: 0.1809 - val_accuracy: 0.9306 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1864 - accuracy: 0.9236 - val_loss: 0.1835 - val_accuracy: 0.9306 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1786 - accuracy: 0.9296 - val_loss: 0.2385 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1655 - accuracy: 0.9355 - val_loss: 0.1853 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1770 - accuracy: 0.9311 - val_loss: 0.2334 - val_accuracy: 0.9236 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1823 - accuracy: 0.9256 - val_loss: 0.3586 - val_accuracy: 0.8681 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1904 - accuracy: 0.9196 - val_loss: 0.2642 - val_accuracy: 0.9028 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1739 - accuracy: 0.9306 - val_loss: 0.1922 - val_accuracy: 0.9479 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1761 - accuracy: 0.9266 - val_loss: 0.2641 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1681 - accuracy: 0.9360 - val_loss: 0.2049 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1635 - accuracy: 0.9360 - val_loss: 0.1819 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9306INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1658 - accuracy: 0.9306 - val_loss: 0.1592 - val_accuracy: 0.9271 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1736 - accuracy: 0.9315 - val_loss: 0.2374 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1571 - accuracy: 0.9400 - val_loss: 0.3902 - val_accuracy: 0.8576 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1521 - accuracy: 0.9435 - val_loss: 0.2604 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.1462 - accuracy: 0.9449 - val_loss: 0.1774 - val_accuracy: 0.9306 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9415INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1532 - accuracy: 0.9415 - val_loss: 0.1481 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.1428 - accuracy: 0.9484 - val_loss: 0.1656 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9469INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.1401 - accuracy: 0.9469 - val_loss: 0.1437 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.1326 - accuracy: 0.9504 - val_loss: 0.1657 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1429 - accuracy: 0.9425 - val_loss: 0.2138 - val_accuracy: 0.9306 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1433 - accuracy: 0.9425 - val_loss: 0.2093 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1590 - accuracy: 0.9355 - val_loss: 0.1971 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1507 - accuracy: 0.9375 - val_loss: 0.1531 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9410INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1429 - accuracy: 0.9410 - val_loss: 0.1434 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1453 - accuracy: 0.9435 - val_loss: 0.1717 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1515 - accuracy: 0.9425 - val_loss: 0.1633 - val_accuracy: 0.9514 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1384 - accuracy: 0.9469 - val_loss: 0.1508 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1262 - accuracy: 0.9524 - val_loss: 0.2307 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1336 - accuracy: 0.9499 - val_loss: 0.2322 - val_accuracy: 0.9271 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1346 - accuracy: 0.9449 - val_loss: 0.1596 - val_accuracy: 0.9340 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1293 - accuracy: 0.9499 - val_loss: 0.2361 - val_accuracy: 0.9097 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 14s 4s/step - loss: 0.1376 - accuracy: 0.9454 - val_loss: 0.1563 - val_accuracy: 0.9444 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 14s 3s/step - loss: 0.1544 - accuracy: 0.9380 - val_loss: 0.1499 - val_accuracy: 0.9410 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "1/4 [======>.......................] - ETA: 10s - loss: 0.1234 - accuracy: 0.9444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update score after  5\n",
      "              method  accuracy  +-acc  f1-score  +-f1\n",
      "10            EEGNet     69.21  10.34     69.32 10.37\n",
      "12            EEGene     65.86   7.75     65.98  7.97\n",
      "9                all     64.64   7.22     64.55  8.05\n",
      "1                raw     64.29   5.19     62.66  6.48\n",
      "4    cross_correlate     61.86   9.51     62.79 10.83\n",
      "11       DeepConvNet     61.23  13.04     51.84 20.67\n",
      "6            meanstd     60.65   7.48     60.76  6.11\n",
      "0         covariance     60.13   6.99     60.71  7.86\n",
      "8   spectral_entropy     57.29   5.92     58.34  7.75\n",
      "7           variance     56.25   5.39     56.23  9.09\n",
      "5             maxmin     54.46   3.36     52.97  6.49\n",
      "3                fft     53.01   2.64     51.49  3.73\n",
      "2               fft2     51.27   2.42     49.99  2.21\n",
      "subject :  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting\n",
      "no delete\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 22, 400, 8)        1600      \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 22, 400, 8)       32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_12 (Depthw  (None, 1, 400, 16)       352       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 1, 400, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 1, 400, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_24 (Avera  (None, 1, 100, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_12 (Separa  (None, 1, 100, 16)       1056      \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_86 (Bat  (None, 1, 100, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_25 (Avera  (None, 1, 12, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 1, 12, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 386       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,554\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "The first kernel size is (1, 200)\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7385 - accuracy: 0.4975INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.7385 - accuracy: 0.4975 - val_loss: 1.0407 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.5680INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6966 - accuracy: 0.5680 - val_loss: 1.0197 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.6410 - accuracy: 0.6404 - val_loss: 1.0231 - val_accuracy: 0.6840 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5975 - accuracy: 0.6984INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5975 - accuracy: 0.6984 - val_loss: 0.7842 - val_accuracy: 0.7569 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.7183INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5643 - accuracy: 0.7183 - val_loss: 0.7574 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.5424 - accuracy: 0.7282 - val_loss: 1.0037 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.7401INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5273 - accuracy: 0.7401 - val_loss: 0.6094 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.7609INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5091 - accuracy: 0.7609 - val_loss: 0.5196 - val_accuracy: 0.8056 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7684INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.4948 - accuracy: 0.7684 - val_loss: 0.4493 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4764 - accuracy: 0.7822 - val_loss: 0.4584 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4300 - accuracy: 0.7946 - val_loss: 0.4921 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.4073 - accuracy: 0.8180 - val_loss: 0.5270 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3777 - accuracy: 0.8259 - val_loss: 0.7221 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3638 - accuracy: 0.8398 - val_loss: 0.6140 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3460 - accuracy: 0.8462 - val_loss: 0.6841 - val_accuracy: 0.7396 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3269 - accuracy: 0.8596 - val_loss: 0.6947 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3097 - accuracy: 0.8720 - val_loss: 0.6925 - val_accuracy: 0.7465 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.3114 - accuracy: 0.8591 - val_loss: 0.9831 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 13s 3s/step - loss: 0.3024 - accuracy: 0.8671 - val_loss: 0.9797 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2969 - accuracy: 0.8705 - val_loss: 0.5539 - val_accuracy: 0.7778 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2754 - accuracy: 0.8814 - val_loss: 0.6757 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2712 - accuracy: 0.8909 - val_loss: 0.4756 - val_accuracy: 0.8160 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2886 - accuracy: 0.8705 - val_loss: 0.5995 - val_accuracy: 0.7639 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2589 - accuracy: 0.8943 - val_loss: 0.4739 - val_accuracy: 0.8021 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2657 - accuracy: 0.8854 - val_loss: 0.5532 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2593 - accuracy: 0.8948 - val_loss: 0.4755 - val_accuracy: 0.7951 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2522 - accuracy: 0.8988 - val_loss: 0.5529 - val_accuracy: 0.7847 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 12s 3s/step - loss: 0.2376 - accuracy: 0.9013 - val_loss: 0.5110 - val_accuracy: 0.7812 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:37:55.045103: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.83      0.81       144\n",
      "         1.0       0.82      0.78      0.80       144\n",
      "\n",
      "    accuracy                           0.81       288\n",
      "   macro avg       0.81      0.81      0.81       288\n",
      "weighted avg       0.81      0.81      0.81       288\n",
      "\n",
      "F1-score is computed based on binary\n",
      "deleting\n",
      "no delete\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 22, 400, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 22, 396, 25)       150       \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 1, 396, 25)        13775     \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 1, 396, 25)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_88 (Activation)  (None, 1, 396, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 1, 198, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 1, 198, 25)        0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 1, 194, 50)        6300      \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 1, 194, 50)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_89 (Activation)  (None, 1, 194, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 1, 97, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 1, 97, 50)         0         \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 1, 93, 100)        25100     \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 1, 93, 100)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_90 (Activation)  (None, 1, 93, 100)        0         \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 1, 46, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 1, 46, 100)        0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 1, 42, 200)        100200    \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 1, 42, 200)       4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_91 (Activation)  (None, 1, 42, 200)        0         \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 1, 21, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 1, 21, 200)        0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 4200)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 8402      \n",
      "                                                                 \n",
      " activation_92 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,943\n",
      "Trainable params: 153,935\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.4227 - accuracy: 0.5164INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 9s 2s/step - loss: 8.4227 - accuracy: 0.5164 - val_loss: 16.2009 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.9507 - accuracy: 0.5050INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 3.9507 - accuracy: 0.5050 - val_loss: 3.7119 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4204 - accuracy: 0.5149INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4204 - accuracy: 0.5149 - val_loss: 1.0025 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9522 - accuracy: 0.5243INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.9522 - accuracy: 0.5243 - val_loss: 0.9885 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9047 - accuracy: 0.5203INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9047 - accuracy: 0.5203 - val_loss: 0.8093 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8752 - accuracy: 0.5030INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.8752 - accuracy: 0.5030 - val_loss: 0.8034 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7632 - accuracy: 0.5218 - val_loss: 0.8427 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.5174INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7319 - accuracy: 0.5174 - val_loss: 0.7539 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6985 - accuracy: 0.5332 - val_loss: 0.7583 - val_accuracy: 0.4757 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.5357INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.7014 - accuracy: 0.5357 - val_loss: 0.7295 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6859 - accuracy: 0.5615 - val_loss: 0.7417 - val_accuracy: 0.4306 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6829 - accuracy: 0.5734 - val_loss: 0.7526 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6815 - accuracy: 0.5694 - val_loss: 0.7355 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6715 - accuracy: 0.5794 - val_loss: 0.7382 - val_accuracy: 0.4583 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6649 - accuracy: 0.5947 - val_loss: 0.7502 - val_accuracy: 0.4618 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6573 - accuracy: 0.6106 - val_loss: 0.7692 - val_accuracy: 0.4792 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6448 - accuracy: 0.6225 - val_loss: 0.7720 - val_accuracy: 0.4861 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6397 - accuracy: 0.6434 - val_loss: 0.7954 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6214 - accuracy: 0.6488 - val_loss: 0.7721 - val_accuracy: 0.4931 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6228 - accuracy: 0.6478 - val_loss: 0.7703 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5989 - accuracy: 0.6587 - val_loss: 0.7391 - val_accuracy: 0.5660 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.6974INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5596 - accuracy: 0.6974 - val_loss: 0.7264 - val_accuracy: 0.5833 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.5204 - accuracy: 0.7277 - val_loss: 0.9169 - val_accuracy: 0.5069 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4854 - accuracy: 0.7510 - val_loss: 0.7572 - val_accuracy: 0.5451 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.7758INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4628 - accuracy: 0.7758 - val_loss: 0.7100 - val_accuracy: 0.5382 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4368 - accuracy: 0.7912 - val_loss: 0.7600 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4246 - accuracy: 0.8001 - val_loss: 0.9409 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4235 - accuracy: 0.7961 - val_loss: 0.8875 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4304 - accuracy: 0.7981 - val_loss: 0.9159 - val_accuracy: 0.5312 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4159 - accuracy: 0.7897 - val_loss: 0.7390 - val_accuracy: 0.5417 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3911 - accuracy: 0.8130 - val_loss: 1.1256 - val_accuracy: 0.5139 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3789 - accuracy: 0.8239 - val_loss: 0.7807 - val_accuracy: 0.5660 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3631 - accuracy: 0.8343 - val_loss: 0.7451 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3516 - accuracy: 0.8433 - val_loss: 1.0646 - val_accuracy: 0.5278 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3527 - accuracy: 0.8348 - val_loss: 0.7952 - val_accuracy: 0.5521 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3389 - accuracy: 0.8383 - val_loss: 0.7162 - val_accuracy: 0.5972 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3422 - accuracy: 0.8517 - val_loss: 0.7159 - val_accuracy: 0.6042 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3281 - accuracy: 0.8631 - val_loss: 0.7739 - val_accuracy: 0.5521 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3312 - accuracy: 0.8477 - val_loss: 0.7391 - val_accuracy: 0.5938 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3331 - accuracy: 0.8502 - val_loss: 0.9338 - val_accuracy: 0.5243 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8487INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3331 - accuracy: 0.8487 - val_loss: 0.6926 - val_accuracy: 0.6285 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3296 - accuracy: 0.8492 - val_loss: 0.8247 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3221 - accuracy: 0.8542 - val_loss: 1.5213 - val_accuracy: 0.5035 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3059 - accuracy: 0.8636 - val_loss: 0.8317 - val_accuracy: 0.5903 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3121 - accuracy: 0.8571 - val_loss: 0.7503 - val_accuracy: 0.6215 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3251 - accuracy: 0.8552 - val_loss: 1.0127 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.8492INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3354 - accuracy: 0.8492 - val_loss: 0.6158 - val_accuracy: 0.6771 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3334 - accuracy: 0.8487 - val_loss: 0.7325 - val_accuracy: 0.6076 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3189 - accuracy: 0.8591 - val_loss: 0.6378 - val_accuracy: 0.6354 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3170 - accuracy: 0.8621 - val_loss: 1.2317 - val_accuracy: 0.5174 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3157 - accuracy: 0.8591 - val_loss: 0.6418 - val_accuracy: 0.6458 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2960 - accuracy: 0.8676 - val_loss: 0.6262 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3017 - accuracy: 0.8636 - val_loss: 0.9833 - val_accuracy: 0.5486 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2894 - accuracy: 0.8730 - val_loss: 0.8080 - val_accuracy: 0.6285 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8616INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.3049 - accuracy: 0.8616 - val_loss: 0.5640 - val_accuracy: 0.7292 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2920 - accuracy: 0.8720 - val_loss: 0.5994 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2853 - accuracy: 0.8720 - val_loss: 0.6039 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2729 - accuracy: 0.8834 - val_loss: 0.7162 - val_accuracy: 0.6528 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2603 - accuracy: 0.8844 - val_loss: 0.8941 - val_accuracy: 0.5972 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.8854INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2540 - accuracy: 0.8854 - val_loss: 0.5571 - val_accuracy: 0.7674 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.8834INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2503 - accuracy: 0.8834 - val_loss: 0.5356 - val_accuracy: 0.7222 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2550 - accuracy: 0.8810 - val_loss: 0.6703 - val_accuracy: 0.6632 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2546 - accuracy: 0.8904 - val_loss: 1.1341 - val_accuracy: 0.5556 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2576 - accuracy: 0.8849 - val_loss: 0.6585 - val_accuracy: 0.6701 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2654 - accuracy: 0.8879 - val_loss: 0.5607 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2510 - accuracy: 0.8914 - val_loss: 0.5976 - val_accuracy: 0.7257 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.8909INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.2573 - accuracy: 0.8909 - val_loss: 0.5247 - val_accuracy: 0.7812 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2371 - accuracy: 0.8993 - val_loss: 0.8256 - val_accuracy: 0.6701 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2545 - accuracy: 0.8909 - val_loss: 1.3685 - val_accuracy: 0.5382 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.8814INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2648 - accuracy: 0.8814 - val_loss: 0.5087 - val_accuracy: 0.7431 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2505 - accuracy: 0.8934 - val_loss: 0.6155 - val_accuracy: 0.7049 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.8874INFO:tensorflow:Assets written to: log/bcic_indep_1_out_weights.tf/assets\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2535 - accuracy: 0.8874 - val_loss: 0.4831 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2500 - accuracy: 0.8963 - val_loss: 1.8254 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2458 - accuracy: 0.8914 - val_loss: 0.5263 - val_accuracy: 0.7361 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2346 - accuracy: 0.8929 - val_loss: 0.5022 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2250 - accuracy: 0.9033 - val_loss: 0.6851 - val_accuracy: 0.6944 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2477 - accuracy: 0.8934 - val_loss: 0.6358 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2392 - accuracy: 0.8968 - val_loss: 0.5739 - val_accuracy: 0.7257 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2284 - accuracy: 0.8998 - val_loss: 0.7505 - val_accuracy: 0.6875 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2506 - accuracy: 0.8914 - val_loss: 0.6886 - val_accuracy: 0.6910 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2404 - accuracy: 0.8983 - val_loss: 0.6362 - val_accuracy: 0.7153 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2164 - accuracy: 0.9043 - val_loss: 0.5686 - val_accuracy: 0.7118 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2177 - accuracy: 0.9062 - val_loss: 0.6005 - val_accuracy: 0.7014 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2244 - accuracy: 0.9013 - val_loss: 0.5414 - val_accuracy: 0.7396 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2024 - accuracy: 0.9127 - val_loss: 0.5465 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2064 - accuracy: 0.9087 - val_loss: 0.6191 - val_accuracy: 0.7222 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2107 - accuracy: 0.9067 - val_loss: 0.4905 - val_accuracy: 0.7708 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1998 - accuracy: 0.9196 - val_loss: 0.5245 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1984 - accuracy: 0.9122 - val_loss: 0.5173 - val_accuracy: 0.7743 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2092 - accuracy: 0.9107 - val_loss: 0.5442 - val_accuracy: 0.7604 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2152 - accuracy: 0.9097 - val_loss: 0.6234 - val_accuracy: 0.6979 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2070 - accuracy: 0.9157 - val_loss: 0.6587 - val_accuracy: 0.7188 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:45:47.319196: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open log/bcic_indep_1_out_weights.tf: FAILED_PRECONDITION: log/bcic_indep_1_out_weights.tf; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.95      0.84       144\n",
      "         1.0       0.93      0.68      0.79       144\n",
      "\n",
      "    accuracy                           0.82       288\n",
      "   macro avg       0.84      0.82      0.81       288\n",
      "weighted avg       0.84      0.82      0.81       288\n",
      "\n",
      "F1-score is computed based on binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/home/jupyter-markerxz/.local/lib/python3.9/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    }
   ],
   "source": [
    "bcic_indep = Experiment.subject_independent_cv(X_bcic,y_bcic,\n",
    "                                               seed=0,verbose=1,\n",
    "                                               model_name='bcic_indep_1',\n",
    "                                               benchmarks=['EEGNet','DeepConvNet','EEGene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0cbb9a-378b-441e-a6ae-9bdcca6d62d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>+-acc</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>+-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>69.06</td>\n",
       "      <td>11.12</td>\n",
       "      <td>70.41</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeepConvNet</td>\n",
       "      <td>67.67</td>\n",
       "      <td>14.88</td>\n",
       "      <td>60.55</td>\n",
       "      <td>21.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EEGene</td>\n",
       "      <td>66.32</td>\n",
       "      <td>9.08</td>\n",
       "      <td>65.18</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>65.20</td>\n",
       "      <td>8.36</td>\n",
       "      <td>63.85</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>63.62</td>\n",
       "      <td>4.61</td>\n",
       "      <td>60.85</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meanstd</td>\n",
       "      <td>63.31</td>\n",
       "      <td>9.58</td>\n",
       "      <td>62.99</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cross_correlate</td>\n",
       "      <td>63.04</td>\n",
       "      <td>8.81</td>\n",
       "      <td>62.01</td>\n",
       "      <td>9.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covariance</td>\n",
       "      <td>62.23</td>\n",
       "      <td>9.57</td>\n",
       "      <td>61.17</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>variance</td>\n",
       "      <td>59.80</td>\n",
       "      <td>11.55</td>\n",
       "      <td>58.81</td>\n",
       "      <td>13.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>58.56</td>\n",
       "      <td>6.51</td>\n",
       "      <td>58.34</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>maxmin</td>\n",
       "      <td>55.83</td>\n",
       "      <td>6.02</td>\n",
       "      <td>52.76</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fft</td>\n",
       "      <td>53.16</td>\n",
       "      <td>2.45</td>\n",
       "      <td>51.13</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fft2</td>\n",
       "      <td>51.70</td>\n",
       "      <td>3.21</td>\n",
       "      <td>48.78</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method  accuracy  +-acc  f1-score  +-f1\n",
       "10            EEGNet     69.06  11.12     70.41  9.32\n",
       "11       DeepConvNet     67.67  14.88     60.55 21.75\n",
       "12            EEGene     66.32   9.08     65.18  9.44\n",
       "9                all     65.20   8.36     63.85  8.95\n",
       "1                raw     63.62   4.61     60.85  6.08\n",
       "6            meanstd     63.31   9.58     62.99  8.46\n",
       "4    cross_correlate     63.04   8.81     62.01  9.65\n",
       "0         covariance     62.23   9.57     61.17 10.16\n",
       "7           variance     59.80  11.55     58.81 13.06\n",
       "8   spectral_entropy     58.56   6.51     58.34  9.95\n",
       "5             maxmin     55.83   6.02     52.76  8.07\n",
       "3                fft     53.16   2.45     51.13  3.58\n",
       "2               fft2     51.70   3.21     48.78  4.96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment.make_df(bcic_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941b879-27bc-4a11-bdaf-1a4260f286b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
